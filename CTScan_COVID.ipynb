{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTaYnRxfI09e9l+wFsfMFh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75a4f7444af4424cbc6242c1f7e50414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33f2f225b0fe466d9b5298628baae6ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aef8ffcd7d344cc2850b164348db819f",
              "IPY_MODEL_6c38cbc8a4cd45aa8e6bff3c226f7ecd"
            ]
          }
        },
        "33f2f225b0fe466d9b5298628baae6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aef8ffcd7d344cc2850b164348db819f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5bef42c49d7f4e7b806a751743f08ab1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 57365526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 57365526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc7285849be745738c58e8922c14ae32"
          }
        },
        "6c38cbc8a4cd45aa8e6bff3c226f7ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_778dae2ce16745739733bab50f0e3a07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 54.7M/54.7M [00:09&lt;00:00, 5.86MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0509ed66c996480797052dbbe78d724a"
          }
        },
        "5bef42c49d7f4e7b806a751743f08ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc7285849be745738c58e8922c14ae32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "778dae2ce16745739733bab50f0e3a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0509ed66c996480797052dbbe78d724a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ammzny/CT_COVID/blob/main/CTScan_COVID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbXPkwNDqr4F",
        "outputId": "ad734e84-8d11-47ed-e19e-7f069751958a"
      },
      "source": [
        "!git clone https://github.com/Ammzny/CT_COVID"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CT_COVID'...\n",
            "remote: Enumerating objects: 1852, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 1852 (delta 0), reused 2 (delta 0), pack-reused 1849\u001b[K\n",
            "Receiving objects: 100% (1852/1852), 358.68 MiB | 30.02 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "Checking out files: 100% (1753/1753), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_b35B1Zq-X9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import random \n",
        "from torchvision.datasets import ImageFolder\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from skimage.io import imread, imsave\n",
        "import skimage\n",
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDhxgTt3rCK2"
      },
      "source": [
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "########## Mean and std are calculated from the train dataset\n",
        "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
        "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
        "train_transformer = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(90),\n",
        "    # random brightness and random contrast\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_transformer = transforms.Compose([\n",
        "#     transforms.Resize(224),\n",
        "#     transforms.CenterCrop(224),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I7LEYayFrFZ6",
        "outputId": "dd78fb77-693b-4422-e1b7-ed198478315d"
      },
      "source": [
        "'''Load LUNA dataset'''\n",
        "\n",
        "# import h5py \n",
        "# import numpy as np\n",
        "# import skimage\n",
        "# import torch\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torch.utils.data import TensorDataset\n",
        "# f = h5py.File('all_patches.hdf5','r')\n",
        "# f.keys()\n",
        "# img = f['ct_slices'][:]  \n",
        "# label = f['slice_class'][:] \n",
        "# f.close()\n",
        "# print(np.shape(img))\n",
        "# print('b',np.shape(label))\n",
        "# skimage.io.imshow(img[120])\n",
        "# print(label[120])\n",
        "# batchsize=4\n",
        "\n",
        "# class LungDataset(Dataset):\n",
        "#     def __init__(self, img, label, transform=None):\n",
        "#         self.img = img\n",
        "#         self.label = label\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.img)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         if torch.is_tensor(idx):\n",
        "#             idx = idx.tolist()\n",
        "        \n",
        "#         image = PIL_image = Image.fromarray(self.img[idx]).convert('RGB')\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "#         sample = {'img': image,\n",
        "#                   'label': int(self.label[idx])}\n",
        "#         return sample\n",
        "    \n",
        "# trainset = LungDataset(img, label, transform= val_transformer)\n",
        "# valset = LungDataset(img, label, transform= val_transformer)\n",
        "# train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
        "# val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
        "# modelname = 'medical_transfer'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Load LUNA dataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk7u4SXIrHuN",
        "outputId": "e2ed3105-1b61-42ab-e5bb-56e1a34708e6"
      },
      "source": [
        "batchsize=4\n",
        "def read_txt(txt_path):\n",
        "    with open(txt_path) as f:\n",
        "        lines = f.readlines()\n",
        "    txt_data = [line.strip() for line in lines]\n",
        "    return txt_data\n",
        "\n",
        "class CovidCTDataset(Dataset):\n",
        "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            txt_path (string): Path to the txt file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        File structure:\n",
        "        - root_dir\n",
        "            - CT_COVID\n",
        "                - img1.png\n",
        "                - img2.png\n",
        "                - ......\n",
        "            - CT_NonCOVID\n",
        "                - img1.png\n",
        "                - img2.png\n",
        "                - ......\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
        "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
        "        self.num_cls = len(self.classes)\n",
        "        self.img_list = []\n",
        "        for c in range(self.num_cls):\n",
        "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
        "            self.img_list += cls_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_path = self.img_list[idx][0]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        sample = {'img': image,\n",
        "                  'label': int(self.img_list[idx][1])}\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    trainset = CovidCTDataset(root_dir='CT_COVID/Data',\n",
        "                              txt_COVID='CT_COVID/Data/COVID/trainCT_COVID.txt',\n",
        "                              txt_NonCOVID='CT_COVID/Data/NonCOVID/trainCT_NonCOVID.txt',\n",
        "                              transform= train_transformer)\n",
        "    valset = CovidCTDataset(root_dir='CT_COVID/Data/',\n",
        "                              txt_COVID='CT_COVID/Data/COVID/valCT_COVID.txt',\n",
        "                              txt_NonCOVID='CT_COVID/Data/NonCOVID/valCT_NonCOVID.txt',\n",
        "                              transform= val_transformer)\n",
        "    testset = CovidCTDataset(root_dir='CT_COVID/Data/',\n",
        "                              txt_COVID='CT_COVID/Data/COVID/testCT_COVID.txt',\n",
        "                              txt_NonCOVID='CT_COVID/Data/NonCOVID/testCT_NonCOVID.txt',\n",
        "                              transform= val_transformer)\n",
        "    print(trainset.__len__())\n",
        "    print(valset.__len__())\n",
        "    print(testset.__len__())\n",
        "\n",
        "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
        "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
        "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "425\n",
            "118\n",
            "203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "97AKOFaMrzoz",
        "outputId": "cc45bc44-c981-48f4-a4ab-cbf6cb944ddf"
      },
      "source": [
        "for batch_index, batch_samples in enumerate(train_loader):      \n",
        "        data, target = batch_samples['img'], batch_samples['label']\n",
        "skimage.io.imshow(data[0,1,:,:].numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff45af84f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zN2akWncr6hU",
        "outputId": "c9565a40-84bb-4aa2-9121-7d564b323b39"
      },
      "source": [
        "# mixup\n",
        "'''Use mixup to do data augmentation'''\n",
        "\n",
        "# def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "#     '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "#     if alpha > 0:\n",
        "#         lam = np.random.beta(alpha, alpha)\n",
        "# #         print('lam',lam)\n",
        "#     else:\n",
        "#         lam = 1\n",
        "\n",
        "#     batch_size = x.size()[0]\n",
        "#     if use_cuda:\n",
        "#         index = torch.randperm(batch_size).cuda()\n",
        "#     else:\n",
        "#         index = torch.randperm(batch_size)\n",
        "\n",
        "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "#     y_a, y_b = y, y[index]\n",
        "#     return mixed_x, y_a, y_b, lam\n",
        "\n",
        "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "# #     print(pred)\n",
        "# #     print(y_a)\n",
        "# #     print('criterion',criterion(pred, y_a))\n",
        "#     return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Use mixup to do data augmentation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB4hV7Bqr9Fa"
      },
      "source": [
        "#training process is defined here \n",
        "\n",
        "alpha = None\n",
        "## alpha is None if mixup is not used\n",
        "alpha_name = f'{alpha}'\n",
        "device = 'cuda'\n",
        "\n",
        "def train(optimizer, epoch):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    \n",
        "    for batch_index, batch_samples in enumerate(train_loader):\n",
        "        \n",
        "        # move data to device\n",
        "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
        "        \n",
        "        ## adjust data to meet the input dimension of model\n",
        "#         data = data[:, 0, :, :]\n",
        "#         data = data[:, None, :, :]    \n",
        "        \n",
        "        #mixup\n",
        "#         data, targets_a, targets_b, lam = mixup_data(data, target, alpha, use_cuda=True)\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        criteria = nn.CrossEntropyLoss()\n",
        "        loss = criteria(output, target.long())\n",
        "        \n",
        "        #mixup loss\n",
        "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
        "\n",
        "        train_loss += criteria(output, target.long())\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
        "    \n",
        "        # Display progress and write to tensorboard\n",
        "        if batch_index % bs == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
        "                epoch, batch_index, len(train_loader),\n",
        "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
        "    \n",
        "#     print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
        "#         100.0 * train_correct / len(train_loader.dataset)))\n",
        "#     f = open('model_result/{}.txt'.format(modelname), 'a+')\n",
        "#     f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
        "#         100.0 * train_correct / len(train_loader.dataset)))\n",
        "#     f.write('\\n')\n",
        "#     f.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5gxLRs1r_Nq"
      },
      "source": [
        "#val process is defined here\n",
        "\n",
        "def val(epoch):\n",
        "    \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    results = []\n",
        "    \n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    FP = 0\n",
        "    \n",
        "    \n",
        "    criteria = nn.CrossEntropyLoss()\n",
        "    # Don't update model\n",
        "    with torch.no_grad():\n",
        "        tpr_list = []\n",
        "        fpr_list = []\n",
        "        \n",
        "        predlist=[]\n",
        "        scorelist=[]\n",
        "        targetlist=[]\n",
        "        # Predict\n",
        "        for batch_index, batch_samples in enumerate(val_loader):\n",
        "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
        "            \n",
        "#             data = data[:, 0, :, :]\n",
        "#             data = data[:, None, :, :]\n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += criteria(output, target.long())\n",
        "            score = F.softmax(output, dim=1)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "#             print('target',target.long()[:, 2].view_as(pred))\n",
        "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
        "            \n",
        "#             print(output[:,1].cpu().numpy())\n",
        "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
        "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
        "            targetcpu=target.long().cpu().numpy()\n",
        "            predlist=np.append(predlist, pred.cpu().numpy())\n",
        "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
        "            targetlist=np.append(targetlist,targetcpu)\n",
        "           \n",
        "    return targetlist, scorelist, predlist\n",
        "    \n",
        "    # Write to tensorboard\n",
        "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVL9kPHdsBN0"
      },
      "source": [
        "#test process is defined here \n",
        "\n",
        "def test(epoch):\n",
        "    \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    results = []\n",
        "    \n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    FP = 0\n",
        "    \n",
        "    \n",
        "    criteria = nn.CrossEntropyLoss()\n",
        "    # Don't update model\n",
        "    with torch.no_grad():\n",
        "        tpr_list = []\n",
        "        fpr_list = []\n",
        "        \n",
        "        predlist=[]\n",
        "        scorelist=[]\n",
        "        targetlist=[]\n",
        "        # Predict\n",
        "        for batch_index, batch_samples in enumerate(test_loader):\n",
        "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
        "#             data = data[:, 0, :, :]\n",
        "#             data = data[:, None, :, :]\n",
        "#             print(target)\n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += criteria(output, target.long())\n",
        "            score = F.softmax(output, dim=1)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "#             print('target',target.long()[:, 2].view_as(pred))\n",
        "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
        "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
        "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
        "# #             # FN    predict 0 label 1\n",
        "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
        "# #             # FP    predict 1 label 0\n",
        "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
        "#             print(TP,TN,FN,FP)\n",
        "            \n",
        "            \n",
        "#             print(output[:,1].cpu().numpy())\n",
        "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
        "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
        "            targetcpu=target.long().cpu().numpy()\n",
        "            predlist=np.append(predlist, pred.cpu().numpy())\n",
        "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
        "            targetlist=np.append(targetlist,targetcpu)\n",
        "    return targetlist, scorelist, predlist\n",
        "    \n",
        "    # Write to tensorboard\n",
        "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hH-Cg7p-sDMZ",
        "outputId": "1429ecf0-2493-4f28-fa95-f1de6cad78a2"
      },
      "source": [
        "'''CheXNet pretrained model'''\n",
        "\n",
        "# class DenseNet121(nn.Module):\n",
        "#     \"\"\"Model modified.\n",
        "\n",
        "#     The architecture of our model is the same as standard DenseNet121\n",
        "#     except the classifier layer which has an additional sigmoid function.\n",
        "\n",
        "#     \"\"\"\n",
        "#     def __init__(self, out_size):\n",
        "#         super(DenseNet121, self).__init__()\n",
        "#         self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
        "#         num_ftrs = self.densenet121.classifier.in_features\n",
        "#         self.densenet121.classifier = nn.Sequential(\n",
        "#             nn.Linear(num_ftrs, out_size),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.densenet121(x)\n",
        "#         return x\n",
        "  \n",
        "\n",
        "# device = 'cuda'\n",
        "# CKPT_PATH = 'model.pth.tar'\n",
        "# N_CLASSES = 14\n",
        "\n",
        "# DenseNet121 = DenseNet121(N_CLASSES).cuda()\n",
        "\n",
        "# CKPT_PATH = './CheXNet/model.pth.tar'\n",
        "\n",
        "# if os.path.isfile(CKPT_PATH):\n",
        "#     checkpoint = torch.load(CKPT_PATH)        \n",
        "#     state_dict = checkpoint['state_dict']\n",
        "#     remove_data_parallel = False\n",
        "\n",
        "\n",
        "#     pattern = re.compile(\n",
        "#         r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "#     for key in list(state_dict.keys()):\n",
        "#         match = pattern.match(key)\n",
        "#         new_key = match.group(1) + match.group(2) if match else key\n",
        "#         new_key = new_key[7:] if remove_data_parallel else new_key\n",
        "#         new_key = new_key[7:]\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#         del state_dict[key]\n",
        "\n",
        "\n",
        "#     DenseNet121.load_state_dict(checkpoint['state_dict'])\n",
        "#     print(\"=> loaded checkpoint\")\n",
        "# #     print(densenet121)\n",
        "# else:\n",
        "#     print(\"=> no checkpoint found\")\n",
        "\n",
        "# # for parma in DenseNet121.parameters():\n",
        "# #         parma.requires_grad = False\n",
        "# DenseNet121.densenet121.classifier._modules['0'] = nn.Linear(in_features=1024, out_features=2, bias=True)\n",
        "# DenseNet121.densenet121.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "# # print(DenseNet121)\n",
        "# model = DenseNet121.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CheXNet pretrained model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yaP2G-ADsFe4",
        "outputId": "7da2a3c9-602b-4582-a2d8-ea0f0bab19ba"
      },
      "source": [
        "'''DenseNet121 pretrained model from xrv'''\n",
        "\n",
        "# class DenseNetModel(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         \"\"\"\n",
        "#         Pass in parsed HyperOptArgumentParser to the model\n",
        "#         :param hparams:\n",
        "#         \"\"\"\n",
        "#         super(DenseNetModel, self).__init__()\n",
        "\n",
        "#         self.dense_net = xrv.models.DenseNet(num_classes=2)\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         logits = self.dense_net(x)\n",
        "#         return logits\n",
        "    \n",
        "# model = DenseNetModel().cuda()\n",
        "# modelname = 'DenseNet_medical'\n",
        "# # print(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DenseNet121 pretrained model from xrv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nbR-eHzksIYA",
        "outputId": "abaf07f3-444d-4218-c333-51384746c2de"
      },
      "source": [
        "'''ResNet18 pretrained'''\n",
        "# import torchvision.models as models\n",
        "# model = models.resnet18(pretrained=True).cuda()\n",
        "# modelname = 'ResNet18'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ResNet18 pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jnPideDqsKru",
        "outputId": "b0930685-6b62-4429-ff2b-27d8f928f23d"
      },
      "source": [
        "'''Dense121 pretrained'''\n",
        "# import torchvision.models as models\n",
        "# model = models.densenet121(pretrained=True).cuda()\n",
        "# modelname = 'Dense121'\n",
        "# pretrained_net = torch.load('model_backup/Dense121.pt')\n",
        "# model.load_state_dict(pretrained_net)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dense121 pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBwPV30EsMu0"
      },
      "source": [
        "### Dense169\n",
        "import torchvision.models as models\n",
        "# model = models.densenet169(pretrained=True).cuda()\n",
        "# # # modelname = 'Dense169'\n",
        "\n",
        "# \"\"\"load MoCo pretrained model\"\"\"\n",
        "# checkpoint = torch.load('new_data/save_model_dense/checkpoint_luna_covid_moco.pth.tar')\n",
        "# # # # print(checkpoint.keys())\n",
        "# # # # print(checkpoint['arch'])\n",
        "\n",
        "# state_dict = checkpoint['state_dict']\n",
        "# for key in list(state_dict.keys()):\n",
        "#     if 'module.encoder_q' in key:\n",
        "# #         print(key[17:])\n",
        "#         new_key = key[17:]\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#     del state_dict[key]\n",
        "# for key in list(state_dict.keys()):\n",
        "#     if  key == 'classifier.0.weight':\n",
        "#         new_key = 'classifier.weight'\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#         del state_dict[key]\n",
        "#     if  key == 'classifier.0.bias':\n",
        "#         new_key = 'classifier.bias'\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#         del state_dict[key]\n",
        "#     if  key == 'classifier.2.weight' or key == 'classifier.2.bias':\n",
        "#         del state_dict[key]\n",
        "# state_dict['classifier.weight'] = state_dict['classifier.weight'][:1000,:]\n",
        "# state_dict['classifier.bias'] = state_dict['classifier.bias'][:1000]\n",
        "# model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# # # print(model)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "75a4f7444af4424cbc6242c1f7e50414",
            "33f2f225b0fe466d9b5298628baae6ea",
            "aef8ffcd7d344cc2850b164348db819f",
            "6c38cbc8a4cd45aa8e6bff3c226f7ecd",
            "5bef42c49d7f4e7b806a751743f08ab1",
            "fc7285849be745738c58e8922c14ae32",
            "778dae2ce16745739733bab50f0e3a07",
            "0509ed66c996480797052dbbe78d724a"
          ]
        },
        "id": "Zje8qBCUs3AL",
        "outputId": "fd7a0ed5-5dc2-4230-bc58-ea653a2c1b6c"
      },
      "source": [
        "\"\"\"Load Self-Trans model\"\"\"\n",
        "\"\"\"Change names and locations to the Self-Trans.pt\"\"\"\n",
        "\n",
        "model = models.densenet169(pretrained=True).cuda()\n",
        "# pretrained_net = torch.load('model_backup/Dense169.pt')\n",
        "# pretrained_net = torch.load('model_backup/mixup/Dense169_0.6.pt')\n",
        "pretrained_net = torch.load('CT_COVID/Self-Trans.pt')\n",
        "\n",
        "\n",
        "model.load_state_dict(pretrained_net)\n",
        "\n",
        "modelname = 'Dense169_ssl_luna_moco'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a4f7444af4424cbc6242c1f7e50414",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=57365526.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OsxfAk6ZKpk2",
        "outputId": "083d21fe-3989-4292-ee77-02722bec03a0"
      },
      "source": [
        "'''ResNet50 pretrained'''\n",
        "\n",
        "# import torchvision.models as models\n",
        "# model = models.resnet50(pretrained=True).cuda()\n",
        "\n",
        "# checkpoint = torch.load('new_data/save_model/checkpoint.pth.tar')\n",
        "# # print(checkpoint.keys())\n",
        "# # print(checkpoint['arch'])\n",
        "\n",
        "# state_dict = checkpoint['state_dict']\n",
        "# for key in list(state_dict.keys()):\n",
        "#     if 'module.encoder_q' in key:\n",
        "#         print(key[17:])\n",
        "#         new_key = key[17:]\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#     del state_dict[key]\n",
        "# for key in list(state_dict.keys()):\n",
        "#     if  key == 'fc.0.weight':\n",
        "#         new_key = 'fc.weight'\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#         del state_dict[key]\n",
        "#     if  key == 'fc.0.bias':\n",
        "#         new_key = 'fc.bias'\n",
        "#         state_dict[new_key] = state_dict[key]\n",
        "#         del state_dict[key]\n",
        "#     if  key == 'fc.2.weight' or key == 'fc.2.bias':\n",
        "#         del state_dict[key]\n",
        "# state_dict['fc.weight'] = state_dict['fc.weight'][:1000,:]\n",
        "# state_dict['fc.bias'] = state_dict['fc.bias'][:1000]\n",
        "# # print(state_dict.keys())\n",
        "\n",
        "# # print(state_dict)\n",
        "# # pattern = re.compile(\n",
        "# #         r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "# #     for key in list(state_dict.keys()):\n",
        "# #         match = pattern.match(key)\n",
        "# #         new_key = match.group(1) + match.group(2) if match else key\n",
        "# #         new_key = new_key[7:] if remove_data_parallel else new_key\n",
        "# #         new_key = new_key[7:]\n",
        "# #         state_dict[new_key] = state_dict[key]\n",
        "# #         del state_dict[key]\n",
        "    \n",
        "# # model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "# # # modelname = 'ResNet50'\n",
        "# modelname = 'ResNet50_ssl'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ResNet50 pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J9LFDlSwKsHA",
        "outputId": "02802648-bb14-48c6-c39f-015a4166f823"
      },
      "source": [
        "'''VGGNet pretrained'''\n",
        "# import torchvision.models as models\n",
        "# model = models.vgg16(pretrained=True)\n",
        "# model = model.cuda()\n",
        "# modelname = 'vgg16'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'VGGNet pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ai75sp3fKuMM",
        "outputId": "72a61c51-01ee-437c-f7dc-3457f3e219c6"
      },
      "source": [
        "'''efficientNet pretrained'''\n",
        "\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
        "# model = model.cuda()\n",
        "# modelname = 'efficientNet-b0'\n",
        "\n",
        "\n",
        "# model = EfficientNet.from_name('efficientnet-b1').cuda()\n",
        "# modelname = 'efficientNet_random'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'efficientNet pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp-LKm0uKw9F",
        "outputId": "f9dafce9-49b8-4860-f4db-aa1f9c8366ac"
      },
      "source": [
        "# train\n",
        "bs =batchsize\n",
        "votenum = 10\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "r_list = []\n",
        "p_list = []\n",
        "acc_list = []\n",
        "AUC_list = []\n",
        "# TP = 0\n",
        "# TN = 0\n",
        "# FN = 0\n",
        "# FP = 0\n",
        "vote_pred = np.zeros(valset.__len__())\n",
        "vote_score = np.zeros(valset.__len__())\n",
        "\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
        "                                             \n",
        "scheduler = StepLR(optimizer, step_size=1)\n",
        "\n",
        "total_epoch = 50\n",
        "for epoch in range(1, total_epoch+1):\n",
        "    train(optimizer, epoch)\n",
        "    \n",
        "    targetlist, scorelist, predlist = val(epoch)\n",
        "    print('target',targetlist)\n",
        "    print('score',scorelist)\n",
        "    print('predict',predlist)\n",
        "    vote_pred = vote_pred + predlist \n",
        "    vote_score = vote_score + scorelist \n",
        "\n",
        "    if epoch % votenum == 0:\n",
        "        \n",
        "        # major vote\n",
        "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
        "        vote_pred[vote_pred > (votenum/2)] = 1\n",
        "        vote_score = vote_score/votenum\n",
        "        \n",
        "        print('vote_pred', vote_pred)\n",
        "        print('targetlist', targetlist)\n",
        "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
        "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
        "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
        "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
        "        \n",
        "        \n",
        "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
        "        print('TP+FP',TP+FP)\n",
        "        p = TP / (TP + FP)\n",
        "        print('precision',p)\n",
        "        p = TP / (TP + FP)\n",
        "        r = TP / (TP + FN)\n",
        "        print('recall',r)\n",
        "        F1 = 2 * r * p / (r + p)\n",
        "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "        print('F1',F1)\n",
        "        print('acc',acc)\n",
        "        AUC = roc_auc_score(targetlist, vote_score)\n",
        "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
        "        print('AUC', AUC)\n",
        "        \n",
        "        \n",
        "        \n",
        "#         if epoch == total_epoch:\n",
        "        torch.save(model.state_dict(), \"CT_COVID/Self-Trans.pt\".format(modelname,alpha_name))  \n",
        "        \n",
        "        vote_pred = np.zeros(valset.__len__())\n",
        "        vote_score = np.zeros(valset.__len__())\n",
        "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
        "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
        "        epoch, r, p, F1, acc, AUC))\n",
        "\n",
        "#         f = open('model_result/medical_transfer/{}_{}.txt'.format(modelname,alpha_name), 'a+')\n",
        "#         f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
        "# average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
        "#         epoch, r, p, F1, acc, AUC))\n",
        "#         f.close()\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/107 (0%)]\tTrain Loss: 0.005155\n",
            "Train Epoch: 1 [4/107 (4%)]\tTrain Loss: 0.258602\n",
            "Train Epoch: 1 [8/107 (7%)]\tTrain Loss: 0.001978\n",
            "Train Epoch: 1 [12/107 (11%)]\tTrain Loss: 0.091385\n",
            "Train Epoch: 1 [16/107 (15%)]\tTrain Loss: 0.012226\n",
            "Train Epoch: 1 [20/107 (19%)]\tTrain Loss: 0.004769\n",
            "Train Epoch: 1 [24/107 (22%)]\tTrain Loss: 0.046448\n",
            "Train Epoch: 1 [28/107 (26%)]\tTrain Loss: 0.117583\n",
            "Train Epoch: 1 [32/107 (30%)]\tTrain Loss: 0.010998\n",
            "Train Epoch: 1 [36/107 (34%)]\tTrain Loss: 0.006623\n",
            "Train Epoch: 1 [40/107 (37%)]\tTrain Loss: 0.008621\n",
            "Train Epoch: 1 [44/107 (41%)]\tTrain Loss: 0.252702\n",
            "Train Epoch: 1 [48/107 (45%)]\tTrain Loss: 0.053935\n",
            "Train Epoch: 1 [52/107 (49%)]\tTrain Loss: 0.026096\n",
            "Train Epoch: 1 [56/107 (52%)]\tTrain Loss: 0.031970\n",
            "Train Epoch: 1 [60/107 (56%)]\tTrain Loss: 0.021333\n",
            "Train Epoch: 1 [64/107 (60%)]\tTrain Loss: 0.014038\n",
            "Train Epoch: 1 [68/107 (64%)]\tTrain Loss: 0.104762\n",
            "Train Epoch: 1 [72/107 (67%)]\tTrain Loss: 0.015325\n",
            "Train Epoch: 1 [76/107 (71%)]\tTrain Loss: 0.264808\n",
            "Train Epoch: 1 [80/107 (75%)]\tTrain Loss: 0.014095\n",
            "Train Epoch: 1 [84/107 (79%)]\tTrain Loss: 0.152148\n",
            "Train Epoch: 1 [88/107 (82%)]\tTrain Loss: 0.003662\n",
            "Train Epoch: 1 [92/107 (86%)]\tTrain Loss: 0.018465\n",
            "Train Epoch: 1 [96/107 (90%)]\tTrain Loss: 0.016660\n",
            "Train Epoch: 1 [100/107 (93%)]\tTrain Loss: 0.067192\n",
            "Train Epoch: 1 [104/107 (97%)]\tTrain Loss: 0.066096\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.24453772e-03 9.68357861e-01 7.91242182e-01 1.33023992e-01\n",
            " 1.62255531e-03 5.81099140e-03 9.58457053e-01 9.32907760e-02\n",
            " 6.21953513e-03 3.39631468e-01 2.46110246e-01 8.94938782e-03\n",
            " 9.93440524e-02 1.23468004e-02 1.37222353e-02 5.48648939e-04\n",
            " 4.76725516e-04 2.04224780e-01 3.19739766e-02 1.90195620e-01\n",
            " 6.02578819e-01 7.80127645e-01 9.07932103e-01 9.97535825e-01\n",
            " 8.90745878e-01 9.75586057e-01 9.93623734e-01 2.50958413e-01\n",
            " 7.97501951e-02 1.71786353e-01 9.19827074e-02 9.87710208e-02\n",
            " 5.88438585e-02 5.05526608e-04 4.99972666e-04 2.80732964e-03\n",
            " 1.74453249e-03 2.88277030e-01 5.88457379e-03 2.55053630e-03\n",
            " 1.13330758e-03 2.14649760e-03 6.07871786e-02 1.85877576e-01\n",
            " 8.46009314e-01 9.93548930e-02 2.82955617e-01 6.90783709e-02\n",
            " 1.91914290e-01 3.24011713e-01 7.02912927e-01 6.13095690e-05\n",
            " 6.32759533e-04 2.84303203e-02 1.82619874e-06 2.50826147e-03\n",
            " 7.46841207e-02 6.19139769e-07 1.08750486e-04 3.40886712e-02\n",
            " 9.91530180e-01 9.90297139e-01 9.87745941e-01 9.94474113e-01\n",
            " 9.98532057e-01 9.45214212e-01 7.41843700e-01 9.99786198e-01\n",
            " 9.99671221e-01 2.69602329e-01 9.40554500e-01 8.99291098e-01\n",
            " 7.11219013e-01 6.98848128e-01 7.36238837e-01 9.89276528e-01\n",
            " 9.92099524e-01 9.92605448e-01 9.99767005e-01 9.75419879e-01\n",
            " 9.99595582e-01 9.99216080e-01 9.99891162e-01 2.98922330e-01\n",
            " 3.86006117e-01 9.94442642e-01 9.98331130e-01 9.98512208e-01\n",
            " 1.03315644e-01 9.49248314e-01 9.96985376e-01 3.30550820e-01\n",
            " 1.56059578e-01 9.99997854e-01 9.99998093e-01 9.99393225e-01\n",
            " 9.37099695e-01 4.71322924e-01 5.64224720e-01 9.24128294e-01\n",
            " 1.25023946e-01 7.99648106e-01 1.98818427e-02 6.14059627e-01\n",
            " 3.50041211e-01 7.27935791e-01 8.26704681e-01 7.12739378e-02\n",
            " 6.64798692e-02 1.81782261e-01 1.50869161e-01 7.77944103e-02\n",
            " 9.98689950e-01 9.56914783e-01 1.19290888e-01 2.87469387e-01\n",
            " 9.99802411e-01 9.83887732e-01]\n",
            "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 2 [0/107 (0%)]\tTrain Loss: 0.024248\n",
            "Train Epoch: 2 [4/107 (4%)]\tTrain Loss: 0.022224\n",
            "Train Epoch: 2 [8/107 (7%)]\tTrain Loss: 0.014267\n",
            "Train Epoch: 2 [12/107 (11%)]\tTrain Loss: 0.011199\n",
            "Train Epoch: 2 [16/107 (15%)]\tTrain Loss: 0.090278\n",
            "Train Epoch: 2 [20/107 (19%)]\tTrain Loss: 0.010730\n",
            "Train Epoch: 2 [24/107 (22%)]\tTrain Loss: 0.012143\n",
            "Train Epoch: 2 [28/107 (26%)]\tTrain Loss: 0.023651\n",
            "Train Epoch: 2 [32/107 (30%)]\tTrain Loss: 0.009828\n",
            "Train Epoch: 2 [36/107 (34%)]\tTrain Loss: 0.028195\n",
            "Train Epoch: 2 [40/107 (37%)]\tTrain Loss: 0.049525\n",
            "Train Epoch: 2 [44/107 (41%)]\tTrain Loss: 0.057169\n",
            "Train Epoch: 2 [48/107 (45%)]\tTrain Loss: 0.013440\n",
            "Train Epoch: 2 [52/107 (49%)]\tTrain Loss: 0.051458\n",
            "Train Epoch: 2 [56/107 (52%)]\tTrain Loss: 0.023405\n",
            "Train Epoch: 2 [60/107 (56%)]\tTrain Loss: 0.003380\n",
            "Train Epoch: 2 [64/107 (60%)]\tTrain Loss: 0.003869\n",
            "Train Epoch: 2 [68/107 (64%)]\tTrain Loss: 0.016865\n",
            "Train Epoch: 2 [72/107 (67%)]\tTrain Loss: 0.008494\n",
            "Train Epoch: 2 [76/107 (71%)]\tTrain Loss: 0.007263\n",
            "Train Epoch: 2 [80/107 (75%)]\tTrain Loss: 0.016569\n",
            "Train Epoch: 2 [84/107 (79%)]\tTrain Loss: 0.167066\n",
            "Train Epoch: 2 [88/107 (82%)]\tTrain Loss: 0.017675\n",
            "Train Epoch: 2 [92/107 (86%)]\tTrain Loss: 0.010982\n",
            "Train Epoch: 2 [96/107 (90%)]\tTrain Loss: 0.255458\n",
            "Train Epoch: 2 [100/107 (93%)]\tTrain Loss: 0.029203\n",
            "Train Epoch: 2 [104/107 (97%)]\tTrain Loss: 0.072738\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.72668537e-02 6.19943321e-01 3.15311015e-01 9.10158336e-01\n",
            " 3.21507566e-02 1.26575291e-01 6.39575064e-01 7.55834103e-01\n",
            " 1.36896670e-01 7.72531927e-01 8.48654270e-01 1.42592162e-01\n",
            " 7.26840734e-01 6.02655634e-02 5.55134900e-02 8.74247286e-04\n",
            " 3.00770998e-01 1.65587708e-01 1.84508953e-02 1.51734129e-01\n",
            " 2.91170120e-01 7.85461366e-01 9.06293571e-01 9.92915869e-01\n",
            " 9.10890341e-01 9.09606457e-01 9.80208635e-01 2.52421200e-01\n",
            " 3.27789858e-02 1.51741520e-01 1.09912232e-01 7.12186396e-02\n",
            " 8.32986385e-02 1.87536154e-03 3.08287423e-03 4.26162302e-01\n",
            " 5.82392573e-01 9.50766265e-01 1.28823653e-01 5.97419627e-02\n",
            " 2.79145632e-02 1.53514901e-02 6.20818615e-01 5.17363727e-01\n",
            " 6.10682130e-01 1.05432823e-01 2.27123410e-01 8.23139623e-02\n",
            " 2.39550337e-01 1.49071455e-01 6.20879829e-01 4.12636364e-05\n",
            " 7.15209229e-04 2.72605829e-02 4.61689087e-09 4.59572650e-04\n",
            " 5.87294623e-02 1.92798999e-09 8.00602254e-04 6.52884096e-02\n",
            " 9.55614448e-01 9.50217903e-01 9.54238117e-01 9.73902524e-01\n",
            " 9.53872859e-01 9.75556910e-01 9.94346440e-01 9.99930263e-01\n",
            " 9.99961853e-01 8.00106585e-01 7.31428206e-01 5.37021220e-01\n",
            " 8.57839048e-01 8.45437825e-01 8.90133917e-01 7.67192721e-01\n",
            " 9.08681989e-01 8.86548579e-01 9.92467463e-01 9.95729029e-01\n",
            " 9.99562800e-01 9.83062983e-01 9.99470413e-01 4.23778862e-01\n",
            " 5.21591544e-01 9.76413310e-01 9.25784886e-01 6.87065065e-01\n",
            " 2.10841656e-01 9.99776900e-01 9.96708870e-01 9.04018402e-01\n",
            " 8.47294748e-01 9.99733984e-01 9.99875307e-01 9.99134362e-01\n",
            " 6.57460570e-01 6.70883715e-01 7.73940444e-01 9.98948276e-01\n",
            " 3.90660673e-01 7.19867110e-01 6.40590012e-01 8.29338968e-01\n",
            " 5.31161904e-01 7.31448889e-01 8.11370969e-01 3.98458019e-02\n",
            " 5.46265244e-01 6.49831593e-02 2.87382185e-01 1.03923574e-01\n",
            " 9.96706069e-01 9.73956764e-01 7.45705307e-01 6.66392326e-01\n",
            " 9.81689215e-01 7.81048536e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 3 [0/107 (0%)]\tTrain Loss: 0.127664\n",
            "Train Epoch: 3 [4/107 (4%)]\tTrain Loss: 0.043979\n",
            "Train Epoch: 3 [8/107 (7%)]\tTrain Loss: 0.030128\n",
            "Train Epoch: 3 [12/107 (11%)]\tTrain Loss: 0.041533\n",
            "Train Epoch: 3 [16/107 (15%)]\tTrain Loss: 0.008864\n",
            "Train Epoch: 3 [20/107 (19%)]\tTrain Loss: 0.002403\n",
            "Train Epoch: 3 [24/107 (22%)]\tTrain Loss: 0.027299\n",
            "Train Epoch: 3 [28/107 (26%)]\tTrain Loss: 0.041165\n",
            "Train Epoch: 3 [32/107 (30%)]\tTrain Loss: 0.211936\n",
            "Train Epoch: 3 [36/107 (34%)]\tTrain Loss: 0.009505\n",
            "Train Epoch: 3 [40/107 (37%)]\tTrain Loss: 0.017873\n",
            "Train Epoch: 3 [44/107 (41%)]\tTrain Loss: 0.007589\n",
            "Train Epoch: 3 [48/107 (45%)]\tTrain Loss: 0.049839\n",
            "Train Epoch: 3 [52/107 (49%)]\tTrain Loss: 0.030101\n",
            "Train Epoch: 3 [56/107 (52%)]\tTrain Loss: 0.007340\n",
            "Train Epoch: 3 [60/107 (56%)]\tTrain Loss: 0.012623\n",
            "Train Epoch: 3 [64/107 (60%)]\tTrain Loss: 0.101941\n",
            "Train Epoch: 3 [68/107 (64%)]\tTrain Loss: 0.042364\n",
            "Train Epoch: 3 [72/107 (67%)]\tTrain Loss: 0.019527\n",
            "Train Epoch: 3 [76/107 (71%)]\tTrain Loss: 0.006289\n",
            "Train Epoch: 3 [80/107 (75%)]\tTrain Loss: 0.028322\n",
            "Train Epoch: 3 [84/107 (79%)]\tTrain Loss: 0.047362\n",
            "Train Epoch: 3 [88/107 (82%)]\tTrain Loss: 0.055959\n",
            "Train Epoch: 3 [92/107 (86%)]\tTrain Loss: 0.024081\n",
            "Train Epoch: 3 [96/107 (90%)]\tTrain Loss: 0.138147\n",
            "Train Epoch: 3 [100/107 (93%)]\tTrain Loss: 0.001977\n",
            "Train Epoch: 3 [104/107 (97%)]\tTrain Loss: 0.015821\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [6.13684440e-03 8.73749971e-01 2.19922900e-01 6.83630109e-01\n",
            " 1.63558014e-02 2.79649557e-03 5.75059891e-01 1.71380565e-01\n",
            " 4.27949848e-03 3.73426229e-01 7.69718587e-01 5.34654520e-02\n",
            " 4.93337542e-01 1.19383924e-03 1.88927981e-03 6.42825151e-04\n",
            " 6.20506890e-03 6.44290969e-02 7.89818540e-03 6.49558902e-02\n",
            " 4.78526384e-01 8.95368218e-01 8.36272538e-01 9.94682729e-01\n",
            " 7.94006884e-01 6.64837062e-01 9.78953660e-01 1.07302062e-01\n",
            " 1.24073559e-02 2.77182199e-02 8.29041600e-02 6.37276918e-02\n",
            " 1.93254557e-02 1.54472562e-03 3.27561074e-03 1.08086606e-02\n",
            " 1.67792365e-02 4.60549623e-01 1.67108431e-01 1.09783627e-01\n",
            " 4.79042903e-02 2.79233772e-02 5.73388003e-02 9.96625945e-02\n",
            " 4.40962315e-01 2.10868359e-01 6.99850380e-01 1.98822111e-01\n",
            " 2.29394898e-01 4.42639887e-01 6.48994803e-01 3.18381790e-05\n",
            " 2.00208020e-03 2.80267210e-03 1.05581330e-06 4.25770937e-04\n",
            " 6.18951559e-01 1.19086607e-07 1.29872269e-03 1.55643830e-02\n",
            " 9.70971107e-01 9.68162715e-01 9.69872296e-01 9.77271259e-01\n",
            " 9.77894723e-01 8.70356560e-01 5.49973965e-01 9.99668241e-01\n",
            " 9.99269783e-01 5.70097744e-01 9.69220221e-01 9.50131118e-01\n",
            " 7.80272543e-01 8.33783150e-01 5.20078480e-01 6.86974764e-01\n",
            " 9.94556189e-01 9.90438521e-01 9.72879291e-01 9.97254312e-01\n",
            " 9.99887824e-01 9.99561489e-01 9.99907613e-01 2.18158826e-01\n",
            " 6.36064649e-01 9.97110963e-01 9.74142611e-01 9.63139832e-01\n",
            " 1.67274438e-02 9.77157414e-01 9.40686226e-01 6.08433366e-01\n",
            " 3.08356404e-01 9.98469770e-01 9.99459326e-01 9.94094551e-01\n",
            " 1.79988578e-01 6.38864636e-01 5.26610672e-01 9.92624223e-01\n",
            " 7.33686090e-01 9.60847080e-01 4.38797086e-01 5.67213297e-01\n",
            " 5.73060989e-01 9.64773238e-01 9.81781483e-01 4.18428369e-02\n",
            " 3.48103374e-01 2.87667066e-01 2.05151692e-01 4.72167075e-01\n",
            " 9.94228959e-01 9.30910766e-01 1.29415140e-01 1.53501302e-01\n",
            " 9.90230501e-01 8.05493474e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 4 [0/107 (0%)]\tTrain Loss: 0.011628\n",
            "Train Epoch: 4 [4/107 (4%)]\tTrain Loss: 0.078287\n",
            "Train Epoch: 4 [8/107 (7%)]\tTrain Loss: 0.010084\n",
            "Train Epoch: 4 [12/107 (11%)]\tTrain Loss: 0.008119\n",
            "Train Epoch: 4 [16/107 (15%)]\tTrain Loss: 0.122219\n",
            "Train Epoch: 4 [20/107 (19%)]\tTrain Loss: 0.007679\n",
            "Train Epoch: 4 [24/107 (22%)]\tTrain Loss: 0.018563\n",
            "Train Epoch: 4 [28/107 (26%)]\tTrain Loss: 0.002916\n",
            "Train Epoch: 4 [32/107 (30%)]\tTrain Loss: 0.011439\n",
            "Train Epoch: 4 [36/107 (34%)]\tTrain Loss: 0.112224\n",
            "Train Epoch: 4 [40/107 (37%)]\tTrain Loss: 0.024786\n",
            "Train Epoch: 4 [44/107 (41%)]\tTrain Loss: 0.082899\n",
            "Train Epoch: 4 [48/107 (45%)]\tTrain Loss: 0.016243\n",
            "Train Epoch: 4 [52/107 (49%)]\tTrain Loss: 0.004302\n",
            "Train Epoch: 4 [56/107 (52%)]\tTrain Loss: 0.004948\n",
            "Train Epoch: 4 [60/107 (56%)]\tTrain Loss: 0.325734\n",
            "Train Epoch: 4 [64/107 (60%)]\tTrain Loss: 0.187210\n",
            "Train Epoch: 4 [68/107 (64%)]\tTrain Loss: 0.013561\n",
            "Train Epoch: 4 [72/107 (67%)]\tTrain Loss: 0.030017\n",
            "Train Epoch: 4 [76/107 (71%)]\tTrain Loss: 0.171160\n",
            "Train Epoch: 4 [80/107 (75%)]\tTrain Loss: 0.028450\n",
            "Train Epoch: 4 [84/107 (79%)]\tTrain Loss: 0.085183\n",
            "Train Epoch: 4 [88/107 (82%)]\tTrain Loss: 0.041973\n",
            "Train Epoch: 4 [92/107 (86%)]\tTrain Loss: 0.035031\n",
            "Train Epoch: 4 [96/107 (90%)]\tTrain Loss: 0.007714\n",
            "Train Epoch: 4 [100/107 (93%)]\tTrain Loss: 0.013245\n",
            "Train Epoch: 4 [104/107 (97%)]\tTrain Loss: 0.018385\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [4.46663611e-02 9.91562426e-01 7.94334233e-01 9.77535307e-01\n",
            " 6.33616000e-02 8.81876275e-02 9.79446411e-01 8.72138023e-01\n",
            " 7.71140084e-02 7.86120653e-01 4.11184490e-01 2.54338235e-01\n",
            " 7.97540605e-01 7.38920365e-03 1.76576935e-02 2.72147404e-03\n",
            " 2.56476104e-01 1.88063920e-01 4.95112780e-03 2.38387939e-02\n",
            " 1.44828394e-01 8.62190187e-01 7.81385839e-01 9.99034882e-01\n",
            " 9.23278987e-01 7.47035325e-01 9.95014131e-01 6.81851804e-02\n",
            " 1.58414710e-02 1.68789197e-02 1.08554237e-01 1.31494269e-01\n",
            " 6.77721202e-02 3.05561535e-03 5.11499122e-03 6.87111095e-02\n",
            " 2.74865553e-02 7.34002054e-01 2.23243326e-01 1.33140180e-02\n",
            " 5.52588562e-03 2.26683393e-02 2.32690617e-01 1.16566725e-01\n",
            " 3.16178322e-01 1.67431235e-01 8.41666400e-01 5.04718959e-01\n",
            " 6.76780283e-01 6.99381053e-01 9.72971261e-01 2.06678305e-04\n",
            " 4.37607197e-03 9.68988147e-03 2.40845566e-06 8.05345480e-04\n",
            " 3.64570856e-01 5.97652672e-07 8.67652649e-04 2.77696177e-02\n",
            " 9.99148965e-01 9.97215152e-01 9.98732984e-01 9.99122798e-01\n",
            " 8.54664564e-01 9.78855312e-01 9.96368527e-01 9.99975681e-01\n",
            " 9.99941111e-01 8.09864581e-01 9.98573899e-01 9.91033256e-01\n",
            " 9.32412267e-01 9.73612905e-01 7.60795414e-01 8.62169087e-01\n",
            " 9.99580801e-01 9.99735653e-01 9.99882340e-01 9.99411583e-01\n",
            " 9.99978542e-01 9.99852419e-01 9.99971747e-01 8.55246723e-01\n",
            " 9.83918309e-01 9.99982715e-01 9.98264253e-01 9.88778055e-01\n",
            " 1.69473756e-02 9.99113500e-01 9.99217272e-01 9.32670593e-01\n",
            " 8.57856691e-01 9.99968410e-01 9.99983430e-01 9.99753535e-01\n",
            " 5.11574149e-01 8.98906231e-01 9.56957936e-01 9.97814059e-01\n",
            " 8.45792890e-01 9.62436259e-01 5.53435802e-01 9.50141788e-01\n",
            " 5.65808952e-01 9.84979570e-01 9.95152593e-01 1.69560343e-01\n",
            " 1.02942683e-01 5.01363873e-01 5.37275791e-01 2.05368102e-01\n",
            " 9.99961853e-01 9.80621636e-01 3.28890979e-01 6.82670653e-01\n",
            " 9.99327421e-01 9.99088764e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 5 [0/107 (0%)]\tTrain Loss: 0.010853\n",
            "Train Epoch: 5 [4/107 (4%)]\tTrain Loss: 0.000996\n",
            "Train Epoch: 5 [8/107 (7%)]\tTrain Loss: 0.054348\n",
            "Train Epoch: 5 [12/107 (11%)]\tTrain Loss: 0.003891\n",
            "Train Epoch: 5 [16/107 (15%)]\tTrain Loss: 0.030329\n",
            "Train Epoch: 5 [20/107 (19%)]\tTrain Loss: 0.042301\n",
            "Train Epoch: 5 [24/107 (22%)]\tTrain Loss: 0.007385\n",
            "Train Epoch: 5 [28/107 (26%)]\tTrain Loss: 0.099103\n",
            "Train Epoch: 5 [32/107 (30%)]\tTrain Loss: 0.009418\n",
            "Train Epoch: 5 [36/107 (34%)]\tTrain Loss: 0.027289\n",
            "Train Epoch: 5 [40/107 (37%)]\tTrain Loss: 0.069208\n",
            "Train Epoch: 5 [44/107 (41%)]\tTrain Loss: 0.340306\n",
            "Train Epoch: 5 [48/107 (45%)]\tTrain Loss: 0.058889\n",
            "Train Epoch: 5 [52/107 (49%)]\tTrain Loss: 0.060594\n",
            "Train Epoch: 5 [56/107 (52%)]\tTrain Loss: 0.003673\n",
            "Train Epoch: 5 [60/107 (56%)]\tTrain Loss: 0.013858\n",
            "Train Epoch: 5 [64/107 (60%)]\tTrain Loss: 0.095201\n",
            "Train Epoch: 5 [68/107 (64%)]\tTrain Loss: 0.060991\n",
            "Train Epoch: 5 [72/107 (67%)]\tTrain Loss: 0.022217\n",
            "Train Epoch: 5 [76/107 (71%)]\tTrain Loss: 0.003640\n",
            "Train Epoch: 5 [80/107 (75%)]\tTrain Loss: 0.016445\n",
            "Train Epoch: 5 [84/107 (79%)]\tTrain Loss: 0.115510\n",
            "Train Epoch: 5 [88/107 (82%)]\tTrain Loss: 0.126883\n",
            "Train Epoch: 5 [92/107 (86%)]\tTrain Loss: 0.009672\n",
            "Train Epoch: 5 [96/107 (90%)]\tTrain Loss: 0.027649\n",
            "Train Epoch: 5 [100/107 (93%)]\tTrain Loss: 0.007346\n",
            "Train Epoch: 5 [104/107 (97%)]\tTrain Loss: 0.043098\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.35036302e-03 9.22426164e-01 5.75312734e-01 6.86349571e-01\n",
            " 1.04691577e-03 1.53191015e-03 7.16382504e-01 1.20336115e-01\n",
            " 4.93438030e-03 8.76583338e-01 8.37533832e-01 3.17431808e-01\n",
            " 3.22497368e-01 1.09032285e-03 2.29914527e-04 2.23744555e-05\n",
            " 3.16695422e-02 8.57479930e-01 1.16507560e-01 4.09321725e-01\n",
            " 4.24735248e-01 9.99084592e-01 9.92177665e-01 9.99579608e-01\n",
            " 9.99594033e-01 9.98386383e-01 9.98933971e-01 1.02934413e-01\n",
            " 4.47806455e-02 6.36984110e-02 9.79000330e-02 4.90568355e-02\n",
            " 6.45227078e-03 2.62551534e-04 9.78746917e-04 4.74455468e-02\n",
            " 8.00450668e-02 9.98352766e-01 9.28228199e-01 1.13091459e-02\n",
            " 6.14377623e-03 9.30899233e-02 7.59273529e-01 5.03202379e-01\n",
            " 9.03310835e-01 2.35626549e-01 5.94027758e-01 6.17692955e-02\n",
            " 1.32939562e-01 5.99068165e-01 8.63109171e-01 6.70229792e-06\n",
            " 1.81739437e-04 2.25005788e-03 3.17979776e-09 4.41384385e-04\n",
            " 3.66443783e-01 1.34232320e-10 2.66348856e-04 2.95495661e-03\n",
            " 9.99747813e-01 9.98880565e-01 9.99287188e-01 9.99844313e-01\n",
            " 9.94386315e-01 9.97374654e-01 9.95905638e-01 9.99999166e-01\n",
            " 9.99967098e-01 9.52108383e-01 9.87976849e-01 9.36660647e-01\n",
            " 7.19807446e-01 9.53709543e-01 9.33249652e-01 9.94317949e-01\n",
            " 9.94135082e-01 9.96917963e-01 9.99252498e-01 9.97447014e-01\n",
            " 9.99967694e-01 9.99594986e-01 9.99874353e-01 9.94296610e-01\n",
            " 9.92852271e-01 9.99490380e-01 9.99516964e-01 9.97939646e-01\n",
            " 1.91020668e-01 9.99730885e-01 9.98988092e-01 8.80638301e-01\n",
            " 8.50991666e-01 9.99963403e-01 9.99934435e-01 9.99589264e-01\n",
            " 9.36274052e-01 9.82552767e-01 9.95219648e-01 9.99692440e-01\n",
            " 9.01187062e-01 9.61107433e-01 9.60889339e-01 9.75687146e-01\n",
            " 4.22210634e-01 9.92465854e-01 9.91433859e-01 9.76933613e-02\n",
            " 8.81254792e-01 2.71019459e-01 6.62328601e-01 6.67272747e-01\n",
            " 9.99777973e-01 9.98396814e-01 6.76326752e-01 9.98436630e-01\n",
            " 9.99916673e-01 9.99353230e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 6 [0/107 (0%)]\tTrain Loss: 0.282824\n",
            "Train Epoch: 6 [4/107 (4%)]\tTrain Loss: 0.002581\n",
            "Train Epoch: 6 [8/107 (7%)]\tTrain Loss: 0.118907\n",
            "Train Epoch: 6 [12/107 (11%)]\tTrain Loss: 0.071989\n",
            "Train Epoch: 6 [16/107 (15%)]\tTrain Loss: 0.003480\n",
            "Train Epoch: 6 [20/107 (19%)]\tTrain Loss: 0.017704\n",
            "Train Epoch: 6 [24/107 (22%)]\tTrain Loss: 0.032114\n",
            "Train Epoch: 6 [28/107 (26%)]\tTrain Loss: 0.056965\n",
            "Train Epoch: 6 [32/107 (30%)]\tTrain Loss: 0.005559\n",
            "Train Epoch: 6 [36/107 (34%)]\tTrain Loss: 0.001161\n",
            "Train Epoch: 6 [40/107 (37%)]\tTrain Loss: 0.020774\n",
            "Train Epoch: 6 [44/107 (41%)]\tTrain Loss: 0.013110\n",
            "Train Epoch: 6 [48/107 (45%)]\tTrain Loss: 0.022003\n",
            "Train Epoch: 6 [52/107 (49%)]\tTrain Loss: 0.034006\n",
            "Train Epoch: 6 [56/107 (52%)]\tTrain Loss: 0.041933\n",
            "Train Epoch: 6 [60/107 (56%)]\tTrain Loss: 0.010856\n",
            "Train Epoch: 6 [64/107 (60%)]\tTrain Loss: 0.107329\n",
            "Train Epoch: 6 [68/107 (64%)]\tTrain Loss: 0.003628\n",
            "Train Epoch: 6 [72/107 (67%)]\tTrain Loss: 0.018468\n",
            "Train Epoch: 6 [76/107 (71%)]\tTrain Loss: 0.070233\n",
            "Train Epoch: 6 [80/107 (75%)]\tTrain Loss: 0.004089\n",
            "Train Epoch: 6 [84/107 (79%)]\tTrain Loss: 0.025918\n",
            "Train Epoch: 6 [88/107 (82%)]\tTrain Loss: 0.034612\n",
            "Train Epoch: 6 [92/107 (86%)]\tTrain Loss: 0.019083\n",
            "Train Epoch: 6 [96/107 (90%)]\tTrain Loss: 0.009085\n",
            "Train Epoch: 6 [100/107 (93%)]\tTrain Loss: 0.093225\n",
            "Train Epoch: 6 [104/107 (97%)]\tTrain Loss: 0.016760\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.75972635e-02 2.22819343e-01 1.14115462e-01 6.37512565e-01\n",
            " 7.56784230e-02 9.62381586e-02 1.09938063e-01 7.99012959e-01\n",
            " 4.65005897e-02 3.51376295e-01 4.21478510e-01 7.44785666e-01\n",
            " 5.46625495e-01 7.65622258e-02 2.06880607e-02 6.39236125e-04\n",
            " 2.99161896e-02 7.64835835e-01 2.88616959e-02 4.52182293e-02\n",
            " 2.57189751e-01 9.31015313e-01 7.88679361e-01 9.91687953e-01\n",
            " 9.09035504e-01 9.13561821e-01 9.84437227e-01 7.10394382e-01\n",
            " 7.77587369e-02 1.91468984e-01 9.39446688e-01 8.60246420e-01\n",
            " 7.91420221e-01 1.17689488e-03 6.89035058e-02 7.57783949e-01\n",
            " 4.01287585e-01 9.79653478e-01 9.10051107e-01 5.74558452e-02\n",
            " 3.57666090e-02 4.61770408e-02 9.32510376e-01 5.80044627e-01\n",
            " 6.78998113e-01 6.54446006e-01 8.15482259e-01 5.54490447e-01\n",
            " 5.88755906e-01 7.69171119e-01 9.08885837e-01 3.30836023e-03\n",
            " 3.35292108e-02 1.49520308e-01 5.46990777e-04 6.55713864e-03\n",
            " 8.19378138e-01 3.69103109e-05 2.07946282e-02 2.06903860e-01\n",
            " 9.98108029e-01 9.92514431e-01 9.96867716e-01 9.97436106e-01\n",
            " 9.73096788e-01 9.98757243e-01 9.98801112e-01 9.99117434e-01\n",
            " 9.99771893e-01 9.19958770e-01 9.70189452e-01 9.46242929e-01\n",
            " 9.46519971e-01 9.86887634e-01 9.12400544e-01 9.86193120e-01\n",
            " 9.58387554e-01 9.68087316e-01 9.94797170e-01 9.94944990e-01\n",
            " 9.99416232e-01 9.98157442e-01 9.99348104e-01 9.57316875e-01\n",
            " 9.61385787e-01 9.97716784e-01 9.79262888e-01 9.79694426e-01\n",
            " 2.39423677e-01 9.78718042e-01 9.53075469e-01 7.81031787e-01\n",
            " 9.36823368e-01 9.99551117e-01 9.97088015e-01 9.96730566e-01\n",
            " 8.31798196e-01 9.62427318e-01 7.94212937e-01 9.73949313e-01\n",
            " 7.25782394e-01 9.81507957e-01 7.25958288e-01 8.30883682e-01\n",
            " 3.20419967e-01 9.48807061e-01 9.44385469e-01 2.74301637e-02\n",
            " 1.44679144e-01 9.78912860e-02 6.22476526e-02 9.68911573e-02\n",
            " 9.66966033e-01 9.65718448e-01 5.53642631e-01 8.80460799e-01\n",
            " 9.96889412e-01 9.60227847e-01]\n",
            "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 7 [0/107 (0%)]\tTrain Loss: 0.059849\n",
            "Train Epoch: 7 [4/107 (4%)]\tTrain Loss: 0.054408\n",
            "Train Epoch: 7 [8/107 (7%)]\tTrain Loss: 0.006420\n",
            "Train Epoch: 7 [12/107 (11%)]\tTrain Loss: 0.032063\n",
            "Train Epoch: 7 [16/107 (15%)]\tTrain Loss: 0.230506\n",
            "Train Epoch: 7 [20/107 (19%)]\tTrain Loss: 0.035740\n",
            "Train Epoch: 7 [24/107 (22%)]\tTrain Loss: 0.021222\n",
            "Train Epoch: 7 [28/107 (26%)]\tTrain Loss: 0.060290\n",
            "Train Epoch: 7 [32/107 (30%)]\tTrain Loss: 0.003758\n",
            "Train Epoch: 7 [36/107 (34%)]\tTrain Loss: 0.120965\n",
            "Train Epoch: 7 [40/107 (37%)]\tTrain Loss: 0.002413\n",
            "Train Epoch: 7 [44/107 (41%)]\tTrain Loss: 0.024057\n",
            "Train Epoch: 7 [48/107 (45%)]\tTrain Loss: 0.012096\n",
            "Train Epoch: 7 [52/107 (49%)]\tTrain Loss: 0.043629\n",
            "Train Epoch: 7 [56/107 (52%)]\tTrain Loss: 0.011011\n",
            "Train Epoch: 7 [60/107 (56%)]\tTrain Loss: 0.001196\n",
            "Train Epoch: 7 [64/107 (60%)]\tTrain Loss: 0.006393\n",
            "Train Epoch: 7 [68/107 (64%)]\tTrain Loss: 0.113246\n",
            "Train Epoch: 7 [72/107 (67%)]\tTrain Loss: 0.063642\n",
            "Train Epoch: 7 [76/107 (71%)]\tTrain Loss: 0.013481\n",
            "Train Epoch: 7 [80/107 (75%)]\tTrain Loss: 0.244144\n",
            "Train Epoch: 7 [84/107 (79%)]\tTrain Loss: 0.378923\n",
            "Train Epoch: 7 [88/107 (82%)]\tTrain Loss: 0.010823\n",
            "Train Epoch: 7 [92/107 (86%)]\tTrain Loss: 0.248604\n",
            "Train Epoch: 7 [96/107 (90%)]\tTrain Loss: 0.009193\n",
            "Train Epoch: 7 [100/107 (93%)]\tTrain Loss: 0.009581\n",
            "Train Epoch: 7 [104/107 (97%)]\tTrain Loss: 0.009475\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [8.17378834e-02 7.53530204e-01 5.24050891e-01 7.25927949e-01\n",
            " 1.70977432e-02 1.02626413e-01 6.16522849e-01 7.72968769e-01\n",
            " 4.98044230e-02 5.02266526e-01 7.81120181e-01 5.51783681e-01\n",
            " 9.49899614e-01 1.11667320e-01 2.06696726e-02 4.47560888e-04\n",
            " 7.29820371e-01 3.62536423e-02 2.13189982e-02 1.13478951e-01\n",
            " 4.47246015e-01 9.03003395e-01 7.90764868e-01 9.82238889e-01\n",
            " 8.93497288e-01 9.32652652e-01 9.95109379e-01 1.03386223e-01\n",
            " 2.57108565e-02 2.50568837e-01 2.71348983e-01 2.33566850e-01\n",
            " 2.63661772e-01 1.31935196e-03 4.03679488e-03 9.39394608e-02\n",
            " 2.01210856e-01 8.97971094e-01 6.44290209e-01 2.17769351e-02\n",
            " 3.40418611e-03 1.97391398e-02 5.76310694e-01 2.82857239e-01\n",
            " 5.69908679e-01 3.45706493e-02 9.01390612e-01 5.09597659e-01\n",
            " 3.64310473e-01 3.92237306e-01 9.71804738e-01 1.80948206e-04\n",
            " 4.85786190e-03 1.08654443e-02 1.48639685e-06 8.66313744e-03\n",
            " 3.50046381e-02 2.40230543e-06 1.39864767e-03 4.48049568e-02\n",
            " 9.93693352e-01 9.73980308e-01 9.87916231e-01 9.95561123e-01\n",
            " 9.67222631e-01 9.99611437e-01 9.98899937e-01 9.99544203e-01\n",
            " 9.99896407e-01 6.94181442e-01 9.94392633e-01 9.15443122e-01\n",
            " 8.94959807e-01 9.68418419e-01 6.76777244e-01 9.65952218e-01\n",
            " 9.91442978e-01 9.92132843e-01 9.98965979e-01 9.99435484e-01\n",
            " 9.99942064e-01 9.99878764e-01 9.99974608e-01 9.15015340e-01\n",
            " 9.14440215e-01 9.97730196e-01 9.85822737e-01 9.87073183e-01\n",
            " 4.85331625e-01 9.97875214e-01 9.98673320e-01 9.46926534e-01\n",
            " 9.52873528e-01 9.99946237e-01 9.99843597e-01 9.99513030e-01\n",
            " 7.60272503e-01 7.73703218e-01 8.71569037e-01 9.95754361e-01\n",
            " 6.54002190e-01 9.26162243e-01 7.49574900e-01 8.00728142e-01\n",
            " 6.43033028e-01 9.98416543e-01 9.88566101e-01 9.60772112e-02\n",
            " 3.98344636e-01 3.17211092e-01 5.23841143e-01 1.63269117e-01\n",
            " 9.99840498e-01 9.97782767e-01 5.17950617e-02 6.57988846e-01\n",
            " 9.83213902e-01 9.73728657e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 8 [0/107 (0%)]\tTrain Loss: 0.082680\n",
            "Train Epoch: 8 [4/107 (4%)]\tTrain Loss: 0.018934\n",
            "Train Epoch: 8 [8/107 (7%)]\tTrain Loss: 0.006674\n",
            "Train Epoch: 8 [12/107 (11%)]\tTrain Loss: 0.009689\n",
            "Train Epoch: 8 [16/107 (15%)]\tTrain Loss: 0.005792\n",
            "Train Epoch: 8 [20/107 (19%)]\tTrain Loss: 0.010561\n",
            "Train Epoch: 8 [24/107 (22%)]\tTrain Loss: 0.211493\n",
            "Train Epoch: 8 [28/107 (26%)]\tTrain Loss: 0.005264\n",
            "Train Epoch: 8 [32/107 (30%)]\tTrain Loss: 0.126643\n",
            "Train Epoch: 8 [36/107 (34%)]\tTrain Loss: 0.002462\n",
            "Train Epoch: 8 [40/107 (37%)]\tTrain Loss: 0.028047\n",
            "Train Epoch: 8 [44/107 (41%)]\tTrain Loss: 0.052806\n",
            "Train Epoch: 8 [48/107 (45%)]\tTrain Loss: 0.007998\n",
            "Train Epoch: 8 [52/107 (49%)]\tTrain Loss: 0.111734\n",
            "Train Epoch: 8 [56/107 (52%)]\tTrain Loss: 0.002630\n",
            "Train Epoch: 8 [60/107 (56%)]\tTrain Loss: 0.003307\n",
            "Train Epoch: 8 [64/107 (60%)]\tTrain Loss: 0.021009\n",
            "Train Epoch: 8 [68/107 (64%)]\tTrain Loss: 0.104920\n",
            "Train Epoch: 8 [72/107 (67%)]\tTrain Loss: 0.000627\n",
            "Train Epoch: 8 [76/107 (71%)]\tTrain Loss: 0.026351\n",
            "Train Epoch: 8 [80/107 (75%)]\tTrain Loss: 0.060558\n",
            "Train Epoch: 8 [84/107 (79%)]\tTrain Loss: 0.023348\n",
            "Train Epoch: 8 [88/107 (82%)]\tTrain Loss: 0.001824\n",
            "Train Epoch: 8 [92/107 (86%)]\tTrain Loss: 0.131311\n",
            "Train Epoch: 8 [96/107 (90%)]\tTrain Loss: 0.004800\n",
            "Train Epoch: 8 [100/107 (93%)]\tTrain Loss: 0.155533\n",
            "Train Epoch: 8 [104/107 (97%)]\tTrain Loss: 0.007304\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.81878626e-01 9.10658002e-01 8.05198193e-01 7.76869059e-01\n",
            " 3.81706958e-03 6.83311448e-02 9.04751599e-01 8.10369909e-01\n",
            " 3.44273858e-02 6.51788652e-01 5.15458584e-01 5.67198813e-01\n",
            " 9.12546754e-01 1.60493772e-04 5.26573393e-04 1.12357304e-06\n",
            " 7.63402088e-04 7.16532350e-01 1.79844594e-03 9.92891565e-03\n",
            " 6.34086225e-03 9.81263399e-01 3.25724721e-01 9.92192447e-01\n",
            " 8.72644186e-01 7.77895570e-01 5.31242967e-01 9.74204112e-03\n",
            " 3.82454687e-04 6.52294420e-03 1.89010594e-02 1.69716077e-03\n",
            " 9.67980176e-03 6.61650438e-06 7.16574561e-07 1.46714216e-02\n",
            " 2.77270138e-01 9.93194699e-01 3.54345560e-01 5.14907515e-05\n",
            " 1.31556690e-05 9.91172783e-06 9.96847808e-01 2.61308819e-01\n",
            " 1.58821136e-01 2.37194356e-03 1.10275850e-01 1.92019921e-02\n",
            " 1.00629935e-02 2.00799853e-02 9.83215794e-02 6.63110102e-03\n",
            " 4.50781267e-03 8.43380019e-02 5.36701691e-06 1.06831193e-02\n",
            " 6.99399292e-01 1.88789854e-05 1.43536562e-02 4.93618613e-03\n",
            " 9.95949388e-01 9.84786332e-01 9.94249582e-01 9.96276677e-01\n",
            " 9.88170743e-01 9.98732865e-01 9.96417284e-01 9.92375791e-01\n",
            " 9.99785244e-01 2.21487917e-02 6.41255438e-01 9.32633355e-02\n",
            " 4.95273352e-01 2.26403654e-01 7.77814388e-02 9.82804060e-01\n",
            " 9.89728570e-01 9.97664213e-01 9.93239403e-01 8.62343609e-01\n",
            " 9.97681975e-01 6.26552284e-01 9.86231625e-01 9.95342135e-01\n",
            " 9.90566790e-01 9.99943256e-01 9.86577868e-01 8.57274294e-01\n",
            " 5.33637730e-03 8.50171447e-02 2.14678124e-01 9.79369581e-01\n",
            " 9.53203440e-01 9.99860168e-01 9.99373496e-01 9.99097109e-01\n",
            " 6.06771111e-01 9.79633451e-01 9.63306487e-01 6.16268635e-01\n",
            " 7.97608733e-01 9.72280324e-01 8.44415009e-01 9.65463698e-01\n",
            " 9.01026368e-01 9.97045219e-01 9.97466326e-01 6.28064678e-04\n",
            " 2.24022404e-03 1.56089485e-01 5.58218844e-02 4.09151912e-02\n",
            " 9.94533539e-01 5.42116582e-01 1.23180344e-03 4.30278212e-01\n",
            " 9.99869943e-01 9.98799443e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 9 [0/107 (0%)]\tTrain Loss: 0.005155\n",
            "Train Epoch: 9 [4/107 (4%)]\tTrain Loss: 0.013996\n",
            "Train Epoch: 9 [8/107 (7%)]\tTrain Loss: 0.013314\n",
            "Train Epoch: 9 [12/107 (11%)]\tTrain Loss: 0.209945\n",
            "Train Epoch: 9 [16/107 (15%)]\tTrain Loss: 0.010926\n",
            "Train Epoch: 9 [20/107 (19%)]\tTrain Loss: 0.041597\n",
            "Train Epoch: 9 [24/107 (22%)]\tTrain Loss: 0.316615\n",
            "Train Epoch: 9 [28/107 (26%)]\tTrain Loss: 0.000834\n",
            "Train Epoch: 9 [32/107 (30%)]\tTrain Loss: 0.028830\n",
            "Train Epoch: 9 [36/107 (34%)]\tTrain Loss: 0.011932\n",
            "Train Epoch: 9 [40/107 (37%)]\tTrain Loss: 0.005744\n",
            "Train Epoch: 9 [44/107 (41%)]\tTrain Loss: 0.005907\n",
            "Train Epoch: 9 [48/107 (45%)]\tTrain Loss: 0.004076\n",
            "Train Epoch: 9 [52/107 (49%)]\tTrain Loss: 0.388460\n",
            "Train Epoch: 9 [56/107 (52%)]\tTrain Loss: 0.013113\n",
            "Train Epoch: 9 [60/107 (56%)]\tTrain Loss: 0.001903\n",
            "Train Epoch: 9 [64/107 (60%)]\tTrain Loss: 0.002242\n",
            "Train Epoch: 9 [68/107 (64%)]\tTrain Loss: 0.004913\n",
            "Train Epoch: 9 [72/107 (67%)]\tTrain Loss: 0.017351\n",
            "Train Epoch: 9 [76/107 (71%)]\tTrain Loss: 0.004019\n",
            "Train Epoch: 9 [80/107 (75%)]\tTrain Loss: 0.014251\n",
            "Train Epoch: 9 [84/107 (79%)]\tTrain Loss: 0.027696\n",
            "Train Epoch: 9 [88/107 (82%)]\tTrain Loss: 0.013570\n",
            "Train Epoch: 9 [92/107 (86%)]\tTrain Loss: 0.024659\n",
            "Train Epoch: 9 [96/107 (90%)]\tTrain Loss: 0.047358\n",
            "Train Epoch: 9 [100/107 (93%)]\tTrain Loss: 0.012138\n",
            "Train Epoch: 9 [104/107 (97%)]\tTrain Loss: 0.058143\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.75028814e-02 9.45723295e-01 9.02199030e-01 5.68637997e-02\n",
            " 6.15268364e-04 5.42393280e-03 9.16659534e-01 5.41521125e-02\n",
            " 7.90567603e-03 9.92052674e-01 5.93398929e-01 8.28593373e-01\n",
            " 6.71924651e-01 2.21380815e-02 9.14344843e-03 8.39772343e-04\n",
            " 1.35023408e-02 1.73962656e-02 2.21528169e-02 3.86149406e-01\n",
            " 5.81896484e-01 9.92229998e-01 9.35619175e-01 9.84821141e-01\n",
            " 9.93527472e-01 9.02474344e-01 7.29280293e-01 5.41989133e-02\n",
            " 1.17383143e-02 2.09616035e-01 8.07448998e-02 1.12776913e-01\n",
            " 1.31647468e-01 6.62457373e-04 5.30104153e-04 6.63192384e-03\n",
            " 5.68333045e-02 9.30264831e-01 4.13371474e-01 5.20502441e-02\n",
            " 3.04004662e-02 1.11791074e-01 5.76356947e-01 5.13333417e-02\n",
            " 3.33206087e-01 1.85835481e-01 1.43441319e-01 2.30342764e-02\n",
            " 6.90848902e-02 3.88454676e-01 4.86695558e-01 2.87096482e-04\n",
            " 4.92977502e-04 6.50743162e-03 1.36065461e-08 1.44922151e-03\n",
            " 1.75059736e-02 7.30302432e-08 3.53302137e-04 1.09019584e-03\n",
            " 9.34068859e-01 9.08525348e-01 9.81626511e-01 9.82258439e-01\n",
            " 8.55507672e-01 9.94900525e-01 9.61336076e-01 9.98557985e-01\n",
            " 9.94238615e-01 5.60958683e-01 9.14402425e-01 7.18782663e-01\n",
            " 1.21424392e-01 5.29888093e-01 2.39231393e-01 7.31267691e-01\n",
            " 9.80874121e-01 9.94787335e-01 9.48298633e-01 7.84485579e-01\n",
            " 9.89632368e-01 8.95765841e-01 9.85424221e-01 9.79597390e-01\n",
            " 9.88369465e-01 9.99252498e-01 9.72183883e-01 9.71883714e-01\n",
            " 5.45367189e-02 9.17373180e-01 9.79785264e-01 8.11385334e-01\n",
            " 6.37930393e-01 9.99722183e-01 9.96922433e-01 9.97799456e-01\n",
            " 7.33599424e-01 6.68369353e-01 9.21854258e-01 9.37464118e-01\n",
            " 7.81829894e-01 9.32051420e-01 6.27745271e-01 7.19418645e-01\n",
            " 1.58602670e-01 9.67993200e-01 8.78162801e-01 7.52487108e-02\n",
            " 5.58658540e-02 2.20455658e-02 1.48406327e-01 1.14641692e-02\n",
            " 9.79859650e-01 9.82641697e-01 1.02590742e-02 5.11497259e-01\n",
            " 9.96924341e-01 9.97641563e-01]\n",
            "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 10 [0/107 (0%)]\tTrain Loss: 0.010369\n",
            "Train Epoch: 10 [4/107 (4%)]\tTrain Loss: 0.010926\n",
            "Train Epoch: 10 [8/107 (7%)]\tTrain Loss: 0.005886\n",
            "Train Epoch: 10 [12/107 (11%)]\tTrain Loss: 0.001786\n",
            "Train Epoch: 10 [16/107 (15%)]\tTrain Loss: 0.009449\n",
            "Train Epoch: 10 [20/107 (19%)]\tTrain Loss: 0.099951\n",
            "Train Epoch: 10 [24/107 (22%)]\tTrain Loss: 0.004797\n",
            "Train Epoch: 10 [28/107 (26%)]\tTrain Loss: 0.004352\n",
            "Train Epoch: 10 [32/107 (30%)]\tTrain Loss: 0.010555\n",
            "Train Epoch: 10 [36/107 (34%)]\tTrain Loss: 0.029393\n",
            "Train Epoch: 10 [40/107 (37%)]\tTrain Loss: 0.087108\n",
            "Train Epoch: 10 [44/107 (41%)]\tTrain Loss: 0.018726\n",
            "Train Epoch: 10 [48/107 (45%)]\tTrain Loss: 0.001815\n",
            "Train Epoch: 10 [52/107 (49%)]\tTrain Loss: 0.067907\n",
            "Train Epoch: 10 [56/107 (52%)]\tTrain Loss: 0.289237\n",
            "Train Epoch: 10 [60/107 (56%)]\tTrain Loss: 0.002627\n",
            "Train Epoch: 10 [64/107 (60%)]\tTrain Loss: 0.007378\n",
            "Train Epoch: 10 [68/107 (64%)]\tTrain Loss: 0.067659\n",
            "Train Epoch: 10 [72/107 (67%)]\tTrain Loss: 0.045586\n",
            "Train Epoch: 10 [76/107 (71%)]\tTrain Loss: 0.002416\n",
            "Train Epoch: 10 [80/107 (75%)]\tTrain Loss: 0.011398\n",
            "Train Epoch: 10 [84/107 (79%)]\tTrain Loss: 0.003242\n",
            "Train Epoch: 10 [88/107 (82%)]\tTrain Loss: 0.007250\n",
            "Train Epoch: 10 [92/107 (86%)]\tTrain Loss: 0.088478\n",
            "Train Epoch: 10 [96/107 (90%)]\tTrain Loss: 0.010206\n",
            "Train Epoch: 10 [100/107 (93%)]\tTrain Loss: 0.036130\n",
            "Train Epoch: 10 [104/107 (97%)]\tTrain Loss: 0.026728\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [7.07108229e-02 8.73472333e-01 1.31940350e-01 4.36032563e-01\n",
            " 2.19835155e-02 1.24842832e-02 6.20132327e-01 3.58043492e-01\n",
            " 2.70929690e-02 8.64136279e-01 3.00956871e-02 2.40653872e-01\n",
            " 4.45995450e-01 2.18403004e-02 1.08177296e-03 8.29222699e-05\n",
            " 8.61658752e-02 5.31906247e-01 3.77985463e-02 4.05578911e-01\n",
            " 8.75618398e-01 9.93190229e-01 9.95633423e-01 9.99490857e-01\n",
            " 9.55497622e-01 9.97969210e-01 9.98763442e-01 8.63992125e-02\n",
            " 3.73728834e-02 5.01943938e-02 9.92708355e-02 2.54623204e-01\n",
            " 2.58776456e-01 1.91229177e-04 2.14054016e-03 1.09956497e-02\n",
            " 6.87779561e-02 9.79054093e-01 4.39367682e-01 4.95088398e-02\n",
            " 6.78687245e-02 1.59094501e-02 8.60580027e-01 2.07064763e-01\n",
            " 5.43551803e-01 5.56693494e-01 6.90056801e-01 2.79940844e-01\n",
            " 7.51381099e-01 9.38626230e-01 8.60511065e-01 6.69487235e-07\n",
            " 1.63793436e-06 9.70235839e-03 1.34082158e-13 9.67915275e-06\n",
            " 8.57470185e-02 1.77990841e-13 9.86327996e-06 2.07988243e-03\n",
            " 9.99334037e-01 9.99381423e-01 9.98749733e-01 9.99017239e-01\n",
            " 9.94825363e-01 9.94000196e-01 9.96714711e-01 9.99947071e-01\n",
            " 9.99951482e-01 7.19190359e-01 9.93660808e-01 9.44777966e-01\n",
            " 9.49018478e-01 9.68170881e-01 9.20561433e-01 9.92664516e-01\n",
            " 9.84890759e-01 9.95063484e-01 9.99472558e-01 9.95815337e-01\n",
            " 9.99924064e-01 9.99483943e-01 9.99915600e-01 9.43725288e-01\n",
            " 9.97208655e-01 9.99950886e-01 9.99727905e-01 9.97794390e-01\n",
            " 1.85887784e-01 9.93769944e-01 9.97400999e-01 7.32201755e-01\n",
            " 4.84242141e-01 9.99961853e-01 9.99817789e-01 9.99310732e-01\n",
            " 6.58234417e-01 9.95157659e-01 9.95960176e-01 9.94022191e-01\n",
            " 9.73900795e-01 9.85909700e-01 3.88362855e-01 9.52954829e-01\n",
            " 9.13028479e-01 9.97198343e-01 9.97072935e-01 3.88560258e-02\n",
            " 1.74843624e-01 5.03152460e-02 1.43978775e-01 5.43406978e-03\n",
            " 9.98549163e-01 9.88328457e-01 7.39417255e-01 9.55171764e-01\n",
            " 9.99294877e-01 9.95016277e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "TP= 51 TN= 42 FN= 7 FP= 18\n",
            "TP+FP 69\n",
            "precision 0.7391304347826086\n",
            "recall 0.8793103448275862\n",
            "F1 0.8031496062992126\n",
            "acc 0.788135593220339\n",
            "AUCp 0.7896551724137931\n",
            "AUC 0.8841954022988506\n",
            "\n",
            " The epoch is 10, average recall: 0.8793, average precision: 0.7391,average F1: 0.8031, average accuracy: 0.7881, average AUC: 0.8842\n",
            "Train Epoch: 11 [0/107 (0%)]\tTrain Loss: 0.029295\n",
            "Train Epoch: 11 [4/107 (4%)]\tTrain Loss: 0.043115\n",
            "Train Epoch: 11 [8/107 (7%)]\tTrain Loss: 0.015339\n",
            "Train Epoch: 11 [12/107 (11%)]\tTrain Loss: 0.046394\n",
            "Train Epoch: 11 [16/107 (15%)]\tTrain Loss: 0.003049\n",
            "Train Epoch: 11 [20/107 (19%)]\tTrain Loss: 0.002366\n",
            "Train Epoch: 11 [24/107 (22%)]\tTrain Loss: 0.007584\n",
            "Train Epoch: 11 [28/107 (26%)]\tTrain Loss: 0.043195\n",
            "Train Epoch: 11 [32/107 (30%)]\tTrain Loss: 0.085055\n",
            "Train Epoch: 11 [36/107 (34%)]\tTrain Loss: 0.054224\n",
            "Train Epoch: 11 [40/107 (37%)]\tTrain Loss: 0.007856\n",
            "Train Epoch: 11 [44/107 (41%)]\tTrain Loss: 0.031836\n",
            "Train Epoch: 11 [48/107 (45%)]\tTrain Loss: 0.009290\n",
            "Train Epoch: 11 [52/107 (49%)]\tTrain Loss: 0.037382\n",
            "Train Epoch: 11 [56/107 (52%)]\tTrain Loss: 0.044822\n",
            "Train Epoch: 11 [60/107 (56%)]\tTrain Loss: 0.046713\n",
            "Train Epoch: 11 [64/107 (60%)]\tTrain Loss: 0.005140\n",
            "Train Epoch: 11 [68/107 (64%)]\tTrain Loss: 0.004581\n",
            "Train Epoch: 11 [72/107 (67%)]\tTrain Loss: 0.026976\n",
            "Train Epoch: 11 [76/107 (71%)]\tTrain Loss: 0.000650\n",
            "Train Epoch: 11 [80/107 (75%)]\tTrain Loss: 0.112628\n",
            "Train Epoch: 11 [84/107 (79%)]\tTrain Loss: 0.046842\n",
            "Train Epoch: 11 [88/107 (82%)]\tTrain Loss: 0.006654\n",
            "Train Epoch: 11 [92/107 (86%)]\tTrain Loss: 0.029800\n",
            "Train Epoch: 11 [96/107 (90%)]\tTrain Loss: 0.007837\n",
            "Train Epoch: 11 [100/107 (93%)]\tTrain Loss: 0.075511\n",
            "Train Epoch: 11 [104/107 (97%)]\tTrain Loss: 0.007429\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [8.24245065e-02 9.84076679e-01 5.82152963e-01 5.76375127e-01\n",
            " 1.96981132e-02 3.01556028e-02 9.40528870e-01 6.83344007e-01\n",
            " 2.10937746e-02 9.68850493e-01 3.92411649e-01 6.43092752e-01\n",
            " 8.81995559e-01 3.83994520e-01 1.48027435e-01 3.88827687e-03\n",
            " 2.72861570e-02 9.20566320e-01 5.85562475e-02 8.65230143e-01\n",
            " 9.56052482e-01 9.89956796e-01 9.95900095e-01 9.97706294e-01\n",
            " 9.66695249e-01 9.97737885e-01 9.94408011e-01 3.63004565e-01\n",
            " 4.39553112e-02 2.15993762e-01 7.27400661e-01 9.43209827e-01\n",
            " 8.24406803e-01 5.35806641e-03 1.04027605e-02 1.70036219e-02\n",
            " 6.08232953e-02 9.92172718e-01 7.46999860e-01 5.03130630e-02\n",
            " 6.38329834e-02 3.23617272e-02 8.53581131e-01 2.63942093e-01\n",
            " 8.49045336e-01 6.71457648e-01 9.38958168e-01 7.50668049e-01\n",
            " 9.58390951e-01 9.53881681e-01 9.95480418e-01 1.71710744e-05\n",
            " 7.23020139e-06 2.32480536e-03 1.27128599e-10 2.72592642e-05\n",
            " 7.35886618e-02 7.87027735e-11 7.32822764e-06 2.49881647e-03\n",
            " 9.99567926e-01 9.99663591e-01 9.99791563e-01 9.99742925e-01\n",
            " 9.99206245e-01 9.97797847e-01 9.97853100e-01 9.99888182e-01\n",
            " 9.99533296e-01 9.72373843e-01 9.98829305e-01 9.97494936e-01\n",
            " 9.83374715e-01 9.97048676e-01 9.91978049e-01 9.99751627e-01\n",
            " 9.98628378e-01 9.99387264e-01 9.99602258e-01 9.98730958e-01\n",
            " 9.99831080e-01 9.99841690e-01 9.99860525e-01 9.85424697e-01\n",
            " 9.97098804e-01 9.99947429e-01 9.99274671e-01 9.99199331e-01\n",
            " 3.07590604e-01 9.82217968e-01 9.60382938e-01 9.44352508e-01\n",
            " 8.29982042e-01 9.98805523e-01 9.96585250e-01 9.77897823e-01\n",
            " 6.25340223e-01 9.92122710e-01 9.92718339e-01 9.88241017e-01\n",
            " 9.70817983e-01 9.98717666e-01 7.14939713e-01 9.10697997e-01\n",
            " 7.90359199e-01 9.94178414e-01 9.95442867e-01 6.57021552e-02\n",
            " 4.86961454e-01 1.65354699e-01 2.09626332e-01 7.54940659e-02\n",
            " 9.78855431e-01 9.89318430e-01 8.67451549e-01 9.56180632e-01\n",
            " 9.99130905e-01 9.89422381e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 12 [0/107 (0%)]\tTrain Loss: 0.010360\n",
            "Train Epoch: 12 [4/107 (4%)]\tTrain Loss: 0.032495\n",
            "Train Epoch: 12 [8/107 (7%)]\tTrain Loss: 0.003756\n",
            "Train Epoch: 12 [12/107 (11%)]\tTrain Loss: 0.006280\n",
            "Train Epoch: 12 [16/107 (15%)]\tTrain Loss: 0.565045\n",
            "Train Epoch: 12 [20/107 (19%)]\tTrain Loss: 0.135706\n",
            "Train Epoch: 12 [24/107 (22%)]\tTrain Loss: 0.013697\n",
            "Train Epoch: 12 [28/107 (26%)]\tTrain Loss: 0.100397\n",
            "Train Epoch: 12 [32/107 (30%)]\tTrain Loss: 0.001019\n",
            "Train Epoch: 12 [36/107 (34%)]\tTrain Loss: 0.002533\n",
            "Train Epoch: 12 [40/107 (37%)]\tTrain Loss: 0.008124\n",
            "Train Epoch: 12 [44/107 (41%)]\tTrain Loss: 0.237113\n",
            "Train Epoch: 12 [48/107 (45%)]\tTrain Loss: 0.012209\n",
            "Train Epoch: 12 [52/107 (49%)]\tTrain Loss: 0.002570\n",
            "Train Epoch: 12 [56/107 (52%)]\tTrain Loss: 0.002520\n",
            "Train Epoch: 12 [60/107 (56%)]\tTrain Loss: 0.005228\n",
            "Train Epoch: 12 [64/107 (60%)]\tTrain Loss: 0.242370\n",
            "Train Epoch: 12 [68/107 (64%)]\tTrain Loss: 0.004787\n",
            "Train Epoch: 12 [72/107 (67%)]\tTrain Loss: 0.028284\n",
            "Train Epoch: 12 [76/107 (71%)]\tTrain Loss: 0.005687\n",
            "Train Epoch: 12 [80/107 (75%)]\tTrain Loss: 0.021893\n",
            "Train Epoch: 12 [84/107 (79%)]\tTrain Loss: 0.012097\n",
            "Train Epoch: 12 [88/107 (82%)]\tTrain Loss: 0.060871\n",
            "Train Epoch: 12 [92/107 (86%)]\tTrain Loss: 0.024203\n",
            "Train Epoch: 12 [96/107 (90%)]\tTrain Loss: 0.036262\n",
            "Train Epoch: 12 [100/107 (93%)]\tTrain Loss: 0.001800\n",
            "Train Epoch: 12 [104/107 (97%)]\tTrain Loss: 0.037554\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.91560345e-04 7.33658612e-01 1.88644826e-01 6.21552728e-02\n",
            " 2.28470293e-04 2.81893229e-03 5.92572987e-01 8.32643062e-02\n",
            " 8.56792904e-04 8.88288558e-01 5.26346326e-01 3.70073915e-01\n",
            " 9.25408006e-01 2.77588572e-02 2.88151699e-04 1.31539171e-04\n",
            " 2.50436701e-02 4.77637470e-01 4.17236499e-02 4.31031317e-01\n",
            " 6.49903059e-01 9.97570336e-01 9.24818218e-01 9.98731673e-01\n",
            " 9.95151997e-01 9.81574118e-01 9.75883067e-01 3.22502013e-03\n",
            " 6.51121233e-03 3.44815031e-02 1.37907022e-03 1.78647369e-01\n",
            " 2.11453363e-02 1.11887341e-04 8.17881883e-05 1.06434338e-02\n",
            " 4.68157977e-03 7.62390912e-01 1.86476767e-01 6.62759319e-03\n",
            " 8.96359608e-03 1.16966907e-02 8.57645571e-01 1.23576606e-02\n",
            " 1.92990988e-01 2.99100950e-03 1.70917660e-02 3.34933400e-03\n",
            " 8.12421814e-02 1.82512298e-01 5.40681839e-01 7.50492468e-09\n",
            " 2.98319911e-08 5.13717168e-06 2.66324565e-15 1.66933532e-07\n",
            " 9.30412571e-05 6.01464332e-15 1.61677676e-07 2.65798326e-06\n",
            " 9.83438551e-01 9.61905658e-01 9.82991397e-01 9.71308172e-01\n",
            " 6.41037643e-01 9.82610166e-01 9.46988642e-01 9.99546111e-01\n",
            " 9.98072267e-01 7.19024301e-01 7.76541889e-01 6.11303627e-01\n",
            " 6.37385622e-02 4.96805727e-01 3.79388273e-01 9.40391779e-01\n",
            " 8.99532259e-01 9.71026659e-01 9.46528316e-01 8.21623802e-01\n",
            " 9.92896855e-01 9.76622462e-01 9.99054492e-01 9.84128177e-01\n",
            " 8.67184818e-01 9.76381361e-01 9.85086083e-01 9.92113113e-01\n",
            " 2.39175186e-01 9.98685300e-01 9.77836847e-01 3.97227019e-01\n",
            " 8.78773853e-02 9.99921083e-01 9.95702326e-01 9.98772085e-01\n",
            " 1.07964510e-02 9.73956585e-01 9.80057955e-01 9.65009689e-01\n",
            " 9.93173897e-01 9.46138322e-01 7.08042681e-01 4.66387868e-01\n",
            " 4.85871851e-01 8.53189290e-01 9.78709698e-01 1.51335280e-02\n",
            " 1.42284334e-01 2.22825492e-03 2.21911687e-02 4.56670262e-02\n",
            " 9.93505716e-01 9.94728148e-01 3.17728966e-01 8.45652461e-01\n",
            " 9.99717176e-01 9.87122536e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 13 [0/107 (0%)]\tTrain Loss: 0.012321\n",
            "Train Epoch: 13 [4/107 (4%)]\tTrain Loss: 0.012979\n",
            "Train Epoch: 13 [8/107 (7%)]\tTrain Loss: 0.007407\n",
            "Train Epoch: 13 [12/107 (11%)]\tTrain Loss: 0.018666\n",
            "Train Epoch: 13 [16/107 (15%)]\tTrain Loss: 0.000447\n",
            "Train Epoch: 13 [20/107 (19%)]\tTrain Loss: 0.062522\n",
            "Train Epoch: 13 [24/107 (22%)]\tTrain Loss: 0.149558\n",
            "Train Epoch: 13 [28/107 (26%)]\tTrain Loss: 0.056311\n",
            "Train Epoch: 13 [32/107 (30%)]\tTrain Loss: 0.003037\n",
            "Train Epoch: 13 [36/107 (34%)]\tTrain Loss: 0.001737\n",
            "Train Epoch: 13 [40/107 (37%)]\tTrain Loss: 0.002574\n",
            "Train Epoch: 13 [44/107 (41%)]\tTrain Loss: 0.001934\n",
            "Train Epoch: 13 [48/107 (45%)]\tTrain Loss: 0.009208\n",
            "Train Epoch: 13 [52/107 (49%)]\tTrain Loss: 0.012921\n",
            "Train Epoch: 13 [56/107 (52%)]\tTrain Loss: 0.006258\n",
            "Train Epoch: 13 [60/107 (56%)]\tTrain Loss: 0.001295\n",
            "Train Epoch: 13 [64/107 (60%)]\tTrain Loss: 0.002451\n",
            "Train Epoch: 13 [68/107 (64%)]\tTrain Loss: 0.062632\n",
            "Train Epoch: 13 [72/107 (67%)]\tTrain Loss: 0.001439\n",
            "Train Epoch: 13 [76/107 (71%)]\tTrain Loss: 0.002388\n",
            "Train Epoch: 13 [80/107 (75%)]\tTrain Loss: 0.004430\n",
            "Train Epoch: 13 [84/107 (79%)]\tTrain Loss: 0.008579\n",
            "Train Epoch: 13 [88/107 (82%)]\tTrain Loss: 0.268751\n",
            "Train Epoch: 13 [92/107 (86%)]\tTrain Loss: 0.008890\n",
            "Train Epoch: 13 [96/107 (90%)]\tTrain Loss: 0.008375\n",
            "Train Epoch: 13 [100/107 (93%)]\tTrain Loss: 0.000820\n",
            "Train Epoch: 13 [104/107 (97%)]\tTrain Loss: 0.055629\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [9.54756327e-03 9.83694375e-01 9.18701768e-01 3.33139330e-01\n",
            " 2.34494801e-03 4.67622019e-02 9.74778473e-01 4.95250672e-02\n",
            " 3.16207223e-02 9.32744205e-01 7.01476276e-01 3.87151688e-01\n",
            " 9.24082458e-01 2.27202094e-04 2.85640475e-04 1.17330012e-04\n",
            " 3.30637151e-04 9.02086437e-01 8.64808485e-02 7.29766011e-01\n",
            " 8.38211715e-01 9.94997144e-01 9.97184336e-01 9.98421550e-01\n",
            " 9.22652602e-01 9.55193996e-01 6.50893152e-01 7.17116566e-03\n",
            " 2.43299035e-03 3.61719541e-02 5.40912105e-03 3.92587371e-02\n",
            " 1.43732261e-02 3.18748789e-05 1.45091208e-05 2.65008101e-04\n",
            " 1.25103001e-03 5.45455873e-01 2.56188530e-02 1.57170335e-03\n",
            " 6.49464130e-03 1.71027146e-03 4.92393732e-01 8.24764669e-02\n",
            " 5.62556446e-01 2.29080319e-01 1.30238593e-01 7.74625130e-03\n",
            " 3.60962659e-01 5.60185313e-01 8.97825897e-01 1.36034237e-13\n",
            " 7.63809682e-10 4.35796643e-08 4.76897787e-26 2.10433337e-09\n",
            " 8.69610801e-07 8.86562117e-25 8.78532316e-11 9.85519946e-05\n",
            " 9.98965383e-01 9.99458492e-01 9.99805510e-01 9.99373257e-01\n",
            " 9.81640637e-01 9.80613112e-01 9.83435333e-01 9.99981880e-01\n",
            " 9.99136031e-01 8.45729709e-01 9.80319977e-01 7.87569761e-01\n",
            " 3.15655500e-01 9.76582825e-01 9.41412985e-01 9.93220568e-01\n",
            " 9.98735368e-01 9.99490023e-01 9.98122513e-01 9.68878031e-01\n",
            " 9.98355448e-01 9.97784674e-01 9.99857903e-01 9.86892283e-01\n",
            " 9.94743586e-01 9.85657215e-01 9.99666452e-01 9.99648690e-01\n",
            " 4.96673724e-03 5.86869493e-02 6.40966952e-01 8.42523098e-01\n",
            " 8.68586957e-01 9.98342872e-01 9.31534410e-01 9.44103539e-01\n",
            " 1.07171498e-01 7.31286526e-01 8.19264710e-01 9.09341276e-01\n",
            " 8.32963645e-01 9.92627561e-01 5.09200156e-01 8.66310477e-01\n",
            " 2.44788349e-01 9.88010943e-01 9.98019814e-01 1.52736565e-03\n",
            " 1.88816004e-04 4.57262708e-04 6.47049164e-04 5.71636483e-04\n",
            " 6.05878294e-01 9.61002707e-01 2.55722195e-01 7.61656761e-01\n",
            " 9.90432084e-01 9.75911796e-01]\n",
            "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 14 [0/107 (0%)]\tTrain Loss: 0.018711\n",
            "Train Epoch: 14 [4/107 (4%)]\tTrain Loss: 0.026478\n",
            "Train Epoch: 14 [8/107 (7%)]\tTrain Loss: 0.003288\n",
            "Train Epoch: 14 [12/107 (11%)]\tTrain Loss: 0.002882\n",
            "Train Epoch: 14 [16/107 (15%)]\tTrain Loss: 0.006578\n",
            "Train Epoch: 14 [20/107 (19%)]\tTrain Loss: 0.000686\n",
            "Train Epoch: 14 [24/107 (22%)]\tTrain Loss: 0.003088\n",
            "Train Epoch: 14 [28/107 (26%)]\tTrain Loss: 0.050696\n",
            "Train Epoch: 14 [32/107 (30%)]\tTrain Loss: 0.002148\n",
            "Train Epoch: 14 [36/107 (34%)]\tTrain Loss: 0.014425\n",
            "Train Epoch: 14 [40/107 (37%)]\tTrain Loss: 0.278708\n",
            "Train Epoch: 14 [44/107 (41%)]\tTrain Loss: 0.005634\n",
            "Train Epoch: 14 [48/107 (45%)]\tTrain Loss: 0.015596\n",
            "Train Epoch: 14 [52/107 (49%)]\tTrain Loss: 0.006197\n",
            "Train Epoch: 14 [56/107 (52%)]\tTrain Loss: 0.009430\n",
            "Train Epoch: 14 [60/107 (56%)]\tTrain Loss: 0.007582\n",
            "Train Epoch: 14 [64/107 (60%)]\tTrain Loss: 0.004244\n",
            "Train Epoch: 14 [68/107 (64%)]\tTrain Loss: 0.004208\n",
            "Train Epoch: 14 [72/107 (67%)]\tTrain Loss: 0.018742\n",
            "Train Epoch: 14 [76/107 (71%)]\tTrain Loss: 0.112068\n",
            "Train Epoch: 14 [80/107 (75%)]\tTrain Loss: 0.006206\n",
            "Train Epoch: 14 [84/107 (79%)]\tTrain Loss: 0.013554\n",
            "Train Epoch: 14 [88/107 (82%)]\tTrain Loss: 0.002236\n",
            "Train Epoch: 14 [92/107 (86%)]\tTrain Loss: 0.002658\n",
            "Train Epoch: 14 [96/107 (90%)]\tTrain Loss: 0.044995\n",
            "Train Epoch: 14 [100/107 (93%)]\tTrain Loss: 0.028997\n",
            "Train Epoch: 14 [104/107 (97%)]\tTrain Loss: 0.002914\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.19811865e-04 8.93844485e-01 2.27962509e-02 6.43812791e-02\n",
            " 2.84838537e-03 1.38368952e-04 7.96013176e-01 3.09120808e-02\n",
            " 1.47902465e-04 1.25728488e-01 7.58091211e-02 1.79066397e-02\n",
            " 6.33486152e-01 2.86912750e-02 1.25551794e-03 1.13914418e-03\n",
            " 4.23337985e-03 1.93513967e-02 1.49702176e-03 2.72917718e-01\n",
            " 5.75317800e-01 5.58869123e-01 8.83987308e-01 9.98056591e-01\n",
            " 9.48137760e-01 9.81510699e-01 9.81056392e-01 3.99330724e-03\n",
            " 2.10288889e-03 2.42084102e-03 1.48259988e-02 4.50661294e-02\n",
            " 6.84001250e-03 8.40994180e-05 2.90155032e-04 4.87688463e-03\n",
            " 2.51916074e-03 6.44926488e-01 4.22538891e-02 3.41619295e-03\n",
            " 5.34853479e-03 2.26055365e-03 1.65819556e-01 1.16072483e-02\n",
            " 1.30110919e-01 2.20027100e-03 3.73239934e-01 4.68427390e-02\n",
            " 2.41061524e-02 2.96559539e-02 3.21663231e-01 1.87929302e-07\n",
            " 4.29032707e-06 3.80266283e-04 2.80455048e-13 3.35398763e-05\n",
            " 1.89330953e-03 2.84922801e-12 1.88372996e-06 4.00512763e-05\n",
            " 9.95983243e-01 9.91804838e-01 9.96903956e-01 9.96608377e-01\n",
            " 9.03274894e-01 7.99888194e-01 9.41728234e-01 9.98881400e-01\n",
            " 9.93357837e-01 8.42359900e-01 9.60546017e-01 7.18094647e-01\n",
            " 1.44361407e-01 6.73645794e-01 9.92696434e-02 3.59488904e-01\n",
            " 9.86640751e-01 9.95029628e-01 9.96148586e-01 7.52174079e-01\n",
            " 9.97526109e-01 9.93593514e-01 9.98692453e-01 5.05436778e-01\n",
            " 4.04842079e-01 9.82411087e-01 9.88065720e-01 9.84125137e-01\n",
            " 9.42010507e-02 7.66064823e-01 9.85287309e-01 5.57371199e-01\n",
            " 6.10833876e-02 9.99628782e-01 9.97587919e-01 9.93834496e-01\n",
            " 3.78306769e-02 9.93084237e-02 9.38377619e-01 7.62301743e-01\n",
            " 8.00132751e-01 9.46499765e-01 7.17013478e-02 7.37204105e-02\n",
            " 1.20165125e-01 8.97669911e-01 9.29595232e-01 1.50925957e-03\n",
            " 1.55531568e-02 3.88034014e-03 3.37966084e-02 2.50209495e-02\n",
            " 9.88245845e-01 9.76580620e-01 2.40295157e-02 2.49829385e-02\n",
            " 9.96473968e-01 6.24633968e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 15 [0/107 (0%)]\tTrain Loss: 0.000986\n",
            "Train Epoch: 15 [4/107 (4%)]\tTrain Loss: 0.000506\n",
            "Train Epoch: 15 [8/107 (7%)]\tTrain Loss: 0.011082\n",
            "Train Epoch: 15 [12/107 (11%)]\tTrain Loss: 0.002935\n",
            "Train Epoch: 15 [16/107 (15%)]\tTrain Loss: 0.040981\n",
            "Train Epoch: 15 [20/107 (19%)]\tTrain Loss: 0.000507\n",
            "Train Epoch: 15 [24/107 (22%)]\tTrain Loss: 0.002178\n",
            "Train Epoch: 15 [28/107 (26%)]\tTrain Loss: 0.000580\n",
            "Train Epoch: 15 [32/107 (30%)]\tTrain Loss: 0.000749\n",
            "Train Epoch: 15 [36/107 (34%)]\tTrain Loss: 0.014836\n",
            "Train Epoch: 15 [40/107 (37%)]\tTrain Loss: 0.026701\n",
            "Train Epoch: 15 [44/107 (41%)]\tTrain Loss: 0.000257\n",
            "Train Epoch: 15 [48/107 (45%)]\tTrain Loss: 0.016904\n",
            "Train Epoch: 15 [52/107 (49%)]\tTrain Loss: 0.054614\n",
            "Train Epoch: 15 [56/107 (52%)]\tTrain Loss: 0.027064\n",
            "Train Epoch: 15 [60/107 (56%)]\tTrain Loss: 0.009619\n",
            "Train Epoch: 15 [64/107 (60%)]\tTrain Loss: 0.000340\n",
            "Train Epoch: 15 [68/107 (64%)]\tTrain Loss: 0.000959\n",
            "Train Epoch: 15 [72/107 (67%)]\tTrain Loss: 0.000145\n",
            "Train Epoch: 15 [76/107 (71%)]\tTrain Loss: 0.000742\n",
            "Train Epoch: 15 [80/107 (75%)]\tTrain Loss: 0.000814\n",
            "Train Epoch: 15 [84/107 (79%)]\tTrain Loss: 0.001193\n",
            "Train Epoch: 15 [88/107 (82%)]\tTrain Loss: 0.005451\n",
            "Train Epoch: 15 [92/107 (86%)]\tTrain Loss: 0.006019\n",
            "Train Epoch: 15 [96/107 (90%)]\tTrain Loss: 0.000807\n",
            "Train Epoch: 15 [100/107 (93%)]\tTrain Loss: 0.000273\n",
            "Train Epoch: 15 [104/107 (97%)]\tTrain Loss: 0.064732\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.11290794e-02 7.91657746e-01 2.91539997e-01 5.10281086e-01\n",
            " 7.04861712e-03 3.99028789e-03 8.86416972e-01 7.80079186e-01\n",
            " 2.46691634e-03 6.36881590e-01 6.05630875e-01 2.14596316e-01\n",
            " 9.98757720e-01 6.15795376e-03 2.63386010e-03 2.73620710e-04\n",
            " 5.67283621e-03 2.32295692e-03 5.61222434e-04 3.17633659e-01\n",
            " 9.51111794e-01 9.89786386e-01 9.81581450e-01 9.99310255e-01\n",
            " 9.91194069e-01 9.88484919e-01 9.89755571e-01 1.10890449e-03\n",
            " 6.12704607e-04 8.98887811e-04 8.65674764e-03 1.90574415e-02\n",
            " 1.32833719e-02 5.31376209e-05 7.42301054e-05 6.00644271e-04\n",
            " 1.12455757e-03 3.71116072e-01 1.66325569e-02 4.72594006e-03\n",
            " 7.87324831e-03 7.20551237e-03 1.77026808e-01 2.72532701e-02\n",
            " 2.73144156e-01 4.31802198e-02 5.63843548e-01 1.25527680e-01\n",
            " 1.39000997e-01 2.86779642e-01 8.50434601e-01 1.08744151e-08\n",
            " 2.80754790e-07 1.74085246e-04 1.33973044e-16 8.73093632e-06\n",
            " 2.93135177e-04 1.24543659e-15 1.84116118e-07 2.75741895e-05\n",
            " 9.97169435e-01 9.98774946e-01 9.99265611e-01 9.98969555e-01\n",
            " 9.94623423e-01 9.97293532e-01 9.75109637e-01 9.99946952e-01\n",
            " 9.99974489e-01 9.54217494e-01 9.95418191e-01 9.53623891e-01\n",
            " 8.33090723e-01 9.84412134e-01 9.93491232e-01 8.99218142e-01\n",
            " 9.88695741e-01 9.91989195e-01 9.98018622e-01 9.74430501e-01\n",
            " 9.99586761e-01 9.99497175e-01 9.99911070e-01 5.87407768e-01\n",
            " 8.54161203e-01 9.95564342e-01 9.67824340e-01 9.12917495e-01\n",
            " 6.46878630e-02 9.89771783e-01 9.76265490e-01 8.45395029e-01\n",
            " 2.10210949e-01 9.99989867e-01 9.99829292e-01 9.99650002e-01\n",
            " 2.62115262e-02 8.41368139e-01 9.93116617e-01 9.90450799e-01\n",
            " 9.63255882e-01 9.72776771e-01 4.94645596e-01 6.61257923e-01\n",
            " 8.82090569e-01 9.88543630e-01 9.98398840e-01 2.37199431e-03\n",
            " 9.20029916e-03 3.56641784e-03 4.48826775e-02 4.49805101e-03\n",
            " 9.63305175e-01 9.93934810e-01 1.83232889e-01 3.80360521e-02\n",
            " 9.98703241e-01 9.72849965e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 16 [0/107 (0%)]\tTrain Loss: 0.000912\n",
            "Train Epoch: 16 [4/107 (4%)]\tTrain Loss: 0.019397\n",
            "Train Epoch: 16 [8/107 (7%)]\tTrain Loss: 0.000593\n",
            "Train Epoch: 16 [12/107 (11%)]\tTrain Loss: 0.003455\n",
            "Train Epoch: 16 [16/107 (15%)]\tTrain Loss: 0.041923\n",
            "Train Epoch: 16 [20/107 (19%)]\tTrain Loss: 0.001335\n",
            "Train Epoch: 16 [24/107 (22%)]\tTrain Loss: 0.000982\n",
            "Train Epoch: 16 [28/107 (26%)]\tTrain Loss: 0.003477\n",
            "Train Epoch: 16 [32/107 (30%)]\tTrain Loss: 0.000873\n",
            "Train Epoch: 16 [36/107 (34%)]\tTrain Loss: 0.001333\n",
            "Train Epoch: 16 [40/107 (37%)]\tTrain Loss: 0.043987\n",
            "Train Epoch: 16 [44/107 (41%)]\tTrain Loss: 0.006354\n",
            "Train Epoch: 16 [48/107 (45%)]\tTrain Loss: 0.005426\n",
            "Train Epoch: 16 [52/107 (49%)]\tTrain Loss: 0.024248\n",
            "Train Epoch: 16 [56/107 (52%)]\tTrain Loss: 0.009819\n",
            "Train Epoch: 16 [60/107 (56%)]\tTrain Loss: 0.115333\n",
            "Train Epoch: 16 [64/107 (60%)]\tTrain Loss: 0.004204\n",
            "Train Epoch: 16 [68/107 (64%)]\tTrain Loss: 0.053414\n",
            "Train Epoch: 16 [72/107 (67%)]\tTrain Loss: 0.052067\n",
            "Train Epoch: 16 [76/107 (71%)]\tTrain Loss: 0.000557\n",
            "Train Epoch: 16 [80/107 (75%)]\tTrain Loss: 0.134861\n",
            "Train Epoch: 16 [84/107 (79%)]\tTrain Loss: 0.130889\n",
            "Train Epoch: 16 [88/107 (82%)]\tTrain Loss: 0.001149\n",
            "Train Epoch: 16 [92/107 (86%)]\tTrain Loss: 0.000936\n",
            "Train Epoch: 16 [96/107 (90%)]\tTrain Loss: 0.000912\n",
            "Train Epoch: 16 [100/107 (93%)]\tTrain Loss: 0.003421\n",
            "Train Epoch: 16 [104/107 (97%)]\tTrain Loss: 0.100242\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.11812450e-01 8.85890305e-01 2.37622485e-01 8.66760254e-01\n",
            " 3.70491073e-02 9.19581130e-02 8.67117226e-01 7.31318235e-01\n",
            " 1.08958326e-01 7.24267483e-01 1.89819440e-01 1.69998094e-01\n",
            " 8.64254057e-01 8.52117836e-02 1.56421453e-01 6.71371468e-04\n",
            " 3.56663298e-03 4.17579234e-01 3.75645980e-02 3.96264017e-01\n",
            " 5.20572126e-01 9.62062538e-01 9.97547567e-01 9.97877002e-01\n",
            " 8.09518456e-01 9.88861501e-01 9.46531057e-01 4.93466482e-02\n",
            " 8.94288123e-02 3.94113399e-02 7.02539161e-02 1.91993430e-01\n",
            " 2.34635130e-01 7.52257474e-05 2.96843267e-04 1.68281922e-03\n",
            " 5.83495107e-03 9.72899735e-01 8.05843398e-02 3.45129194e-03\n",
            " 3.45338229e-03 1.77991495e-03 9.49859500e-01 1.92653105e-01\n",
            " 9.79813099e-01 2.05820888e-01 7.68253624e-01 3.84119809e-01\n",
            " 4.29781199e-01 3.87506992e-01 7.74262369e-01 1.65848451e-05\n",
            " 3.74407718e-05 2.31991075e-02 1.03158419e-11 1.94231980e-03\n",
            " 7.45393559e-02 2.87051945e-11 5.78195795e-05 1.68996956e-03\n",
            " 9.98013377e-01 9.96674776e-01 9.97723758e-01 9.96971607e-01\n",
            " 9.97690320e-01 9.97270644e-01 9.98098195e-01 9.99998331e-01\n",
            " 9.99996781e-01 9.78969991e-01 9.79231834e-01 8.55614066e-01\n",
            " 9.34807599e-01 9.61780787e-01 9.22096491e-01 9.78428066e-01\n",
            " 9.85940874e-01 9.91516829e-01 9.99708474e-01 9.92374241e-01\n",
            " 9.99653935e-01 9.97976124e-01 9.99720156e-01 9.12931323e-01\n",
            " 7.55708098e-01 9.95998859e-01 9.98861313e-01 9.91222739e-01\n",
            " 6.73962012e-02 1.44152999e-01 7.52976656e-01 9.07794178e-01\n",
            " 9.38312531e-01 9.99997258e-01 9.99831200e-01 9.99546587e-01\n",
            " 5.61263323e-01 7.92984724e-01 9.48911607e-01 8.65782917e-01\n",
            " 7.57994056e-01 9.37995672e-01 2.80863941e-01 9.01065290e-01\n",
            " 9.70598698e-01 9.97234762e-01 9.99717891e-01 3.89088015e-03\n",
            " 8.39885511e-03 3.29412445e-02 1.00432403e-01 5.17000370e-02\n",
            " 9.77887213e-01 9.68337595e-01 2.15270013e-01 1.79776862e-01\n",
            " 9.78089035e-01 8.48120689e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 17 [0/107 (0%)]\tTrain Loss: 0.002236\n",
            "Train Epoch: 17 [4/107 (4%)]\tTrain Loss: 0.002583\n",
            "Train Epoch: 17 [8/107 (7%)]\tTrain Loss: 0.002728\n",
            "Train Epoch: 17 [12/107 (11%)]\tTrain Loss: 0.003418\n",
            "Train Epoch: 17 [16/107 (15%)]\tTrain Loss: 0.017680\n",
            "Train Epoch: 17 [20/107 (19%)]\tTrain Loss: 0.006943\n",
            "Train Epoch: 17 [24/107 (22%)]\tTrain Loss: 0.004306\n",
            "Train Epoch: 17 [28/107 (26%)]\tTrain Loss: 0.019493\n",
            "Train Epoch: 17 [32/107 (30%)]\tTrain Loss: 0.008308\n",
            "Train Epoch: 17 [36/107 (34%)]\tTrain Loss: 0.000690\n",
            "Train Epoch: 17 [40/107 (37%)]\tTrain Loss: 0.035876\n",
            "Train Epoch: 17 [44/107 (41%)]\tTrain Loss: 0.012369\n",
            "Train Epoch: 17 [48/107 (45%)]\tTrain Loss: 0.006693\n",
            "Train Epoch: 17 [52/107 (49%)]\tTrain Loss: 0.000802\n",
            "Train Epoch: 17 [56/107 (52%)]\tTrain Loss: 0.000615\n",
            "Train Epoch: 17 [60/107 (56%)]\tTrain Loss: 0.001904\n",
            "Train Epoch: 17 [64/107 (60%)]\tTrain Loss: 0.036153\n",
            "Train Epoch: 17 [68/107 (64%)]\tTrain Loss: 0.005262\n",
            "Train Epoch: 17 [72/107 (67%)]\tTrain Loss: 0.216280\n",
            "Train Epoch: 17 [76/107 (71%)]\tTrain Loss: 0.021201\n",
            "Train Epoch: 17 [80/107 (75%)]\tTrain Loss: 0.073001\n",
            "Train Epoch: 17 [84/107 (79%)]\tTrain Loss: 0.006620\n",
            "Train Epoch: 17 [88/107 (82%)]\tTrain Loss: 0.001590\n",
            "Train Epoch: 17 [92/107 (86%)]\tTrain Loss: 0.027368\n",
            "Train Epoch: 17 [96/107 (90%)]\tTrain Loss: 0.058788\n",
            "Train Epoch: 17 [100/107 (93%)]\tTrain Loss: 0.064645\n",
            "Train Epoch: 17 [104/107 (97%)]\tTrain Loss: 0.017461\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.26005122e-01 9.76139724e-01 6.18399143e-01 7.10771143e-01\n",
            " 1.69555917e-02 1.13705449e-01 8.55177939e-01 4.80920941e-01\n",
            " 4.44907211e-02 8.20676982e-01 3.30003053e-01 1.74900308e-01\n",
            " 9.39388633e-01 6.88468039e-01 5.67693055e-01 1.83619354e-02\n",
            " 2.26111319e-02 1.68816611e-01 3.87643427e-02 1.76208675e-01\n",
            " 9.39412564e-02 9.51468945e-01 9.02003288e-01 9.99095917e-01\n",
            " 5.87502778e-01 6.45077407e-01 9.78595197e-01 2.25988805e-01\n",
            " 3.76546048e-02 1.85244046e-02 2.95800984e-01 1.94953933e-01\n",
            " 8.82994175e-01 1.65400666e-03 8.13007762e-04 2.54148990e-02\n",
            " 8.32151026e-02 6.78516448e-01 2.67840382e-02 1.75314248e-02\n",
            " 2.10751388e-02 1.23144081e-02 3.26473922e-01 1.33057073e-01\n",
            " 8.38356376e-01 1.37633443e-01 9.35080826e-01 7.50810087e-01\n",
            " 9.93784785e-01 2.03344360e-01 9.95822906e-01 1.73584782e-02\n",
            " 3.52402125e-03 2.91249722e-01 1.48933459e-05 1.20792100e-02\n",
            " 2.14148447e-01 9.27218789e-05 1.09468065e-02 6.72001690e-02\n",
            " 9.98295248e-01 9.98549879e-01 9.99785364e-01 9.99781191e-01\n",
            " 9.99864936e-01 9.99956489e-01 9.99978781e-01 9.99998212e-01\n",
            " 9.99995351e-01 9.63909328e-01 9.97910440e-01 9.88599300e-01\n",
            " 9.99484420e-01 9.99405384e-01 9.95183289e-01 9.96754348e-01\n",
            " 9.98304844e-01 9.98994887e-01 9.99994040e-01 9.99987960e-01\n",
            " 9.99998331e-01 9.99996662e-01 9.99999642e-01 9.80811596e-01\n",
            " 6.65068030e-01 9.99853373e-01 9.99068439e-01 9.37358439e-01\n",
            " 7.72472247e-02 7.79177904e-01 6.66397750e-01 8.86784613e-01\n",
            " 7.83847868e-01 9.99987364e-01 9.99987841e-01 9.99896169e-01\n",
            " 3.45012009e-01 2.43476227e-01 2.87754416e-01 2.91144550e-01\n",
            " 4.41706806e-01 9.88126755e-01 5.19322276e-01 8.84967506e-01\n",
            " 9.72977042e-01 9.87615883e-01 9.99813497e-01 1.18605560e-02\n",
            " 1.04881404e-02 1.03154533e-01 1.21070988e-01 2.34609544e-02\n",
            " 7.43051469e-01 9.83966529e-01 7.06278443e-01 1.81831896e-01\n",
            " 9.99943733e-01 9.70010936e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "Train Epoch: 18 [0/107 (0%)]\tTrain Loss: 0.030663\n",
            "Train Epoch: 18 [4/107 (4%)]\tTrain Loss: 0.005409\n",
            "Train Epoch: 18 [8/107 (7%)]\tTrain Loss: 0.010635\n",
            "Train Epoch: 18 [12/107 (11%)]\tTrain Loss: 0.002370\n",
            "Train Epoch: 18 [16/107 (15%)]\tTrain Loss: 0.010407\n",
            "Train Epoch: 18 [20/107 (19%)]\tTrain Loss: 0.003398\n",
            "Train Epoch: 18 [24/107 (22%)]\tTrain Loss: 0.020362\n",
            "Train Epoch: 18 [28/107 (26%)]\tTrain Loss: 0.004809\n",
            "Train Epoch: 18 [32/107 (30%)]\tTrain Loss: 0.005301\n",
            "Train Epoch: 18 [36/107 (34%)]\tTrain Loss: 0.012364\n",
            "Train Epoch: 18 [40/107 (37%)]\tTrain Loss: 0.033554\n",
            "Train Epoch: 18 [44/107 (41%)]\tTrain Loss: 0.012250\n",
            "Train Epoch: 18 [48/107 (45%)]\tTrain Loss: 0.157501\n",
            "Train Epoch: 18 [52/107 (49%)]\tTrain Loss: 0.003356\n",
            "Train Epoch: 18 [56/107 (52%)]\tTrain Loss: 0.008222\n",
            "Train Epoch: 18 [60/107 (56%)]\tTrain Loss: 0.014890\n",
            "Train Epoch: 18 [64/107 (60%)]\tTrain Loss: 0.008846\n",
            "Train Epoch: 18 [68/107 (64%)]\tTrain Loss: 0.007741\n",
            "Train Epoch: 18 [72/107 (67%)]\tTrain Loss: 0.039145\n",
            "Train Epoch: 18 [76/107 (71%)]\tTrain Loss: 0.014906\n",
            "Train Epoch: 18 [80/107 (75%)]\tTrain Loss: 0.005915\n",
            "Train Epoch: 18 [84/107 (79%)]\tTrain Loss: 0.000638\n",
            "Train Epoch: 18 [88/107 (82%)]\tTrain Loss: 0.011134\n",
            "Train Epoch: 18 [92/107 (86%)]\tTrain Loss: 0.030194\n",
            "Train Epoch: 18 [96/107 (90%)]\tTrain Loss: 0.003168\n",
            "Train Epoch: 18 [100/107 (93%)]\tTrain Loss: 0.001852\n",
            "Train Epoch: 18 [104/107 (97%)]\tTrain Loss: 0.027419\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.00068932e-02 9.27922726e-01 5.12939453e-01 8.68628085e-01\n",
            " 7.11371191e-03 3.27494144e-01 9.20700967e-01 8.13790619e-01\n",
            " 1.86153427e-02 4.16381449e-01 1.17412582e-01 1.44286286e-02\n",
            " 8.69044542e-01 6.03937149e-01 5.08212268e-01 2.62870657e-04\n",
            " 9.52220362e-05 2.92884499e-01 7.36297294e-02 2.57576466e-01\n",
            " 6.22281969e-01 9.96453166e-01 9.50834155e-01 9.98749852e-01\n",
            " 9.80578959e-01 9.32223678e-01 9.80607033e-01 6.49991751e-01\n",
            " 2.51325741e-02 4.97234985e-02 8.02123308e-01 7.52523541e-01\n",
            " 8.03455234e-01 3.42207262e-04 7.11377710e-04 4.11601132e-03\n",
            " 1.24817919e-02 9.67195988e-01 2.31715903e-01 2.69365660e-03\n",
            " 2.09500152e-03 7.77113624e-03 8.46954465e-01 3.01619977e-01\n",
            " 8.16890299e-01 7.94668198e-01 9.33222353e-01 8.14479053e-01\n",
            " 9.56043124e-01 7.40109324e-01 9.76896226e-01 1.58464318e-05\n",
            " 1.82005970e-04 9.98095274e-02 5.31465368e-14 2.08781657e-05\n",
            " 1.12762656e-02 1.50494428e-12 3.09675420e-06 4.15420495e-02\n",
            " 9.98721540e-01 9.98000681e-01 9.98030365e-01 9.98002231e-01\n",
            " 9.82137561e-01 9.98968244e-01 9.91849661e-01 9.99963284e-01\n",
            " 9.98820841e-01 9.77905452e-01 9.97297943e-01 9.75310564e-01\n",
            " 9.93045747e-01 9.98036444e-01 9.92605805e-01 9.80541706e-01\n",
            " 9.94173825e-01 9.92217422e-01 9.98706460e-01 9.99646664e-01\n",
            " 9.99865174e-01 9.99151707e-01 9.99618888e-01 9.29506838e-01\n",
            " 8.78759444e-01 9.98975158e-01 9.98506844e-01 9.93944466e-01\n",
            " 9.89860371e-02 6.82509780e-01 9.80501354e-01 9.84700084e-01\n",
            " 9.44644153e-01 9.99913096e-01 9.99500275e-01 9.94986415e-01\n",
            " 7.09673911e-02 4.27898094e-02 1.62103713e-01 9.48722780e-01\n",
            " 7.98461676e-01 9.79959488e-01 3.02385628e-01 9.36581373e-01\n",
            " 9.91558671e-01 9.97784078e-01 9.99828100e-01 3.72254044e-01\n",
            " 8.93523172e-02 2.35583782e-01 6.28218591e-01 5.54134473e-02\n",
            " 9.80696619e-01 8.76071036e-01 4.30427372e-01 1.37406170e-01\n",
            " 9.97717977e-01 9.84150648e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 19 [0/107 (0%)]\tTrain Loss: 0.005407\n",
            "Train Epoch: 19 [4/107 (4%)]\tTrain Loss: 0.005165\n",
            "Train Epoch: 19 [8/107 (7%)]\tTrain Loss: 0.004873\n",
            "Train Epoch: 19 [12/107 (11%)]\tTrain Loss: 0.005665\n",
            "Train Epoch: 19 [16/107 (15%)]\tTrain Loss: 0.007097\n",
            "Train Epoch: 19 [20/107 (19%)]\tTrain Loss: 0.001209\n",
            "Train Epoch: 19 [24/107 (22%)]\tTrain Loss: 0.042798\n",
            "Train Epoch: 19 [28/107 (26%)]\tTrain Loss: 0.000117\n",
            "Train Epoch: 19 [32/107 (30%)]\tTrain Loss: 0.003392\n",
            "Train Epoch: 19 [36/107 (34%)]\tTrain Loss: 0.006600\n",
            "Train Epoch: 19 [40/107 (37%)]\tTrain Loss: 0.001670\n",
            "Train Epoch: 19 [44/107 (41%)]\tTrain Loss: 0.036363\n",
            "Train Epoch: 19 [48/107 (45%)]\tTrain Loss: 0.001402\n",
            "Train Epoch: 19 [52/107 (49%)]\tTrain Loss: 0.003126\n",
            "Train Epoch: 19 [56/107 (52%)]\tTrain Loss: 0.000165\n",
            "Train Epoch: 19 [60/107 (56%)]\tTrain Loss: 0.027478\n",
            "Train Epoch: 19 [64/107 (60%)]\tTrain Loss: 0.010900\n",
            "Train Epoch: 19 [68/107 (64%)]\tTrain Loss: 0.027491\n",
            "Train Epoch: 19 [72/107 (67%)]\tTrain Loss: 0.002420\n",
            "Train Epoch: 19 [76/107 (71%)]\tTrain Loss: 0.044054\n",
            "Train Epoch: 19 [80/107 (75%)]\tTrain Loss: 0.017300\n",
            "Train Epoch: 19 [84/107 (79%)]\tTrain Loss: 0.032579\n",
            "Train Epoch: 19 [88/107 (82%)]\tTrain Loss: 0.101277\n",
            "Train Epoch: 19 [92/107 (86%)]\tTrain Loss: 0.004991\n",
            "Train Epoch: 19 [96/107 (90%)]\tTrain Loss: 0.011730\n",
            "Train Epoch: 19 [100/107 (93%)]\tTrain Loss: 0.060533\n",
            "Train Epoch: 19 [104/107 (97%)]\tTrain Loss: 0.013839\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [6.07728260e-04 8.72347802e-02 1.78242184e-03 7.75265247e-02\n",
            " 1.76091213e-03 1.08937277e-02 9.60541368e-02 4.11678813e-02\n",
            " 2.45945482e-03 8.01596820e-01 5.08291662e-01 5.22894204e-01\n",
            " 2.78477103e-01 5.73591352e-01 1.60932660e-01 1.53012304e-02\n",
            " 6.57734051e-02 1.23160332e-01 2.98663586e-01 5.19559324e-01\n",
            " 6.70551896e-01 9.94536817e-01 8.31965804e-01 9.97532964e-01\n",
            " 9.91082072e-01 9.93836582e-01 9.93963063e-01 2.42108330e-01\n",
            " 2.22710110e-02 4.24290029e-03 2.66645830e-02 3.66570018e-02\n",
            " 1.07085526e-01 8.51514190e-03 8.38445500e-02 8.29174649e-03\n",
            " 3.97019178e-01 5.90423226e-01 6.51914477e-02 1.79286744e-03\n",
            " 5.74632257e-04 9.11654264e-04 5.32548249e-01 3.63740399e-02\n",
            " 2.54359365e-01 1.37730613e-01 3.20465933e-03 4.66715224e-04\n",
            " 1.31120626e-02 3.31326611e-02 9.06942561e-02 3.70486326e-08\n",
            " 7.03274636e-05 7.27282095e-05 1.99929422e-16 4.05813765e-08\n",
            " 1.15766434e-05 1.52345154e-15 3.08392572e-07 3.94926127e-03\n",
            " 8.03055882e-01 4.71270770e-01 8.18424881e-01 6.85553849e-01\n",
            " 2.73677319e-01 7.73934662e-01 7.34461784e-01 9.96174812e-01\n",
            " 6.59823537e-01 8.44759345e-01 1.92406833e-01 1.34985015e-01\n",
            " 7.44991302e-01 6.34001553e-01 9.39773798e-01 8.08296978e-01\n",
            " 5.59156299e-01 6.79932773e-01 8.98262739e-01 5.82637846e-01\n",
            " 9.67083156e-01 7.29106009e-01 9.25905168e-01 9.76015568e-01\n",
            " 3.65959078e-01 9.54337537e-01 8.31128955e-01 8.38999331e-01\n",
            " 1.84316590e-01 9.97636914e-01 9.92653847e-01 4.28425461e-01\n",
            " 2.81777948e-01 9.99969602e-01 9.99699235e-01 9.96388435e-01\n",
            " 5.36306143e-01 9.69577491e-01 9.78759050e-01 9.96080101e-01\n",
            " 8.17947388e-01 8.25642824e-01 8.76159906e-01 9.44249451e-01\n",
            " 9.25325751e-01 9.93951619e-01 9.94995475e-01 2.88166761e-01\n",
            " 4.72629249e-01 1.87287807e-01 7.99851954e-01 8.24548841e-01\n",
            " 9.97320950e-01 9.96665061e-01 2.26117253e-01 5.73154330e-01\n",
            " 9.99967337e-01 9.99817789e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 20 [0/107 (0%)]\tTrain Loss: 0.015476\n",
            "Train Epoch: 20 [4/107 (4%)]\tTrain Loss: 0.001807\n",
            "Train Epoch: 20 [8/107 (7%)]\tTrain Loss: 0.047375\n",
            "Train Epoch: 20 [12/107 (11%)]\tTrain Loss: 0.003493\n",
            "Train Epoch: 20 [16/107 (15%)]\tTrain Loss: 0.044378\n",
            "Train Epoch: 20 [20/107 (19%)]\tTrain Loss: 0.003149\n",
            "Train Epoch: 20 [24/107 (22%)]\tTrain Loss: 0.001047\n",
            "Train Epoch: 20 [28/107 (26%)]\tTrain Loss: 0.000978\n",
            "Train Epoch: 20 [32/107 (30%)]\tTrain Loss: 0.003119\n",
            "Train Epoch: 20 [36/107 (34%)]\tTrain Loss: 0.002212\n",
            "Train Epoch: 20 [40/107 (37%)]\tTrain Loss: 0.004994\n",
            "Train Epoch: 20 [44/107 (41%)]\tTrain Loss: 0.003270\n",
            "Train Epoch: 20 [48/107 (45%)]\tTrain Loss: 0.001874\n",
            "Train Epoch: 20 [52/107 (49%)]\tTrain Loss: 0.163262\n",
            "Train Epoch: 20 [56/107 (52%)]\tTrain Loss: 0.108485\n",
            "Train Epoch: 20 [60/107 (56%)]\tTrain Loss: 0.141683\n",
            "Train Epoch: 20 [64/107 (60%)]\tTrain Loss: 0.063078\n",
            "Train Epoch: 20 [68/107 (64%)]\tTrain Loss: 0.143189\n",
            "Train Epoch: 20 [72/107 (67%)]\tTrain Loss: 0.010881\n",
            "Train Epoch: 20 [76/107 (71%)]\tTrain Loss: 0.028858\n",
            "Train Epoch: 20 [80/107 (75%)]\tTrain Loss: 0.023944\n",
            "Train Epoch: 20 [84/107 (79%)]\tTrain Loss: 0.003384\n",
            "Train Epoch: 20 [88/107 (82%)]\tTrain Loss: 0.003212\n",
            "Train Epoch: 20 [92/107 (86%)]\tTrain Loss: 0.007267\n",
            "Train Epoch: 20 [96/107 (90%)]\tTrain Loss: 0.085139\n",
            "Train Epoch: 20 [100/107 (93%)]\tTrain Loss: 0.012681\n",
            "Train Epoch: 20 [104/107 (97%)]\tTrain Loss: 0.002951\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.02916423e-03 8.93853724e-01 2.81371564e-01 1.21656246e-01\n",
            " 3.36771645e-03 3.60981678e-03 9.35389221e-01 4.06914428e-02\n",
            " 5.51656995e-04 1.21779084e-01 3.42866927e-01 6.63832873e-02\n",
            " 6.39636993e-01 9.75712296e-03 3.12575400e-02 2.03120941e-03\n",
            " 7.14480644e-04 1.67299118e-02 3.23129967e-02 7.31388405e-02\n",
            " 4.12135571e-01 8.61901224e-01 8.90248716e-01 9.99561727e-01\n",
            " 7.24606335e-01 9.38951433e-01 9.34856951e-01 4.47226837e-02\n",
            " 5.01208659e-03 2.81202444e-03 1.17237316e-02 3.70904170e-02\n",
            " 4.66247983e-02 3.68126261e-04 2.57694686e-04 9.53681592e-04\n",
            " 8.53979320e-04 7.43882880e-02 1.59668196e-02 2.36753933e-03\n",
            " 2.97816447e-03 2.43926537e-03 3.89739096e-01 1.11666210e-02\n",
            " 4.43686217e-01 7.94816762e-02 5.61224706e-02 2.85871290e-02\n",
            " 2.13341147e-01 1.09690100e-01 6.17233157e-01 4.25364851e-06\n",
            " 6.76062889e-04 6.43012405e-04 3.65722071e-11 9.70283963e-06\n",
            " 5.18844742e-03 2.81870194e-10 1.90422234e-05 1.70016885e-02\n",
            " 9.95274782e-01 9.79076624e-01 9.95088279e-01 9.93830144e-01\n",
            " 6.94101572e-01 9.31372523e-01 9.27799344e-01 9.99779642e-01\n",
            " 9.91237640e-01 9.22233343e-01 8.66436541e-01 5.21765888e-01\n",
            " 9.51412201e-01 9.76509035e-01 9.16887939e-01 5.51436007e-01\n",
            " 9.95211422e-01 9.93662000e-01 9.95497704e-01 9.73824263e-01\n",
            " 9.98876274e-01 9.91389334e-01 9.99456227e-01 8.75248909e-01\n",
            " 7.59313464e-01 9.60536003e-01 9.95909929e-01 9.62577105e-01\n",
            " 5.56902252e-02 1.32666543e-01 9.91795599e-01 7.78354466e-01\n",
            " 4.89769399e-01 1.00000000e+00 9.99932051e-01 9.99949932e-01\n",
            " 5.88389397e-01 3.09426099e-01 8.38528335e-01 6.99350595e-01\n",
            " 6.87961578e-01 9.39647496e-01 3.73740762e-01 9.50954437e-01\n",
            " 8.95710468e-01 9.96627092e-01 9.99925137e-01 2.91724317e-03\n",
            " 1.66691723e-03 5.33468649e-03 5.33815427e-03 1.04401978e-02\n",
            " 9.41416264e-01 8.67038250e-01 1.19693121e-02 2.56222844e-01\n",
            " 9.99874234e-01 6.92679107e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "vote_pred [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "TP= 47 TN= 47 FN= 11 FP= 13\n",
            "TP+FP 60\n",
            "precision 0.7833333333333333\n",
            "recall 0.8103448275862069\n",
            "F1 0.7966101694915254\n",
            "acc 0.7966101694915254\n",
            "AUCp 0.7968390804597701\n",
            "AUC 0.8600574712643678\n",
            "\n",
            " The epoch is 20, average recall: 0.8103, average precision: 0.7833,average F1: 0.7966, average accuracy: 0.7966, average AUC: 0.8601\n",
            "Train Epoch: 21 [0/107 (0%)]\tTrain Loss: 0.001711\n",
            "Train Epoch: 21 [4/107 (4%)]\tTrain Loss: 0.006339\n",
            "Train Epoch: 21 [8/107 (7%)]\tTrain Loss: 0.009109\n",
            "Train Epoch: 21 [12/107 (11%)]\tTrain Loss: 0.008285\n",
            "Train Epoch: 21 [16/107 (15%)]\tTrain Loss: 0.000645\n",
            "Train Epoch: 21 [20/107 (19%)]\tTrain Loss: 0.003300\n",
            "Train Epoch: 21 [24/107 (22%)]\tTrain Loss: 0.001265\n",
            "Train Epoch: 21 [28/107 (26%)]\tTrain Loss: 0.003656\n",
            "Train Epoch: 21 [32/107 (30%)]\tTrain Loss: 0.009251\n",
            "Train Epoch: 21 [36/107 (34%)]\tTrain Loss: 0.002229\n",
            "Train Epoch: 21 [40/107 (37%)]\tTrain Loss: 0.004267\n",
            "Train Epoch: 21 [44/107 (41%)]\tTrain Loss: 0.002337\n",
            "Train Epoch: 21 [48/107 (45%)]\tTrain Loss: 0.004067\n",
            "Train Epoch: 21 [52/107 (49%)]\tTrain Loss: 0.005111\n",
            "Train Epoch: 21 [56/107 (52%)]\tTrain Loss: 0.001936\n",
            "Train Epoch: 21 [60/107 (56%)]\tTrain Loss: 0.004233\n",
            "Train Epoch: 21 [64/107 (60%)]\tTrain Loss: 0.051566\n",
            "Train Epoch: 21 [68/107 (64%)]\tTrain Loss: 0.000872\n",
            "Train Epoch: 21 [72/107 (67%)]\tTrain Loss: 0.006180\n",
            "Train Epoch: 21 [76/107 (71%)]\tTrain Loss: 0.039649\n",
            "Train Epoch: 21 [80/107 (75%)]\tTrain Loss: 0.219784\n",
            "Train Epoch: 21 [84/107 (79%)]\tTrain Loss: 0.000573\n",
            "Train Epoch: 21 [88/107 (82%)]\tTrain Loss: 0.081886\n",
            "Train Epoch: 21 [92/107 (86%)]\tTrain Loss: 0.005839\n",
            "Train Epoch: 21 [96/107 (90%)]\tTrain Loss: 0.003914\n",
            "Train Epoch: 21 [100/107 (93%)]\tTrain Loss: 0.040634\n",
            "Train Epoch: 21 [104/107 (97%)]\tTrain Loss: 0.101721\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [4.31013387e-03 9.07594562e-01 4.83451217e-01 1.61140308e-01\n",
            " 1.65700521e-02 3.57424165e-03 8.92339110e-01 6.29624963e-01\n",
            " 1.47266808e-04 2.20436141e-01 6.91685021e-01 7.33266920e-02\n",
            " 9.11114275e-01 2.54046191e-02 3.75603400e-02 4.87856241e-03\n",
            " 1.76546335e-01 3.57461609e-02 6.10883497e-02 4.45310511e-02\n",
            " 4.26226407e-01 9.70006466e-01 8.01513314e-01 9.92919266e-01\n",
            " 9.56541657e-01 9.46348667e-01 8.15725923e-01 2.51601152e-02\n",
            " 8.93170573e-03 3.80133977e-03 1.56270843e-02 3.23453218e-01\n",
            " 1.47727299e-02 5.70411095e-04 1.11714972e-03 1.41572847e-03\n",
            " 2.73958687e-03 7.85265863e-01 3.87362421e-01 3.94185679e-03\n",
            " 3.64206079e-03 7.46150501e-03 8.80609632e-01 4.75187451e-02\n",
            " 6.46503508e-01 4.09046173e-01 2.84042060e-01 1.76968798e-01\n",
            " 8.78470480e-01 1.98350981e-01 9.76226151e-01 2.96619493e-08\n",
            " 1.41310775e-05 3.06791371e-05 1.56100099e-16 5.41684670e-08\n",
            " 5.43741975e-04 5.89904648e-17 1.00735122e-07 9.04932909e-04\n",
            " 9.95771110e-01 9.91691113e-01 9.95817959e-01 9.96252120e-01\n",
            " 9.80065286e-01 9.78376985e-01 8.85586023e-01 9.98059809e-01\n",
            " 9.90767181e-01 8.40771377e-01 9.82177854e-01 8.74716401e-01\n",
            " 9.84241068e-01 9.94507968e-01 9.19606507e-01 9.85242069e-01\n",
            " 9.96604443e-01 9.96166885e-01 9.98662949e-01 9.79635477e-01\n",
            " 9.97222424e-01 9.97674644e-01 9.97809350e-01 9.26188290e-01\n",
            " 9.40836906e-01 9.75181282e-01 9.95655060e-01 9.89702880e-01\n",
            " 5.16804531e-02 9.45471704e-01 9.19520378e-01 8.69219959e-01\n",
            " 4.17357385e-01 9.99822795e-01 9.97701585e-01 9.87127900e-01\n",
            " 8.00773740e-01 9.42591667e-01 9.59329486e-01 9.69094396e-01\n",
            " 7.77143478e-01 9.70317900e-01 7.59097040e-01 8.35852802e-01\n",
            " 9.59919274e-01 9.69228864e-01 9.98325527e-01 4.01582047e-02\n",
            " 2.45549560e-01 4.89701062e-01 5.97044885e-01 4.97818261e-01\n",
            " 9.90258455e-01 9.88114536e-01 3.67851466e-01 7.05665290e-01\n",
            " 9.99251068e-01 9.84304368e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 22 [0/107 (0%)]\tTrain Loss: 0.007015\n",
            "Train Epoch: 22 [4/107 (4%)]\tTrain Loss: 0.009367\n",
            "Train Epoch: 22 [8/107 (7%)]\tTrain Loss: 0.006114\n",
            "Train Epoch: 22 [12/107 (11%)]\tTrain Loss: 0.030884\n",
            "Train Epoch: 22 [16/107 (15%)]\tTrain Loss: 0.012987\n",
            "Train Epoch: 22 [20/107 (19%)]\tTrain Loss: 0.151101\n",
            "Train Epoch: 22 [24/107 (22%)]\tTrain Loss: 0.001703\n",
            "Train Epoch: 22 [28/107 (26%)]\tTrain Loss: 0.004146\n",
            "Train Epoch: 22 [32/107 (30%)]\tTrain Loss: 0.001072\n",
            "Train Epoch: 22 [36/107 (34%)]\tTrain Loss: 0.000769\n",
            "Train Epoch: 22 [40/107 (37%)]\tTrain Loss: 0.000736\n",
            "Train Epoch: 22 [44/107 (41%)]\tTrain Loss: 0.021034\n",
            "Train Epoch: 22 [48/107 (45%)]\tTrain Loss: 0.000387\n",
            "Train Epoch: 22 [52/107 (49%)]\tTrain Loss: 0.003790\n",
            "Train Epoch: 22 [56/107 (52%)]\tTrain Loss: 0.001654\n",
            "Train Epoch: 22 [60/107 (56%)]\tTrain Loss: 0.051006\n",
            "Train Epoch: 22 [64/107 (60%)]\tTrain Loss: 0.001057\n",
            "Train Epoch: 22 [68/107 (64%)]\tTrain Loss: 0.015999\n",
            "Train Epoch: 22 [72/107 (67%)]\tTrain Loss: 0.000334\n",
            "Train Epoch: 22 [76/107 (71%)]\tTrain Loss: 0.000622\n",
            "Train Epoch: 22 [80/107 (75%)]\tTrain Loss: 0.001091\n",
            "Train Epoch: 22 [84/107 (79%)]\tTrain Loss: 0.007676\n",
            "Train Epoch: 22 [88/107 (82%)]\tTrain Loss: 0.007786\n",
            "Train Epoch: 22 [92/107 (86%)]\tTrain Loss: 0.007498\n",
            "Train Epoch: 22 [96/107 (90%)]\tTrain Loss: 0.077629\n",
            "Train Epoch: 22 [100/107 (93%)]\tTrain Loss: 0.004006\n",
            "Train Epoch: 22 [104/107 (97%)]\tTrain Loss: 0.001761\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.64341012e-02 9.98154461e-01 9.80336964e-01 7.88172841e-01\n",
            " 6.81073358e-03 7.97763467e-02 9.99334395e-01 9.67986882e-01\n",
            " 2.42573693e-01 5.72197974e-01 6.14184260e-01 3.51871192e-01\n",
            " 9.98974442e-01 1.07936813e-02 2.43782084e-02 1.06421532e-02\n",
            " 4.38574374e-01 7.52221644e-01 8.27438831e-01 9.00032282e-01\n",
            " 3.20257187e-01 9.96794283e-01 9.85884249e-01 9.99767721e-01\n",
            " 9.87976491e-01 9.79507267e-01 9.35617685e-01 5.83542325e-02\n",
            " 9.35933664e-02 6.94146454e-01 2.33576279e-02 6.18962109e-01\n",
            " 3.99956107e-01 1.75700046e-03 5.93379932e-03 1.88948531e-02\n",
            " 6.22681141e-01 9.84299541e-01 3.51230167e-02 2.47120410e-02\n",
            " 8.87789279e-02 2.24960335e-02 9.68321264e-01 9.05356646e-01\n",
            " 9.81814921e-01 2.47775093e-01 9.21832025e-01 9.14650977e-01\n",
            " 9.44407582e-01 5.03386199e-01 9.88045275e-01 3.79053308e-05\n",
            " 1.38225063e-04 2.97762896e-03 3.89030197e-10 2.18824425e-05\n",
            " 2.09897123e-02 1.39242429e-09 9.77277959e-05 2.58373003e-03\n",
            " 9.99251544e-01 9.98728096e-01 9.98921990e-01 9.98668551e-01\n",
            " 9.41520929e-01 9.97366726e-01 9.81380761e-01 9.99967456e-01\n",
            " 9.99025941e-01 8.89301419e-01 9.91840839e-01 9.25887764e-01\n",
            " 9.67493176e-01 9.95953560e-01 8.09987366e-01 6.92690849e-01\n",
            " 9.99789417e-01 9.99764860e-01 9.99920130e-01 9.97454822e-01\n",
            " 9.99767482e-01 9.99749959e-01 9.99721944e-01 9.42583859e-01\n",
            " 9.96728659e-01 9.98820007e-01 9.99165177e-01 5.94898522e-01\n",
            " 6.56015798e-02 9.95027483e-01 9.86547112e-01 9.34382439e-01\n",
            " 8.86077225e-01 9.99960184e-01 9.96682227e-01 9.98047471e-01\n",
            " 9.83492732e-01 9.08549964e-01 9.90587294e-01 9.92579281e-01\n",
            " 9.84753609e-01 9.82866466e-01 4.51975912e-01 9.62233007e-01\n",
            " 9.51488614e-01 9.87469196e-01 9.98885810e-01 2.63258815e-01\n",
            " 9.24246371e-01 1.73356488e-01 7.66308963e-01 6.75898850e-01\n",
            " 9.98661995e-01 9.99089837e-01 4.65168417e-01 8.49611700e-01\n",
            " 9.99900460e-01 9.99321461e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 23 [0/107 (0%)]\tTrain Loss: 0.007687\n",
            "Train Epoch: 23 [4/107 (4%)]\tTrain Loss: 0.000268\n",
            "Train Epoch: 23 [8/107 (7%)]\tTrain Loss: 0.002485\n",
            "Train Epoch: 23 [12/107 (11%)]\tTrain Loss: 0.000350\n",
            "Train Epoch: 23 [16/107 (15%)]\tTrain Loss: 0.005840\n",
            "Train Epoch: 23 [20/107 (19%)]\tTrain Loss: 0.013790\n",
            "Train Epoch: 23 [24/107 (22%)]\tTrain Loss: 0.049427\n",
            "Train Epoch: 23 [28/107 (26%)]\tTrain Loss: 0.040034\n",
            "Train Epoch: 23 [32/107 (30%)]\tTrain Loss: 0.004482\n",
            "Train Epoch: 23 [36/107 (34%)]\tTrain Loss: 0.016603\n",
            "Train Epoch: 23 [40/107 (37%)]\tTrain Loss: 0.125765\n",
            "Train Epoch: 23 [44/107 (41%)]\tTrain Loss: 0.014949\n",
            "Train Epoch: 23 [48/107 (45%)]\tTrain Loss: 0.004813\n",
            "Train Epoch: 23 [52/107 (49%)]\tTrain Loss: 0.011377\n",
            "Train Epoch: 23 [56/107 (52%)]\tTrain Loss: 0.004685\n",
            "Train Epoch: 23 [60/107 (56%)]\tTrain Loss: 0.000535\n",
            "Train Epoch: 23 [64/107 (60%)]\tTrain Loss: 0.002078\n",
            "Train Epoch: 23 [68/107 (64%)]\tTrain Loss: 0.001390\n",
            "Train Epoch: 23 [72/107 (67%)]\tTrain Loss: 0.001060\n",
            "Train Epoch: 23 [76/107 (71%)]\tTrain Loss: 0.005922\n",
            "Train Epoch: 23 [80/107 (75%)]\tTrain Loss: 0.037056\n",
            "Train Epoch: 23 [84/107 (79%)]\tTrain Loss: 0.010198\n",
            "Train Epoch: 23 [88/107 (82%)]\tTrain Loss: 0.003277\n",
            "Train Epoch: 23 [92/107 (86%)]\tTrain Loss: 0.055529\n",
            "Train Epoch: 23 [96/107 (90%)]\tTrain Loss: 0.206508\n",
            "Train Epoch: 23 [100/107 (93%)]\tTrain Loss: 0.001039\n",
            "Train Epoch: 23 [104/107 (97%)]\tTrain Loss: 0.000990\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.49091813e-02 5.00617504e-01 1.25365913e-01 3.52057107e-02\n",
            " 2.11393740e-03 5.90561181e-02 8.23709488e-01 4.17169258e-02\n",
            " 2.78196692e-01 2.04770546e-02 1.41383335e-01 4.82758060e-02\n",
            " 1.40199304e-01 2.64347211e-04 6.62357634e-05 4.26853134e-04\n",
            " 7.31863431e-04 1.73798040e-03 2.75485712e-04 1.83603652e-02\n",
            " 3.09975836e-02 1.37107149e-01 8.74000490e-01 9.99210954e-01\n",
            " 4.12390023e-01 9.93418336e-01 5.62018752e-01 6.37083501e-03\n",
            " 1.03142741e-03 2.02513440e-03 2.61714286e-03 2.36490997e-03\n",
            " 3.97349847e-03 1.18317912e-04 3.13867698e-04 1.30046497e-03\n",
            " 5.77733736e-04 4.11562026e-02 6.39063399e-03 1.21648412e-03\n",
            " 7.62727344e-04 1.74829422e-03 1.17462147e-02 2.61748908e-03\n",
            " 2.25524947e-01 2.21890919e-02 1.79696903e-01 1.91425458e-02\n",
            " 2.81481832e-01 5.74509650e-02 7.39472985e-01 2.36838127e-06\n",
            " 7.64652577e-05 5.46393625e-04 2.83244050e-13 5.21484367e-07\n",
            " 1.70044485e-04 1.51561784e-11 2.23765473e-05 1.86966601e-04\n",
            " 9.63200688e-01 8.07887495e-01 7.97517240e-01 8.12981188e-01\n",
            " 7.72888839e-01 7.29443133e-01 5.72566152e-01 9.99436438e-01\n",
            " 9.65174556e-01 7.83096015e-01 3.36672157e-01 1.51975751e-01\n",
            " 4.19326603e-01 9.64908779e-01 2.31083527e-01 1.99911073e-01\n",
            " 9.02030706e-01 8.93816769e-01 9.98755574e-01 4.85642731e-01\n",
            " 9.30749536e-01 9.36165750e-01 9.96764302e-01 8.80487729e-03\n",
            " 4.28608447e-01 9.98576045e-01 9.93745923e-01 9.94401515e-01\n",
            " 1.91592262e-03 3.60345572e-01 9.79601383e-01 7.52912229e-03\n",
            " 3.79223712e-02 9.99999404e-01 9.89820361e-01 9.76714253e-01\n",
            " 9.47176576e-01 8.08905587e-02 4.77976143e-01 6.58580065e-01\n",
            " 6.35815322e-01 1.62190109e-01 1.21868756e-02 1.15265297e-02\n",
            " 8.55156500e-03 4.05078828e-02 9.35625851e-01 2.72573729e-04\n",
            " 1.07847305e-03 8.88829061e-04 2.16435175e-03 4.25307866e-04\n",
            " 4.24713284e-01 9.99253929e-01 9.25121550e-03 4.53866413e-03\n",
            " 9.80017841e-01 8.06713879e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 24 [0/107 (0%)]\tTrain Loss: 0.024604\n",
            "Train Epoch: 24 [4/107 (4%)]\tTrain Loss: 0.007506\n",
            "Train Epoch: 24 [8/107 (7%)]\tTrain Loss: 0.031267\n",
            "Train Epoch: 24 [12/107 (11%)]\tTrain Loss: 0.004651\n",
            "Train Epoch: 24 [16/107 (15%)]\tTrain Loss: 0.022345\n",
            "Train Epoch: 24 [20/107 (19%)]\tTrain Loss: 0.000606\n",
            "Train Epoch: 24 [24/107 (22%)]\tTrain Loss: 0.001879\n",
            "Train Epoch: 24 [28/107 (26%)]\tTrain Loss: 0.001445\n",
            "Train Epoch: 24 [32/107 (30%)]\tTrain Loss: 0.003619\n",
            "Train Epoch: 24 [36/107 (34%)]\tTrain Loss: 0.057055\n",
            "Train Epoch: 24 [40/107 (37%)]\tTrain Loss: 0.077648\n",
            "Train Epoch: 24 [44/107 (41%)]\tTrain Loss: 0.008619\n",
            "Train Epoch: 24 [48/107 (45%)]\tTrain Loss: 0.116680\n",
            "Train Epoch: 24 [52/107 (49%)]\tTrain Loss: 0.004753\n",
            "Train Epoch: 24 [56/107 (52%)]\tTrain Loss: 0.000122\n",
            "Train Epoch: 24 [60/107 (56%)]\tTrain Loss: 0.004118\n",
            "Train Epoch: 24 [64/107 (60%)]\tTrain Loss: 0.008686\n",
            "Train Epoch: 24 [68/107 (64%)]\tTrain Loss: 0.000724\n",
            "Train Epoch: 24 [72/107 (67%)]\tTrain Loss: 0.020037\n",
            "Train Epoch: 24 [76/107 (71%)]\tTrain Loss: 0.039537\n",
            "Train Epoch: 24 [80/107 (75%)]\tTrain Loss: 0.009663\n",
            "Train Epoch: 24 [84/107 (79%)]\tTrain Loss: 0.012053\n",
            "Train Epoch: 24 [88/107 (82%)]\tTrain Loss: 0.003293\n",
            "Train Epoch: 24 [92/107 (86%)]\tTrain Loss: 0.002181\n",
            "Train Epoch: 24 [96/107 (90%)]\tTrain Loss: 0.005482\n",
            "Train Epoch: 24 [100/107 (93%)]\tTrain Loss: 0.004958\n",
            "Train Epoch: 24 [104/107 (97%)]\tTrain Loss: 0.011572\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.49488931e-02 9.50140297e-01 1.22642249e-01 7.63634980e-01\n",
            " 4.76574386e-03 2.88144443e-02 9.46089149e-01 8.34586442e-01\n",
            " 1.15940543e-02 4.69395369e-01 6.38538301e-01 2.05798730e-01\n",
            " 8.61954451e-01 7.88518507e-03 2.69004540e-03 4.84331948e-04\n",
            " 1.00896147e-03 5.57148457e-01 1.19331013e-02 5.96849680e-01\n",
            " 2.78968275e-01 9.98856783e-01 9.92748559e-01 9.99998927e-01\n",
            " 9.82484162e-01 9.93475378e-01 9.96733308e-01 2.52442323e-02\n",
            " 1.08129485e-02 3.69649790e-02 7.17859762e-03 1.38816461e-01\n",
            " 5.32919049e-01 1.13101640e-04 7.04441918e-05 1.12233590e-03\n",
            " 6.91309618e-03 7.51250684e-01 6.87935054e-02 8.52042751e-04\n",
            " 5.27345983e-04 1.16233132e-03 7.90323198e-01 4.06307690e-02\n",
            " 9.81667757e-01 5.71571171e-01 9.55445826e-01 9.31998372e-01\n",
            " 5.97766459e-01 3.25367719e-01 9.59873140e-01 2.78994063e-04\n",
            " 3.29569040e-04 5.90717001e-03 8.09700929e-09 7.95177839e-05\n",
            " 1.10223278e-01 5.49724035e-08 1.93454267e-03 4.58994502e-04\n",
            " 9.99796093e-01 9.99413133e-01 9.99759614e-01 9.99570787e-01\n",
            " 9.73323941e-01 9.92069483e-01 9.92048919e-01 9.99997735e-01\n",
            " 9.91587341e-01 9.98691261e-01 9.82197583e-01 9.00705397e-01\n",
            " 9.84200001e-01 9.97306943e-01 8.53769660e-01 9.63399112e-01\n",
            " 9.91973400e-01 9.90717947e-01 9.99719203e-01 9.96620655e-01\n",
            " 9.99207079e-01 9.92420971e-01 9.98774946e-01 9.87716496e-01\n",
            " 8.93534780e-01 9.99511600e-01 9.99749482e-01 9.83620524e-01\n",
            " 8.62278417e-02 3.88546288e-01 9.51518476e-01 8.51229846e-01\n",
            " 7.45011568e-01 1.00000000e+00 9.99696851e-01 9.98244643e-01\n",
            " 9.96564567e-01 5.15957534e-01 8.86063278e-01 9.87497330e-01\n",
            " 9.39973891e-01 9.98119771e-01 9.12157714e-01 8.95153880e-01\n",
            " 9.71485496e-01 9.93663549e-01 9.99835014e-01 8.04035738e-03\n",
            " 5.23254350e-02 5.60422838e-01 1.62145704e-01 2.86021433e-03\n",
            " 9.72542644e-01 9.43879604e-01 3.80401522e-01 6.46606624e-01\n",
            " 9.99967575e-01 7.19363451e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 25 [0/107 (0%)]\tTrain Loss: 0.007286\n",
            "Train Epoch: 25 [4/107 (4%)]\tTrain Loss: 0.002267\n",
            "Train Epoch: 25 [8/107 (7%)]\tTrain Loss: 0.001815\n",
            "Train Epoch: 25 [12/107 (11%)]\tTrain Loss: 0.014284\n",
            "Train Epoch: 25 [16/107 (15%)]\tTrain Loss: 0.009072\n",
            "Train Epoch: 25 [20/107 (19%)]\tTrain Loss: 0.000702\n",
            "Train Epoch: 25 [24/107 (22%)]\tTrain Loss: 0.003145\n",
            "Train Epoch: 25 [28/107 (26%)]\tTrain Loss: 0.001312\n",
            "Train Epoch: 25 [32/107 (30%)]\tTrain Loss: 0.023042\n",
            "Train Epoch: 25 [36/107 (34%)]\tTrain Loss: 0.002445\n",
            "Train Epoch: 25 [40/107 (37%)]\tTrain Loss: 0.002741\n",
            "Train Epoch: 25 [44/107 (41%)]\tTrain Loss: 0.056963\n",
            "Train Epoch: 25 [48/107 (45%)]\tTrain Loss: 0.020313\n",
            "Train Epoch: 25 [52/107 (49%)]\tTrain Loss: 0.037873\n",
            "Train Epoch: 25 [56/107 (52%)]\tTrain Loss: 0.000906\n",
            "Train Epoch: 25 [60/107 (56%)]\tTrain Loss: 0.002059\n",
            "Train Epoch: 25 [64/107 (60%)]\tTrain Loss: 0.001012\n",
            "Train Epoch: 25 [68/107 (64%)]\tTrain Loss: 0.130000\n",
            "Train Epoch: 25 [72/107 (67%)]\tTrain Loss: 0.008442\n",
            "Train Epoch: 25 [76/107 (71%)]\tTrain Loss: 0.015510\n",
            "Train Epoch: 25 [80/107 (75%)]\tTrain Loss: 0.017966\n",
            "Train Epoch: 25 [84/107 (79%)]\tTrain Loss: 0.054012\n",
            "Train Epoch: 25 [88/107 (82%)]\tTrain Loss: 0.001800\n",
            "Train Epoch: 25 [92/107 (86%)]\tTrain Loss: 0.006066\n",
            "Train Epoch: 25 [96/107 (90%)]\tTrain Loss: 0.010113\n",
            "Train Epoch: 25 [100/107 (93%)]\tTrain Loss: 0.006648\n",
            "Train Epoch: 25 [104/107 (97%)]\tTrain Loss: 0.001658\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [4.24551195e-04 9.22363549e-02 8.83493572e-04 2.33685061e-01\n",
            " 2.18996633e-04 5.39249461e-03 1.52633265e-02 2.68417060e-01\n",
            " 6.09237977e-05 1.24300718e-01 2.73067713e-01 1.30700886e-01\n",
            " 8.35366070e-01 1.33375739e-04 8.50798097e-05 2.41043512e-03\n",
            " 4.79245670e-02 7.58121861e-03 2.85866030e-04 7.60853710e-03\n",
            " 5.95187023e-03 9.95685339e-01 9.27436233e-01 9.95586872e-01\n",
            " 9.71058786e-01 9.83477890e-01 9.98476684e-01 3.94552480e-04\n",
            " 1.25085586e-04 2.53277074e-04 1.57527206e-03 2.40573604e-02\n",
            " 2.03972101e-01 1.07706839e-03 2.18713260e-03 1.74381188e-03\n",
            " 2.82565467e-02 9.23086941e-01 8.20782036e-02 6.88668457e-04\n",
            " 3.04617948e-04 4.78574977e-04 2.80807167e-01 3.39483866e-03\n",
            " 2.75552645e-02 7.58538663e-01 4.79823947e-01 5.04779577e-01\n",
            " 2.57735521e-01 1.33906633e-01 7.89155841e-01 4.93573680e-06\n",
            " 4.21248797e-06 6.72408380e-03 2.55714790e-11 5.43648866e-06\n",
            " 9.77733638e-04 2.11655624e-11 1.41118770e-04 6.09380868e-06\n",
            " 9.39224005e-01 9.35555398e-01 9.74074423e-01 9.50944006e-01\n",
            " 9.43533480e-02 9.78579104e-01 9.42683220e-01 9.98422980e-01\n",
            " 8.41896832e-01 9.89616990e-01 7.95601606e-01 5.44329166e-01\n",
            " 8.61161053e-01 9.60787714e-01 1.40744701e-01 1.78700924e-01\n",
            " 8.03395450e-01 8.53628397e-01 9.86394763e-01 9.15387750e-01\n",
            " 9.92959142e-01 9.40007985e-01 9.87250447e-01 8.20112526e-01\n",
            " 2.44292721e-01 9.98538375e-01 5.06479502e-01 8.30275789e-02\n",
            " 1.56482303e-04 9.76763844e-01 9.78987396e-01 8.22150052e-01\n",
            " 8.38063478e-01 9.99975324e-01 9.99357522e-01 9.75610673e-01\n",
            " 2.48155504e-01 7.02157855e-01 8.51714194e-01 9.87140775e-01\n",
            " 2.14207396e-01 9.14997876e-01 2.13248312e-01 9.33448672e-01\n",
            " 9.58420634e-01 9.69986260e-01 9.97684240e-01 1.01913124e-01\n",
            " 9.67309028e-02 5.59415556e-02 1.12845995e-01 2.99120564e-02\n",
            " 9.69688237e-01 8.66139174e-01 9.87151265e-02 3.73534501e-01\n",
            " 9.99471724e-01 3.22009921e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
            "Train Epoch: 26 [0/107 (0%)]\tTrain Loss: 0.002349\n",
            "Train Epoch: 26 [4/107 (4%)]\tTrain Loss: 0.064423\n",
            "Train Epoch: 26 [8/107 (7%)]\tTrain Loss: 0.001330\n",
            "Train Epoch: 26 [12/107 (11%)]\tTrain Loss: 0.003270\n",
            "Train Epoch: 26 [16/107 (15%)]\tTrain Loss: 0.001479\n",
            "Train Epoch: 26 [20/107 (19%)]\tTrain Loss: 0.004528\n",
            "Train Epoch: 26 [24/107 (22%)]\tTrain Loss: 0.000440\n",
            "Train Epoch: 26 [28/107 (26%)]\tTrain Loss: 0.001724\n",
            "Train Epoch: 26 [32/107 (30%)]\tTrain Loss: 0.010153\n",
            "Train Epoch: 26 [36/107 (34%)]\tTrain Loss: 0.000420\n",
            "Train Epoch: 26 [40/107 (37%)]\tTrain Loss: 0.000179\n",
            "Train Epoch: 26 [44/107 (41%)]\tTrain Loss: 0.004783\n",
            "Train Epoch: 26 [48/107 (45%)]\tTrain Loss: 0.011785\n",
            "Train Epoch: 26 [52/107 (49%)]\tTrain Loss: 0.012849\n",
            "Train Epoch: 26 [56/107 (52%)]\tTrain Loss: 0.001837\n",
            "Train Epoch: 26 [60/107 (56%)]\tTrain Loss: 0.000719\n",
            "Train Epoch: 26 [64/107 (60%)]\tTrain Loss: 0.002202\n",
            "Train Epoch: 26 [68/107 (64%)]\tTrain Loss: 0.003426\n",
            "Train Epoch: 26 [72/107 (67%)]\tTrain Loss: 0.004618\n",
            "Train Epoch: 26 [76/107 (71%)]\tTrain Loss: 0.148380\n",
            "Train Epoch: 26 [80/107 (75%)]\tTrain Loss: 0.011453\n",
            "Train Epoch: 26 [84/107 (79%)]\tTrain Loss: 0.001258\n",
            "Train Epoch: 26 [88/107 (82%)]\tTrain Loss: 0.014653\n",
            "Train Epoch: 26 [92/107 (86%)]\tTrain Loss: 0.001147\n",
            "Train Epoch: 26 [96/107 (90%)]\tTrain Loss: 0.036306\n",
            "Train Epoch: 26 [100/107 (93%)]\tTrain Loss: 0.081155\n",
            "Train Epoch: 26 [104/107 (97%)]\tTrain Loss: 0.028658\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [9.82516678e-04 1.36169530e-02 2.66648130e-03 5.08728670e-03\n",
            " 3.30800394e-05 2.85743386e-04 8.20289459e-03 6.23937836e-03\n",
            " 4.23827150e-05 4.72496152e-02 4.97652404e-02 8.99843033e-03\n",
            " 8.64123553e-02 1.11541059e-03 8.38338805e-04 1.70977728e-04\n",
            " 1.88686873e-03 5.59879513e-03 9.84407496e-04 1.68898895e-01\n",
            " 4.49962392e-02 6.72732890e-01 6.31672740e-01 9.94199276e-01\n",
            " 4.20633048e-01 3.76610518e-01 9.02161077e-02 1.26378133e-03\n",
            " 2.60395173e-04 6.76835421e-04 3.02441535e-03 7.32620433e-03\n",
            " 1.22174755e-01 1.28960499e-04 1.52131353e-04 6.45147287e-04\n",
            " 1.71515811e-03 1.86948478e-01 2.12169997e-03 1.26827232e-04\n",
            " 7.21183169e-05 1.21047196e-04 2.18797907e-01 1.55125670e-02\n",
            " 2.98168063e-01 3.58293429e-02 8.57470185e-02 8.65097418e-02\n",
            " 1.11368418e-01 1.38991438e-02 6.67857885e-01 2.05572268e-10\n",
            " 1.49417090e-07 1.10069755e-06 2.29453343e-20 3.67276387e-09\n",
            " 1.99421220e-06 1.05662800e-18 7.02863616e-08 3.94312519e-06\n",
            " 9.64468420e-01 9.29939210e-01 9.35163796e-01 9.29097831e-01\n",
            " 2.51735002e-01 4.51115727e-01 6.84479594e-01 9.98611212e-01\n",
            " 9.50461328e-01 9.64053035e-01 8.05753827e-01 8.05873394e-01\n",
            " 4.97527987e-01 5.62299609e-01 1.10585600e-01 9.08438444e-01\n",
            " 9.57784712e-01 9.84819770e-01 8.98905218e-01 9.79643941e-01\n",
            " 9.81831908e-01 8.02204370e-01 9.62960303e-01 9.62034643e-01\n",
            " 7.23250270e-01 9.96322155e-01 9.71718729e-01 9.57242727e-01\n",
            " 4.37583216e-03 4.31542039e-01 9.05971169e-01 9.46579948e-02\n",
            " 5.94939813e-02 9.99623060e-01 9.51150596e-01 8.82039726e-01\n",
            " 1.21130068e-02 4.33733046e-01 6.63209796e-01 3.19406927e-01\n",
            " 3.32329050e-02 9.07816172e-01 5.71375228e-02 5.85655391e-01\n",
            " 3.71412247e-01 1.96459100e-01 6.55324817e-01 5.65220043e-03\n",
            " 6.07071072e-03 5.80713898e-03 1.71389468e-02 2.39194880e-04\n",
            " 4.64161903e-01 7.16950297e-01 5.55384252e-03 7.47671783e-01\n",
            " 9.91544962e-01 3.56100768e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
            "Train Epoch: 27 [0/107 (0%)]\tTrain Loss: 0.007097\n",
            "Train Epoch: 27 [4/107 (4%)]\tTrain Loss: 0.057480\n",
            "Train Epoch: 27 [8/107 (7%)]\tTrain Loss: 0.005273\n",
            "Train Epoch: 27 [12/107 (11%)]\tTrain Loss: 0.004336\n",
            "Train Epoch: 27 [16/107 (15%)]\tTrain Loss: 0.000254\n",
            "Train Epoch: 27 [20/107 (19%)]\tTrain Loss: 0.001441\n",
            "Train Epoch: 27 [24/107 (22%)]\tTrain Loss: 0.013529\n",
            "Train Epoch: 27 [28/107 (26%)]\tTrain Loss: 0.128510\n",
            "Train Epoch: 27 [32/107 (30%)]\tTrain Loss: 0.001257\n",
            "Train Epoch: 27 [36/107 (34%)]\tTrain Loss: 0.046471\n",
            "Train Epoch: 27 [40/107 (37%)]\tTrain Loss: 0.002712\n",
            "Train Epoch: 27 [44/107 (41%)]\tTrain Loss: 0.007621\n",
            "Train Epoch: 27 [48/107 (45%)]\tTrain Loss: 0.007394\n",
            "Train Epoch: 27 [52/107 (49%)]\tTrain Loss: 0.000260\n",
            "Train Epoch: 27 [56/107 (52%)]\tTrain Loss: 0.023962\n",
            "Train Epoch: 27 [60/107 (56%)]\tTrain Loss: 0.000559\n",
            "Train Epoch: 27 [64/107 (60%)]\tTrain Loss: 0.000493\n",
            "Train Epoch: 27 [68/107 (64%)]\tTrain Loss: 0.025627\n",
            "Train Epoch: 27 [72/107 (67%)]\tTrain Loss: 0.002196\n",
            "Train Epoch: 27 [76/107 (71%)]\tTrain Loss: 0.001594\n",
            "Train Epoch: 27 [80/107 (75%)]\tTrain Loss: 0.000449\n",
            "Train Epoch: 27 [84/107 (79%)]\tTrain Loss: 0.001962\n",
            "Train Epoch: 27 [88/107 (82%)]\tTrain Loss: 0.001259\n",
            "Train Epoch: 27 [92/107 (86%)]\tTrain Loss: 0.001071\n",
            "Train Epoch: 27 [96/107 (90%)]\tTrain Loss: 0.000500\n",
            "Train Epoch: 27 [100/107 (93%)]\tTrain Loss: 0.001117\n",
            "Train Epoch: 27 [104/107 (97%)]\tTrain Loss: 0.066189\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.14871664e-02 5.82106709e-01 2.35475376e-02 9.92692411e-01\n",
            " 1.58887565e-01 7.61597157e-02 3.47160101e-01 9.98197973e-01\n",
            " 9.61617567e-03 8.01009476e-01 6.44999325e-01 6.56988382e-01\n",
            " 9.94351268e-01 8.86178374e-01 8.24446857e-01 1.30545311e-02\n",
            " 7.06809461e-01 1.26072928e-01 7.70046655e-03 4.72499639e-01\n",
            " 5.59694052e-01 8.66947651e-01 9.26768482e-01 9.99833584e-01\n",
            " 8.55977595e-01 6.88665450e-01 9.93789136e-01 1.17842434e-02\n",
            " 6.19132025e-03 4.15554270e-03 1.41739950e-01 2.98991144e-01\n",
            " 9.38760698e-01 1.22534437e-03 1.09963526e-03 3.36543680e-03\n",
            " 1.91856977e-02 8.65071595e-01 4.53116268e-01 3.32948868e-03\n",
            " 4.66979574e-04 1.24374940e-03 7.21770823e-01 1.73792005e-01\n",
            " 7.84205437e-01 2.17912108e-01 9.49273646e-01 2.76421517e-01\n",
            " 4.04989570e-01 1.06898122e-01 9.30362284e-01 2.36862036e-03\n",
            " 3.08041647e-03 1.98195726e-02 8.39150402e-08 8.88155599e-04\n",
            " 1.94986656e-01 1.01941362e-06 7.97045883e-03 3.60235316e-03\n",
            " 9.95453596e-01 9.81937408e-01 9.93408680e-01 9.92162764e-01\n",
            " 9.86930013e-01 9.99770343e-01 9.99950051e-01 9.99850988e-01\n",
            " 9.99954700e-01 9.91357446e-01 9.63354647e-01 8.38183463e-01\n",
            " 9.96992350e-01 9.96066749e-01 9.79043484e-01 9.90247786e-01\n",
            " 9.93711472e-01 9.92770970e-01 9.99722540e-01 9.98841584e-01\n",
            " 9.99907851e-01 9.99215007e-01 9.99877095e-01 9.92004693e-01\n",
            " 9.56108928e-01 9.88596022e-01 9.86938953e-01 9.89832759e-01\n",
            " 4.44115639e-01 9.99957919e-01 9.99968648e-01 9.85579014e-01\n",
            " 9.97407734e-01 1.00000000e+00 9.99998689e-01 9.99993682e-01\n",
            " 4.59895402e-01 9.79625344e-01 9.58510935e-01 9.98864532e-01\n",
            " 1.53175145e-01 9.97865498e-01 8.61983001e-01 9.98392761e-01\n",
            " 9.95921373e-01 9.99772370e-01 9.98123825e-01 1.73705928e-02\n",
            " 6.88277185e-01 8.98716867e-01 2.86421835e-01 2.12061219e-02\n",
            " 9.99968886e-01 9.99090791e-01 7.74705708e-01 9.16114867e-01\n",
            " 9.99862909e-01 9.98483360e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 28 [0/107 (0%)]\tTrain Loss: 0.003192\n",
            "Train Epoch: 28 [4/107 (4%)]\tTrain Loss: 0.007071\n",
            "Train Epoch: 28 [8/107 (7%)]\tTrain Loss: 0.004418\n",
            "Train Epoch: 28 [12/107 (11%)]\tTrain Loss: 0.001669\n",
            "Train Epoch: 28 [16/107 (15%)]\tTrain Loss: 0.000194\n",
            "Train Epoch: 28 [20/107 (19%)]\tTrain Loss: 0.002041\n",
            "Train Epoch: 28 [24/107 (22%)]\tTrain Loss: 0.007758\n",
            "Train Epoch: 28 [28/107 (26%)]\tTrain Loss: 0.080254\n",
            "Train Epoch: 28 [32/107 (30%)]\tTrain Loss: 0.001727\n",
            "Train Epoch: 28 [36/107 (34%)]\tTrain Loss: 0.001228\n",
            "Train Epoch: 28 [40/107 (37%)]\tTrain Loss: 0.001691\n",
            "Train Epoch: 28 [44/107 (41%)]\tTrain Loss: 0.014633\n",
            "Train Epoch: 28 [48/107 (45%)]\tTrain Loss: 0.000720\n",
            "Train Epoch: 28 [52/107 (49%)]\tTrain Loss: 0.000502\n",
            "Train Epoch: 28 [56/107 (52%)]\tTrain Loss: 0.001524\n",
            "Train Epoch: 28 [60/107 (56%)]\tTrain Loss: 0.000300\n",
            "Train Epoch: 28 [64/107 (60%)]\tTrain Loss: 0.000766\n",
            "Train Epoch: 28 [68/107 (64%)]\tTrain Loss: 0.007385\n",
            "Train Epoch: 28 [72/107 (67%)]\tTrain Loss: 0.008220\n",
            "Train Epoch: 28 [76/107 (71%)]\tTrain Loss: 0.033514\n",
            "Train Epoch: 28 [80/107 (75%)]\tTrain Loss: 0.001774\n",
            "Train Epoch: 28 [84/107 (79%)]\tTrain Loss: 0.004055\n",
            "Train Epoch: 28 [88/107 (82%)]\tTrain Loss: 0.003924\n",
            "Train Epoch: 28 [92/107 (86%)]\tTrain Loss: 0.002433\n",
            "Train Epoch: 28 [96/107 (90%)]\tTrain Loss: 0.000087\n",
            "Train Epoch: 28 [100/107 (93%)]\tTrain Loss: 0.000442\n",
            "Train Epoch: 28 [104/107 (97%)]\tTrain Loss: 0.002074\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [8.02749395e-03 2.53059208e-01 2.55795538e-01 3.65197420e-01\n",
            " 6.38284662e-04 4.94226068e-03 7.82879055e-01 9.33288217e-01\n",
            " 2.67766393e-03 2.40314994e-02 4.92683798e-02 9.50323865e-02\n",
            " 3.54474694e-01 1.36159047e-01 1.08248822e-01 5.34268402e-05\n",
            " 2.91051081e-04 4.32928558e-03 1.54630470e-04 2.26416904e-02\n",
            " 1.40185177e-01 9.78770673e-01 7.95981765e-01 9.99703705e-01\n",
            " 7.07574725e-01 6.73701227e-01 9.99923348e-01 5.30149788e-03\n",
            " 1.74148692e-04 4.80128510e-04 2.72011429e-01 5.38441725e-03\n",
            " 1.50884941e-01 1.35233977e-05 1.35864266e-05 5.16299624e-04\n",
            " 1.51596672e-03 6.06909275e-01 8.66986156e-01 7.99102522e-03\n",
            " 7.17389921e-04 3.44148558e-03 2.07080334e-01 5.62077463e-02\n",
            " 8.27607989e-01 4.22340482e-01 9.73900676e-01 1.70479670e-01\n",
            " 9.83719826e-01 8.38536859e-01 9.98865843e-01 5.04211675e-06\n",
            " 5.59781711e-06 1.35149655e-03 1.38585796e-10 4.90849743e-05\n",
            " 1.66747235e-02 2.15815851e-10 2.82086781e-04 3.86210857e-04\n",
            " 9.97965217e-01 9.97183740e-01 9.99516726e-01 9.99057353e-01\n",
            " 9.98139977e-01 9.97832835e-01 9.87530470e-01 9.99999046e-01\n",
            " 9.99441326e-01 9.70357001e-01 9.90780771e-01 9.49096978e-01\n",
            " 9.99205887e-01 9.93561625e-01 9.68402982e-01 9.96305585e-01\n",
            " 9.99656916e-01 9.99814332e-01 9.99908924e-01 9.98267055e-01\n",
            " 9.99966383e-01 9.99716699e-01 9.99917746e-01 9.96301413e-01\n",
            " 9.77935016e-01 9.55422223e-01 9.10448730e-01 9.04759407e-01\n",
            " 4.16777981e-03 9.99871254e-01 9.98614311e-01 5.97684503e-01\n",
            " 3.27123612e-01 9.99999881e-01 9.99995112e-01 9.99920368e-01\n",
            " 3.59564694e-03 9.84156549e-01 4.49819803e-01 9.95464265e-01\n",
            " 3.40677083e-01 9.91436303e-01 4.78791982e-01 4.95210201e-01\n",
            " 4.87259299e-01 8.88865888e-01 8.69143665e-01 3.53491702e-03\n",
            " 6.77813068e-02 4.82611567e-01 1.37865514e-01 5.92591474e-03\n",
            " 9.99440253e-01 8.29812527e-01 6.51961863e-02 4.31346685e-01\n",
            " 9.99970198e-01 9.99259770e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 29 [0/107 (0%)]\tTrain Loss: 0.000361\n",
            "Train Epoch: 29 [4/107 (4%)]\tTrain Loss: 0.011068\n",
            "Train Epoch: 29 [8/107 (7%)]\tTrain Loss: 0.001231\n",
            "Train Epoch: 29 [12/107 (11%)]\tTrain Loss: 0.001030\n",
            "Train Epoch: 29 [16/107 (15%)]\tTrain Loss: 0.000364\n",
            "Train Epoch: 29 [20/107 (19%)]\tTrain Loss: 0.001385\n",
            "Train Epoch: 29 [24/107 (22%)]\tTrain Loss: 0.000912\n",
            "Train Epoch: 29 [28/107 (26%)]\tTrain Loss: 0.000165\n",
            "Train Epoch: 29 [32/107 (30%)]\tTrain Loss: 0.144815\n",
            "Train Epoch: 29 [36/107 (34%)]\tTrain Loss: 0.007359\n",
            "Train Epoch: 29 [40/107 (37%)]\tTrain Loss: 0.001176\n",
            "Train Epoch: 29 [44/107 (41%)]\tTrain Loss: 0.002389\n",
            "Train Epoch: 29 [48/107 (45%)]\tTrain Loss: 0.010400\n",
            "Train Epoch: 29 [52/107 (49%)]\tTrain Loss: 0.002354\n",
            "Train Epoch: 29 [56/107 (52%)]\tTrain Loss: 0.002099\n",
            "Train Epoch: 29 [60/107 (56%)]\tTrain Loss: 0.014209\n",
            "Train Epoch: 29 [64/107 (60%)]\tTrain Loss: 0.018053\n",
            "Train Epoch: 29 [68/107 (64%)]\tTrain Loss: 0.002519\n",
            "Train Epoch: 29 [72/107 (67%)]\tTrain Loss: 0.003526\n",
            "Train Epoch: 29 [76/107 (71%)]\tTrain Loss: 0.002337\n",
            "Train Epoch: 29 [80/107 (75%)]\tTrain Loss: 0.005984\n",
            "Train Epoch: 29 [84/107 (79%)]\tTrain Loss: 0.010725\n",
            "Train Epoch: 29 [88/107 (82%)]\tTrain Loss: 0.000808\n",
            "Train Epoch: 29 [92/107 (86%)]\tTrain Loss: 0.003633\n",
            "Train Epoch: 29 [96/107 (90%)]\tTrain Loss: 0.003185\n",
            "Train Epoch: 29 [100/107 (93%)]\tTrain Loss: 0.003444\n",
            "Train Epoch: 29 [104/107 (97%)]\tTrain Loss: 0.004522\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [4.12105396e-02 9.70516980e-01 6.12784147e-01 7.85959542e-01\n",
            " 8.63691978e-03 1.43952370e-01 9.85574365e-01 9.20025468e-01\n",
            " 1.17480256e-01 8.86335313e-01 3.76922786e-01 8.81840765e-01\n",
            " 7.07766116e-01 1.19718276e-01 8.86684284e-02 9.52101080e-04\n",
            " 9.16082412e-04 2.01548740e-01 1.10962458e-01 3.54737461e-01\n",
            " 4.86722827e-01 9.97927189e-01 9.93809402e-01 9.99435246e-01\n",
            " 9.83665645e-01 9.66896653e-01 9.00390327e-01 7.02483594e-01\n",
            " 1.37407053e-02 1.80893429e-02 1.86026677e-01 3.24609339e-01\n",
            " 2.08170712e-01 3.71030401e-05 2.57357897e-05 1.64847041e-03\n",
            " 4.32652794e-02 9.91188288e-01 8.91290128e-01 3.77003686e-03\n",
            " 4.91535407e-04 9.95934661e-03 8.93742979e-01 9.30023491e-01\n",
            " 9.95904744e-01 9.00471151e-01 9.92825985e-01 8.86094034e-01\n",
            " 9.89161968e-01 9.55107927e-01 9.99556482e-01 2.79370488e-05\n",
            " 3.69841064e-06 3.09379231e-02 1.00035201e-13 8.75912025e-04\n",
            " 4.99939732e-02 4.09786544e-13 2.64094298e-04 6.77953940e-05\n",
            " 9.99551237e-01 9.99620438e-01 9.99732435e-01 9.99678373e-01\n",
            " 9.97374296e-01 9.99199450e-01 9.97822523e-01 9.99997139e-01\n",
            " 9.98264015e-01 9.98463273e-01 9.99610007e-01 9.98903394e-01\n",
            " 9.90349531e-01 9.98341322e-01 9.93698180e-01 9.99811232e-01\n",
            " 9.99162197e-01 9.99513507e-01 9.99949694e-01 9.98973966e-01\n",
            " 9.99931455e-01 9.99708593e-01 9.99971509e-01 9.98466492e-01\n",
            " 9.90049124e-01 9.99733269e-01 9.99260366e-01 9.99440730e-01\n",
            " 1.34299859e-01 9.87637043e-01 9.98594820e-01 9.72398400e-01\n",
            " 9.15994287e-01 9.99999881e-01 9.99985218e-01 9.99839187e-01\n",
            " 9.61904526e-01 9.91887987e-01 9.88364220e-01 9.93467033e-01\n",
            " 4.42317784e-01 9.98905420e-01 8.84982347e-01 9.64299917e-01\n",
            " 8.03146780e-01 9.97621834e-01 9.99104679e-01 7.11183965e-01\n",
            " 1.71995517e-02 7.90110673e-04 5.20838678e-01 6.41409913e-03\n",
            " 9.96024370e-01 9.99392986e-01 1.84076577e-01 9.23380196e-01\n",
            " 9.99797046e-01 9.94339883e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 30 [0/107 (0%)]\tTrain Loss: 0.001153\n",
            "Train Epoch: 30 [4/107 (4%)]\tTrain Loss: 0.002356\n",
            "Train Epoch: 30 [8/107 (7%)]\tTrain Loss: 0.003163\n",
            "Train Epoch: 30 [12/107 (11%)]\tTrain Loss: 0.008831\n",
            "Train Epoch: 30 [16/107 (15%)]\tTrain Loss: 0.000114\n",
            "Train Epoch: 30 [20/107 (19%)]\tTrain Loss: 0.040239\n",
            "Train Epoch: 30 [24/107 (22%)]\tTrain Loss: 0.000312\n",
            "Train Epoch: 30 [28/107 (26%)]\tTrain Loss: 0.001661\n",
            "Train Epoch: 30 [32/107 (30%)]\tTrain Loss: 0.000444\n",
            "Train Epoch: 30 [36/107 (34%)]\tTrain Loss: 0.095419\n",
            "Train Epoch: 30 [40/107 (37%)]\tTrain Loss: 0.023654\n",
            "Train Epoch: 30 [44/107 (41%)]\tTrain Loss: 0.010666\n",
            "Train Epoch: 30 [48/107 (45%)]\tTrain Loss: 0.083264\n",
            "Train Epoch: 30 [52/107 (49%)]\tTrain Loss: 0.252424\n",
            "Train Epoch: 30 [56/107 (52%)]\tTrain Loss: 0.002611\n",
            "Train Epoch: 30 [60/107 (56%)]\tTrain Loss: 0.008615\n",
            "Train Epoch: 30 [64/107 (60%)]\tTrain Loss: 0.005685\n",
            "Train Epoch: 30 [68/107 (64%)]\tTrain Loss: 0.006097\n",
            "Train Epoch: 30 [72/107 (67%)]\tTrain Loss: 0.003348\n",
            "Train Epoch: 30 [76/107 (71%)]\tTrain Loss: 0.006783\n",
            "Train Epoch: 30 [80/107 (75%)]\tTrain Loss: 0.012409\n",
            "Train Epoch: 30 [84/107 (79%)]\tTrain Loss: 0.004419\n",
            "Train Epoch: 30 [88/107 (82%)]\tTrain Loss: 0.000753\n",
            "Train Epoch: 30 [92/107 (86%)]\tTrain Loss: 0.001714\n",
            "Train Epoch: 30 [96/107 (90%)]\tTrain Loss: 0.000932\n",
            "Train Epoch: 30 [100/107 (93%)]\tTrain Loss: 0.023060\n",
            "Train Epoch: 30 [104/107 (97%)]\tTrain Loss: 0.010807\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.98975573e-02 9.06378865e-01 6.84302598e-02 9.42595959e-01\n",
            " 6.15692092e-03 7.25184008e-02 8.15806270e-01 5.99784434e-01\n",
            " 8.99026170e-03 5.06279171e-01 5.38735867e-01 6.83017969e-01\n",
            " 5.49013078e-01 8.15088272e-01 6.62452400e-01 3.13122151e-03\n",
            " 3.42582958e-03 7.01457411e-02 8.88898522e-02 2.82783508e-01\n",
            " 4.99376774e-01 9.96059835e-01 9.84534144e-01 9.99799907e-01\n",
            " 9.81067181e-01 8.84472072e-01 9.99655366e-01 4.73785967e-01\n",
            " 6.87234998e-01 4.72805709e-01 9.70714748e-01 2.80205101e-01\n",
            " 7.40577459e-01 6.02447835e-05 1.28022846e-04 7.76420161e-03\n",
            " 1.47357769e-02 8.88833046e-01 3.85105401e-01 3.99643177e-04\n",
            " 4.21732293e-05 2.35881540e-03 3.17162186e-01 9.75333229e-02\n",
            " 6.75707102e-01 9.79882404e-02 9.26654458e-01 5.51949143e-01\n",
            " 9.49281216e-01 1.28530025e-01 8.95266175e-01 6.30048930e-07\n",
            " 5.97363760e-05 2.19404721e-03 6.66168967e-16 4.16768989e-06\n",
            " 1.21761963e-03 7.23597682e-14 2.37171480e-04 2.14920525e-04\n",
            " 9.93942797e-01 9.76855755e-01 9.85342264e-01 9.80204999e-01\n",
            " 7.23236918e-01 9.87252474e-01 9.56360281e-01 9.99651670e-01\n",
            " 9.57258761e-01 2.88611233e-01 9.77368593e-01 8.86964977e-01\n",
            " 9.25873578e-01 9.70557630e-01 8.59789014e-01 9.84985113e-01\n",
            " 9.51959491e-01 9.63449895e-01 9.99606311e-01 9.89395916e-01\n",
            " 9.99145627e-01 9.38409448e-01 9.99628425e-01 9.97829616e-01\n",
            " 9.84677315e-01 9.95635450e-01 9.91522789e-01 9.90717590e-01\n",
            " 6.71926975e-01 9.98873055e-01 9.99753773e-01 8.95484328e-01\n",
            " 7.77592301e-01 1.00000000e+00 9.99999762e-01 9.99997616e-01\n",
            " 9.76594746e-01 9.91029859e-01 9.96177673e-01 9.96334195e-01\n",
            " 9.76215124e-01 9.80832040e-01 9.28728998e-01 9.30001915e-01\n",
            " 9.67009604e-01 9.94109273e-01 9.99950051e-01 3.63760501e-01\n",
            " 1.52800664e-01 1.32987440e-01 5.62456667e-01 3.28795239e-02\n",
            " 9.99966025e-01 9.99830246e-01 1.07056372e-01 7.75284111e-01\n",
            " 9.99995947e-01 9.99697804e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "vote_pred [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "TP= 49 TN= 45 FN= 9 FP= 15\n",
            "TP+FP 64\n",
            "precision 0.765625\n",
            "recall 0.8448275862068966\n",
            "F1 0.8032786885245901\n",
            "acc 0.7966101694915254\n",
            "AUCp 0.7974137931034483\n",
            "AUC 0.8787356321839082\n",
            "\n",
            " The epoch is 30, average recall: 0.8448, average precision: 0.7656,average F1: 0.8033, average accuracy: 0.7966, average AUC: 0.8787\n",
            "Train Epoch: 31 [0/107 (0%)]\tTrain Loss: 0.002050\n",
            "Train Epoch: 31 [4/107 (4%)]\tTrain Loss: 0.000642\n",
            "Train Epoch: 31 [8/107 (7%)]\tTrain Loss: 0.000158\n",
            "Train Epoch: 31 [12/107 (11%)]\tTrain Loss: 0.188741\n",
            "Train Epoch: 31 [16/107 (15%)]\tTrain Loss: 0.072678\n",
            "Train Epoch: 31 [20/107 (19%)]\tTrain Loss: 0.013580\n",
            "Train Epoch: 31 [24/107 (22%)]\tTrain Loss: 0.008592\n",
            "Train Epoch: 31 [28/107 (26%)]\tTrain Loss: 0.000270\n",
            "Train Epoch: 31 [32/107 (30%)]\tTrain Loss: 0.024046\n",
            "Train Epoch: 31 [36/107 (34%)]\tTrain Loss: 0.002054\n",
            "Train Epoch: 31 [40/107 (37%)]\tTrain Loss: 0.000472\n",
            "Train Epoch: 31 [44/107 (41%)]\tTrain Loss: 0.000236\n",
            "Train Epoch: 31 [48/107 (45%)]\tTrain Loss: 0.001063\n",
            "Train Epoch: 31 [52/107 (49%)]\tTrain Loss: 0.000112\n",
            "Train Epoch: 31 [56/107 (52%)]\tTrain Loss: 0.035387\n",
            "Train Epoch: 31 [60/107 (56%)]\tTrain Loss: 0.008781\n",
            "Train Epoch: 31 [64/107 (60%)]\tTrain Loss: 0.000806\n",
            "Train Epoch: 31 [68/107 (64%)]\tTrain Loss: 0.044592\n",
            "Train Epoch: 31 [72/107 (67%)]\tTrain Loss: 0.000345\n",
            "Train Epoch: 31 [76/107 (71%)]\tTrain Loss: 0.000704\n",
            "Train Epoch: 31 [80/107 (75%)]\tTrain Loss: 0.002638\n",
            "Train Epoch: 31 [84/107 (79%)]\tTrain Loss: 0.001593\n",
            "Train Epoch: 31 [88/107 (82%)]\tTrain Loss: 0.000585\n",
            "Train Epoch: 31 [92/107 (86%)]\tTrain Loss: 0.001200\n",
            "Train Epoch: 31 [96/107 (90%)]\tTrain Loss: 0.002922\n",
            "Train Epoch: 31 [100/107 (93%)]\tTrain Loss: 0.009722\n",
            "Train Epoch: 31 [104/107 (97%)]\tTrain Loss: 0.048764\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.97743102e-05 4.58230138e-01 2.26013601e-01 2.27627873e-01\n",
            " 3.91535359e-05 2.11137522e-05 1.05768874e-01 5.75790942e-01\n",
            " 1.57664556e-06 5.73419854e-02 1.14634889e-03 1.94696650e-01\n",
            " 5.49749061e-02 7.67342772e-06 6.94239179e-06 7.42416546e-07\n",
            " 3.24153888e-07 1.51349204e-02 3.94869967e-05 1.51954743e-03\n",
            " 4.86126775e-03 9.48231399e-01 1.76317856e-01 9.99145031e-01\n",
            " 7.69252777e-01 1.25290649e-02 8.98001492e-01 1.55225222e-04\n",
            " 2.29891407e-06 9.23762582e-06 6.87407504e-04 8.68305273e-04\n",
            " 4.34648682e-04 1.98390264e-08 5.91272320e-09 1.12044211e-06\n",
            " 3.80070196e-06 8.15207660e-01 4.40857839e-03 5.69275585e-07\n",
            " 2.73038921e-07 1.78526329e-06 2.61202723e-01 7.26287079e-04\n",
            " 1.64595127e-01 4.13526455e-03 2.56063223e-01 2.74553925e-01\n",
            " 8.84599566e-01 2.47722387e-01 9.88659620e-01 7.20516979e-10\n",
            " 7.52859464e-09 4.54076940e-07 4.21918206e-20 6.92117226e-08\n",
            " 3.75539879e-04 1.60015236e-18 2.07977814e-06 2.32849118e-07\n",
            " 9.98711705e-01 9.90868092e-01 9.91169572e-01 9.89833355e-01\n",
            " 6.26821995e-01 8.36461067e-01 5.34003258e-01 9.99995112e-01\n",
            " 9.97121036e-01 6.94063127e-01 9.81254339e-01 8.41490269e-01\n",
            " 1.78368725e-02 9.78184402e-01 6.24239072e-02 7.74093270e-01\n",
            " 9.99346912e-01 9.99216318e-01 9.99678731e-01 9.79650497e-01\n",
            " 9.99951839e-01 9.45996165e-01 9.99771059e-01 9.95725989e-01\n",
            " 9.88868475e-01 9.97471452e-01 9.79266346e-01 9.71653581e-01\n",
            " 3.12225384e-05 6.06178679e-03 9.41776454e-01 2.11536977e-02\n",
            " 2.72829738e-02 1.00000000e+00 9.99999166e-01 9.94045258e-01\n",
            " 1.04699749e-03 7.64236331e-01 6.42712593e-01 1.24597706e-01\n",
            " 5.50006926e-02 9.95137990e-01 2.84598238e-04 3.82816121e-02\n",
            " 3.76193458e-03 3.54163945e-02 9.92411494e-01 3.39406281e-04\n",
            " 3.57891440e-05 1.62962842e-05 4.99580754e-04 4.29747706e-05\n",
            " 7.84784019e-01 7.19464302e-01 5.42233975e-05 8.40826018e-04\n",
            " 9.99998450e-01 9.67679322e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 32 [0/107 (0%)]\tTrain Loss: 0.000329\n",
            "Train Epoch: 32 [4/107 (4%)]\tTrain Loss: 0.033493\n",
            "Train Epoch: 32 [8/107 (7%)]\tTrain Loss: 0.005927\n",
            "Train Epoch: 32 [12/107 (11%)]\tTrain Loss: 0.000177\n",
            "Train Epoch: 32 [16/107 (15%)]\tTrain Loss: 0.000242\n",
            "Train Epoch: 32 [20/107 (19%)]\tTrain Loss: 0.079568\n",
            "Train Epoch: 32 [24/107 (22%)]\tTrain Loss: 0.023232\n",
            "Train Epoch: 32 [28/107 (26%)]\tTrain Loss: 0.001187\n",
            "Train Epoch: 32 [32/107 (30%)]\tTrain Loss: 0.000964\n",
            "Train Epoch: 32 [36/107 (34%)]\tTrain Loss: 0.002101\n",
            "Train Epoch: 32 [40/107 (37%)]\tTrain Loss: 0.000282\n",
            "Train Epoch: 32 [44/107 (41%)]\tTrain Loss: 0.001404\n",
            "Train Epoch: 32 [48/107 (45%)]\tTrain Loss: 0.003753\n",
            "Train Epoch: 32 [52/107 (49%)]\tTrain Loss: 0.000806\n",
            "Train Epoch: 32 [56/107 (52%)]\tTrain Loss: 0.008863\n",
            "Train Epoch: 32 [60/107 (56%)]\tTrain Loss: 0.001870\n",
            "Train Epoch: 32 [64/107 (60%)]\tTrain Loss: 0.000202\n",
            "Train Epoch: 32 [68/107 (64%)]\tTrain Loss: 0.000890\n",
            "Train Epoch: 32 [72/107 (67%)]\tTrain Loss: 0.006555\n",
            "Train Epoch: 32 [76/107 (71%)]\tTrain Loss: 0.002979\n",
            "Train Epoch: 32 [80/107 (75%)]\tTrain Loss: 0.003852\n",
            "Train Epoch: 32 [84/107 (79%)]\tTrain Loss: 0.000573\n",
            "Train Epoch: 32 [88/107 (82%)]\tTrain Loss: 0.000994\n",
            "Train Epoch: 32 [92/107 (86%)]\tTrain Loss: 0.001464\n",
            "Train Epoch: 32 [96/107 (90%)]\tTrain Loss: 0.007920\n",
            "Train Epoch: 32 [100/107 (93%)]\tTrain Loss: 0.014877\n",
            "Train Epoch: 32 [104/107 (97%)]\tTrain Loss: 0.000302\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.23987971e-02 9.97396111e-01 9.05729532e-01 9.89204884e-01\n",
            " 2.66075701e-01 3.23496968e-03 9.66468215e-01 9.95200038e-01\n",
            " 1.68828573e-03 1.03720397e-01 2.84649104e-01 4.09281880e-01\n",
            " 9.48763490e-01 5.35715930e-02 1.81559511e-02 1.40786252e-03\n",
            " 7.42857170e-04 1.02719873e-01 2.36779233e-04 7.68586025e-02\n",
            " 1.09400153e-01 9.78774428e-01 9.96161342e-01 9.99755204e-01\n",
            " 9.08445656e-01 8.95796537e-01 9.98344779e-01 5.89063540e-02\n",
            " 1.28250255e-03 8.91737919e-03 2.46826723e-01 1.62343070e-01\n",
            " 8.80666599e-02 1.35764021e-05 1.67263679e-05 2.58295238e-03\n",
            " 8.12052097e-03 9.96778667e-01 9.59210873e-01 2.74580158e-02\n",
            " 9.85033996e-03 2.15905462e-03 9.41621006e-01 3.46439898e-01\n",
            " 9.72203553e-01 4.60768789e-01 9.95788157e-01 9.36544955e-01\n",
            " 9.81015205e-01 9.11203623e-01 9.95505929e-01 6.21518848e-06\n",
            " 8.16932879e-06 2.94969301e-03 7.53593831e-16 1.43357965e-05\n",
            " 6.71280921e-01 1.18702274e-14 6.01718602e-05 5.01715578e-04\n",
            " 9.99856114e-01 9.99555290e-01 9.99662519e-01 9.99733865e-01\n",
            " 9.99214530e-01 9.99977827e-01 9.99813378e-01 9.99999285e-01\n",
            " 9.99922037e-01 9.99364316e-01 9.99820054e-01 9.99706089e-01\n",
            " 9.90440845e-01 9.99696374e-01 9.94689345e-01 9.68968809e-01\n",
            " 9.99681115e-01 9.99509573e-01 9.99998927e-01 9.99821603e-01\n",
            " 9.99999046e-01 9.99893665e-01 9.99902487e-01 9.98894513e-01\n",
            " 9.99321699e-01 9.99952078e-01 9.99569476e-01 9.99599278e-01\n",
            " 4.06108797e-03 9.93500888e-01 9.99490857e-01 9.56507623e-01\n",
            " 9.84770060e-01 9.99999881e-01 9.99988914e-01 9.97132182e-01\n",
            " 4.13153946e-01 9.95502889e-01 9.93069351e-01 9.99929309e-01\n",
            " 9.69555616e-01 9.99886036e-01 7.67199695e-01 3.50339860e-01\n",
            " 6.99770033e-01 8.83207798e-01 9.99988079e-01 4.58882339e-02\n",
            " 8.44902247e-02 1.79854948e-02 6.78978860e-02 1.74077209e-02\n",
            " 9.99454916e-01 9.99014735e-01 5.60602546e-01 7.86855638e-01\n",
            " 9.99995589e-01 9.99941587e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 33 [0/107 (0%)]\tTrain Loss: 0.000476\n",
            "Train Epoch: 33 [4/107 (4%)]\tTrain Loss: 0.006797\n",
            "Train Epoch: 33 [8/107 (7%)]\tTrain Loss: 0.020459\n",
            "Train Epoch: 33 [12/107 (11%)]\tTrain Loss: 0.000571\n",
            "Train Epoch: 33 [16/107 (15%)]\tTrain Loss: 0.000313\n",
            "Train Epoch: 33 [20/107 (19%)]\tTrain Loss: 0.038389\n",
            "Train Epoch: 33 [24/107 (22%)]\tTrain Loss: 0.009682\n",
            "Train Epoch: 33 [28/107 (26%)]\tTrain Loss: 0.001186\n",
            "Train Epoch: 33 [32/107 (30%)]\tTrain Loss: 0.001008\n",
            "Train Epoch: 33 [36/107 (34%)]\tTrain Loss: 0.000362\n",
            "Train Epoch: 33 [40/107 (37%)]\tTrain Loss: 0.000299\n",
            "Train Epoch: 33 [44/107 (41%)]\tTrain Loss: 0.002223\n",
            "Train Epoch: 33 [48/107 (45%)]\tTrain Loss: 0.004044\n",
            "Train Epoch: 33 [52/107 (49%)]\tTrain Loss: 0.004203\n",
            "Train Epoch: 33 [56/107 (52%)]\tTrain Loss: 0.003672\n",
            "Train Epoch: 33 [60/107 (56%)]\tTrain Loss: 0.005014\n",
            "Train Epoch: 33 [64/107 (60%)]\tTrain Loss: 0.000525\n",
            "Train Epoch: 33 [68/107 (64%)]\tTrain Loss: 0.003985\n",
            "Train Epoch: 33 [72/107 (67%)]\tTrain Loss: 0.011832\n",
            "Train Epoch: 33 [76/107 (71%)]\tTrain Loss: 0.014754\n",
            "Train Epoch: 33 [80/107 (75%)]\tTrain Loss: 0.000137\n",
            "Train Epoch: 33 [84/107 (79%)]\tTrain Loss: 0.001102\n",
            "Train Epoch: 33 [88/107 (82%)]\tTrain Loss: 0.010139\n",
            "Train Epoch: 33 [92/107 (86%)]\tTrain Loss: 0.001810\n",
            "Train Epoch: 33 [96/107 (90%)]\tTrain Loss: 0.000840\n",
            "Train Epoch: 33 [100/107 (93%)]\tTrain Loss: 0.000355\n",
            "Train Epoch: 33 [104/107 (97%)]\tTrain Loss: 0.001195\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.39007845e-03 6.90270662e-01 6.84218556e-02 7.38331497e-01\n",
            " 1.34747825e-03 1.43835583e-04 5.89279942e-02 2.66632020e-01\n",
            " 7.55996189e-06 9.89615917e-01 9.50847626e-01 8.78765523e-01\n",
            " 9.58978415e-01 8.91103991e-05 3.20323270e-05 3.53449001e-03\n",
            " 2.64990435e-04 6.57377392e-02 5.73393190e-03 5.21967337e-02\n",
            " 9.07610357e-01 9.99798834e-01 9.99257386e-01 9.99689698e-01\n",
            " 9.91682112e-01 9.91359234e-01 9.79566991e-01 2.71927402e-03\n",
            " 9.10914532e-05 7.44394900e-04 4.41228709e-04 2.43442599e-03\n",
            " 1.56549830e-03 9.00125378e-05 7.72851999e-05 2.18038214e-03\n",
            " 7.26459967e-03 9.97394443e-01 4.65471119e-01 4.23340220e-03\n",
            " 9.53153940e-04 1.00094487e-03 9.32248950e-01 5.21607995e-01\n",
            " 9.72753406e-01 7.68281594e-02 8.80675793e-01 4.67256635e-01\n",
            " 2.20260352e-01 1.77201465e-01 9.42595482e-01 6.58811623e-05\n",
            " 4.13961288e-06 3.72848264e-03 9.91424418e-14 2.64675400e-05\n",
            " 1.59520119e-01 5.28193178e-14 6.43214677e-04 2.58640711e-07\n",
            " 9.97645915e-01 9.98836100e-01 9.95587230e-01 9.94011104e-01\n",
            " 9.01226282e-01 9.98576760e-01 9.54539299e-01 9.99999523e-01\n",
            " 9.98343825e-01 9.72665668e-01 9.98475373e-01 9.91135359e-01\n",
            " 4.33323175e-01 9.62226868e-01 6.00309908e-01 9.84252274e-01\n",
            " 9.93983805e-01 9.66728091e-01 9.94499683e-01 9.83151197e-01\n",
            " 9.99916911e-01 9.95890498e-01 9.98883307e-01 9.99321461e-01\n",
            " 9.99271810e-01 9.97743249e-01 9.98843312e-01 9.62622166e-01\n",
            " 1.10053818e-03 9.91118610e-01 9.98754263e-01 7.96601117e-01\n",
            " 8.91925633e-01 9.99999523e-01 9.99981046e-01 9.98593867e-01\n",
            " 9.82902646e-01 9.90241349e-01 9.57916915e-01 9.98639166e-01\n",
            " 9.89057243e-01 9.93578315e-01 4.49669212e-01 8.89730513e-01\n",
            " 5.62039733e-01 9.89058316e-01 9.97675478e-01 4.28244211e-02\n",
            " 6.11782167e-03 2.23006122e-03 5.11266924e-02 1.89909339e-03\n",
            " 5.87723017e-01 9.99707520e-01 4.58679348e-03 8.81938159e-01\n",
            " 9.99877930e-01 9.98465657e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 34 [0/107 (0%)]\tTrain Loss: 0.011320\n",
            "Train Epoch: 34 [4/107 (4%)]\tTrain Loss: 0.000372\n",
            "Train Epoch: 34 [8/107 (7%)]\tTrain Loss: 0.011639\n",
            "Train Epoch: 34 [12/107 (11%)]\tTrain Loss: 0.000395\n",
            "Train Epoch: 34 [16/107 (15%)]\tTrain Loss: 0.000385\n",
            "Train Epoch: 34 [20/107 (19%)]\tTrain Loss: 0.023550\n",
            "Train Epoch: 34 [24/107 (22%)]\tTrain Loss: 0.002902\n",
            "Train Epoch: 34 [28/107 (26%)]\tTrain Loss: 0.019813\n",
            "Train Epoch: 34 [32/107 (30%)]\tTrain Loss: 0.001460\n",
            "Train Epoch: 34 [36/107 (34%)]\tTrain Loss: 0.003776\n",
            "Train Epoch: 34 [40/107 (37%)]\tTrain Loss: 0.001140\n",
            "Train Epoch: 34 [44/107 (41%)]\tTrain Loss: 0.002082\n",
            "Train Epoch: 34 [48/107 (45%)]\tTrain Loss: 0.000907\n",
            "Train Epoch: 34 [52/107 (49%)]\tTrain Loss: 0.030554\n",
            "Train Epoch: 34 [56/107 (52%)]\tTrain Loss: 0.005255\n",
            "Train Epoch: 34 [60/107 (56%)]\tTrain Loss: 0.052269\n",
            "Train Epoch: 34 [64/107 (60%)]\tTrain Loss: 0.001195\n",
            "Train Epoch: 34 [68/107 (64%)]\tTrain Loss: 0.004208\n",
            "Train Epoch: 34 [72/107 (67%)]\tTrain Loss: 0.224466\n",
            "Train Epoch: 34 [76/107 (71%)]\tTrain Loss: 0.000598\n",
            "Train Epoch: 34 [80/107 (75%)]\tTrain Loss: 0.000703\n",
            "Train Epoch: 34 [84/107 (79%)]\tTrain Loss: 0.002346\n",
            "Train Epoch: 34 [88/107 (82%)]\tTrain Loss: 0.001283\n",
            "Train Epoch: 34 [92/107 (86%)]\tTrain Loss: 0.007623\n",
            "Train Epoch: 34 [96/107 (90%)]\tTrain Loss: 0.002724\n",
            "Train Epoch: 34 [100/107 (93%)]\tTrain Loss: 0.000248\n",
            "Train Epoch: 34 [104/107 (97%)]\tTrain Loss: 0.007536\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.26598257e-04 9.93538797e-01 9.92319956e-02 1.87224954e-01\n",
            " 2.98007013e-04 5.19819441e-04 6.47690654e-01 4.10877287e-01\n",
            " 2.06974637e-05 3.07531327e-01 2.53300786e-01 1.88333318e-02\n",
            " 1.07834175e-01 8.09790625e-04 2.15770840e-03 9.31115635e-03\n",
            " 4.69779037e-03 7.92405531e-02 5.07006014e-04 2.27667484e-02\n",
            " 3.76177818e-01 9.36179578e-01 9.07136917e-01 9.95481968e-01\n",
            " 7.74935424e-01 9.85820532e-01 9.95877743e-01 1.07922005e-02\n",
            " 1.12502945e-04 1.08025037e-04 2.52402723e-02 2.25196942e-03\n",
            " 1.58763845e-02 9.84487560e-05 3.69324989e-05 1.85341842e-03\n",
            " 1.41626195e-04 9.29365695e-01 5.42741343e-02 7.74115615e-04\n",
            " 2.16234985e-04 2.86348019e-04 2.24720284e-01 2.01805425e-03\n",
            " 1.23308249e-01 1.52592231e-02 5.73483825e-01 3.32195789e-01\n",
            " 4.10273820e-01 3.13263476e-01 9.79742706e-01 3.86790052e-04\n",
            " 1.30027789e-03 1.01566993e-01 1.93458177e-07 1.13160560e-04\n",
            " 7.35025227e-01 4.85130691e-08 1.29197177e-03 3.61522762e-05\n",
            " 9.93984997e-01 9.90824103e-01 9.82042730e-01 9.30726051e-01\n",
            " 9.57330346e-01 9.08339977e-01 9.71261859e-01 9.99959588e-01\n",
            " 9.99757349e-01 9.86595571e-01 9.97417808e-01 9.54809606e-01\n",
            " 2.46694311e-01 7.76285648e-01 1.99025646e-02 1.15403570e-01\n",
            " 8.98920536e-01 9.92249131e-01 9.98903394e-01 8.02068710e-01\n",
            " 9.98479664e-01 9.70405698e-01 9.98345137e-01 7.44292259e-01\n",
            " 6.72854260e-02 9.90122139e-01 9.43644941e-01 9.00380671e-01\n",
            " 3.97867057e-03 1.52156293e-01 9.53590095e-01 1.45971164e-01\n",
            " 1.26664042e-02 9.99977589e-01 9.99206722e-01 9.97082293e-01\n",
            " 3.46982956e-01 9.92945254e-01 4.27194864e-01 9.95658994e-01\n",
            " 9.63893056e-01 1.71841055e-01 2.02190243e-02 3.93021286e-01\n",
            " 5.22958457e-01 9.27163363e-01 9.79368985e-01 8.00436304e-04\n",
            " 1.42807013e-03 1.70803759e-02 4.19195835e-03 3.55874114e-02\n",
            " 9.85527635e-01 3.50317746e-01 3.72623047e-03 1.22414939e-02\n",
            " 9.99830842e-01 4.97923553e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
            "Train Epoch: 35 [0/107 (0%)]\tTrain Loss: 0.024332\n",
            "Train Epoch: 35 [4/107 (4%)]\tTrain Loss: 0.004393\n",
            "Train Epoch: 35 [8/107 (7%)]\tTrain Loss: 0.009084\n",
            "Train Epoch: 35 [12/107 (11%)]\tTrain Loss: 0.000603\n",
            "Train Epoch: 35 [16/107 (15%)]\tTrain Loss: 0.001273\n",
            "Train Epoch: 35 [20/107 (19%)]\tTrain Loss: 0.001511\n",
            "Train Epoch: 35 [24/107 (22%)]\tTrain Loss: 0.033791\n",
            "Train Epoch: 35 [28/107 (26%)]\tTrain Loss: 0.000810\n",
            "Train Epoch: 35 [32/107 (30%)]\tTrain Loss: 0.000736\n",
            "Train Epoch: 35 [36/107 (34%)]\tTrain Loss: 0.001278\n",
            "Train Epoch: 35 [40/107 (37%)]\tTrain Loss: 0.000103\n",
            "Train Epoch: 35 [44/107 (41%)]\tTrain Loss: 0.002123\n",
            "Train Epoch: 35 [48/107 (45%)]\tTrain Loss: 0.000619\n",
            "Train Epoch: 35 [52/107 (49%)]\tTrain Loss: 0.007870\n",
            "Train Epoch: 35 [56/107 (52%)]\tTrain Loss: 0.000107\n",
            "Train Epoch: 35 [60/107 (56%)]\tTrain Loss: 0.001990\n",
            "Train Epoch: 35 [64/107 (60%)]\tTrain Loss: 0.000327\n",
            "Train Epoch: 35 [68/107 (64%)]\tTrain Loss: 0.000376\n",
            "Train Epoch: 35 [72/107 (67%)]\tTrain Loss: 0.002393\n",
            "Train Epoch: 35 [76/107 (71%)]\tTrain Loss: 0.033780\n",
            "Train Epoch: 35 [80/107 (75%)]\tTrain Loss: 0.088690\n",
            "Train Epoch: 35 [84/107 (79%)]\tTrain Loss: 0.001627\n",
            "Train Epoch: 35 [88/107 (82%)]\tTrain Loss: 0.000614\n",
            "Train Epoch: 35 [92/107 (86%)]\tTrain Loss: 0.000427\n",
            "Train Epoch: 35 [96/107 (90%)]\tTrain Loss: 0.011087\n",
            "Train Epoch: 35 [100/107 (93%)]\tTrain Loss: 0.001655\n",
            "Train Epoch: 35 [104/107 (97%)]\tTrain Loss: 0.001284\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [6.93197409e-03 9.91496325e-01 1.97548255e-01 9.08464074e-01\n",
            " 5.28947450e-02 7.19304457e-02 3.74890089e-01 9.20052290e-01\n",
            " 1.37776928e-03 5.71503788e-02 8.75308454e-01 2.36950159e-01\n",
            " 9.55302954e-01 7.13860290e-03 7.84115959e-03 3.32542993e-02\n",
            " 2.00899784e-02 6.56474056e-03 5.02892165e-03 1.84468459e-02\n",
            " 6.85114413e-02 9.80721951e-01 3.82280588e-01 9.97071981e-01\n",
            " 9.86599565e-01 6.17450655e-01 9.89593625e-01 3.20881582e-03\n",
            " 2.34786002e-03 7.77785620e-03 2.56682318e-02 4.88485619e-02\n",
            " 1.18898764e-01 1.47825677e-03 1.12662755e-03 3.44170001e-03\n",
            " 2.55322200e-03 9.84470725e-01 8.46303165e-01 2.11541844e-03\n",
            " 2.67846719e-03 2.36857610e-04 5.19159555e-01 9.43081975e-02\n",
            " 1.47547871e-01 9.56172720e-02 9.27252114e-01 8.99393678e-01\n",
            " 8.04710627e-01 9.06366050e-01 9.90630686e-01 5.47770003e-04\n",
            " 2.27563505e-04 2.15959623e-02 1.25966733e-06 1.65621648e-04\n",
            " 8.76354098e-01 2.71635099e-06 3.49813327e-03 8.05569944e-05\n",
            " 9.99368370e-01 9.99567330e-01 9.98906493e-01 9.97546732e-01\n",
            " 4.18562949e-01 9.90185380e-01 9.95191455e-01 9.99949336e-01\n",
            " 9.99977231e-01 9.98646319e-01 9.94934499e-01 9.49015498e-01\n",
            " 8.11492264e-01 9.27176476e-01 3.74268331e-02 2.27283195e-01\n",
            " 9.93824720e-01 9.94083107e-01 9.99633908e-01 9.95478213e-01\n",
            " 9.99849081e-01 9.92448926e-01 9.99614835e-01 9.56038535e-01\n",
            " 9.56639424e-02 9.96967852e-01 8.48419607e-01 8.67728770e-01\n",
            " 8.70737806e-03 9.72384810e-01 9.99085546e-01 8.59012544e-01\n",
            " 5.12335837e-01 9.99998689e-01 9.99995470e-01 9.99983668e-01\n",
            " 9.42121804e-01 9.98069823e-01 8.92285109e-01 9.99720991e-01\n",
            " 8.36185932e-01 3.54912192e-01 6.58616364e-01 9.90392983e-01\n",
            " 9.75262105e-01 9.99551713e-01 9.97990608e-01 2.47793309e-02\n",
            " 6.58344150e-01 5.68707824e-01 4.92989756e-02 4.27653134e-01\n",
            " 9.99845624e-01 9.71903861e-01 1.42952979e-01 4.08158340e-02\n",
            " 9.99857903e-01 9.64130461e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 36 [0/107 (0%)]\tTrain Loss: 0.030407\n",
            "Train Epoch: 36 [4/107 (4%)]\tTrain Loss: 0.151314\n",
            "Train Epoch: 36 [8/107 (7%)]\tTrain Loss: 0.004138\n",
            "Train Epoch: 36 [12/107 (11%)]\tTrain Loss: 0.004611\n",
            "Train Epoch: 36 [16/107 (15%)]\tTrain Loss: 0.115165\n",
            "Train Epoch: 36 [20/107 (19%)]\tTrain Loss: 0.000929\n",
            "Train Epoch: 36 [24/107 (22%)]\tTrain Loss: 0.002324\n",
            "Train Epoch: 36 [28/107 (26%)]\tTrain Loss: 0.001694\n",
            "Train Epoch: 36 [32/107 (30%)]\tTrain Loss: 0.000277\n",
            "Train Epoch: 36 [36/107 (34%)]\tTrain Loss: 0.000670\n",
            "Train Epoch: 36 [40/107 (37%)]\tTrain Loss: 0.007549\n",
            "Train Epoch: 36 [44/107 (41%)]\tTrain Loss: 0.004508\n",
            "Train Epoch: 36 [48/107 (45%)]\tTrain Loss: 0.016771\n",
            "Train Epoch: 36 [52/107 (49%)]\tTrain Loss: 0.000438\n",
            "Train Epoch: 36 [56/107 (52%)]\tTrain Loss: 0.008230\n",
            "Train Epoch: 36 [60/107 (56%)]\tTrain Loss: 0.000098\n",
            "Train Epoch: 36 [64/107 (60%)]\tTrain Loss: 0.000805\n",
            "Train Epoch: 36 [68/107 (64%)]\tTrain Loss: 0.013460\n",
            "Train Epoch: 36 [72/107 (67%)]\tTrain Loss: 0.003835\n",
            "Train Epoch: 36 [76/107 (71%)]\tTrain Loss: 0.073017\n",
            "Train Epoch: 36 [80/107 (75%)]\tTrain Loss: 0.001272\n",
            "Train Epoch: 36 [84/107 (79%)]\tTrain Loss: 0.001665\n",
            "Train Epoch: 36 [88/107 (82%)]\tTrain Loss: 0.000546\n",
            "Train Epoch: 36 [92/107 (86%)]\tTrain Loss: 0.003457\n",
            "Train Epoch: 36 [96/107 (90%)]\tTrain Loss: 0.090707\n",
            "Train Epoch: 36 [100/107 (93%)]\tTrain Loss: 0.000764\n",
            "Train Epoch: 36 [104/107 (97%)]\tTrain Loss: 0.002302\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.75945337e-03 9.96572018e-01 5.69264770e-01 8.80229771e-01\n",
            " 4.09441348e-03 5.31955995e-02 8.82798374e-01 9.73064482e-01\n",
            " 3.21719646e-02 4.60399240e-01 9.59825933e-01 6.76319078e-02\n",
            " 8.92328382e-01 1.79726246e-03 3.96085456e-02 2.34206818e-04\n",
            " 4.77384962e-02 8.48065019e-01 1.65812466e-02 7.92794749e-02\n",
            " 4.27173346e-01 9.98392999e-01 9.96402025e-01 9.98377919e-01\n",
            " 9.93916929e-01 9.99368966e-01 9.61270630e-01 3.13380569e-01\n",
            " 1.76720042e-03 5.83372079e-03 1.43257856e-01 2.48932489e-03\n",
            " 2.29586557e-01 3.88941880e-05 3.49550864e-05 1.28144713e-03\n",
            " 9.78410710e-03 9.63856280e-01 2.07849920e-01 5.00921858e-04\n",
            " 5.95631544e-04 1.06122799e-03 9.43191528e-01 2.81729139e-02\n",
            " 3.37846756e-01 8.18267651e-03 7.66363740e-01 5.63118160e-01\n",
            " 8.06551933e-01 6.85320616e-01 9.65410471e-01 4.37590279e-05\n",
            " 2.03895965e-03 3.07940822e-02 1.56131247e-10 1.17419416e-03\n",
            " 2.53006399e-01 3.72643427e-09 1.01258792e-03 1.73472904e-03\n",
            " 9.99569118e-01 9.99681234e-01 9.98535395e-01 9.97325420e-01\n",
            " 9.87976372e-01 9.59425688e-01 9.95285332e-01 9.99998569e-01\n",
            " 9.99228477e-01 9.98357952e-01 9.36600626e-01 8.69309425e-01\n",
            " 8.56211126e-01 9.91118014e-01 9.79070902e-01 9.19543803e-01\n",
            " 9.99448359e-01 9.99686956e-01 9.99684215e-01 9.83498514e-01\n",
            " 9.99518991e-01 9.82645154e-01 9.98016596e-01 9.95745957e-01\n",
            " 2.85151362e-01 9.76145148e-01 9.94467854e-01 9.94609952e-01\n",
            " 2.68114120e-01 3.14067066e-01 9.90063488e-01 7.10814178e-01\n",
            " 7.66343296e-01 9.99978065e-01 9.99690056e-01 9.99349415e-01\n",
            " 8.82677794e-01 9.97292101e-01 9.27966356e-01 9.96447921e-01\n",
            " 3.91896188e-01 6.56333029e-01 7.56465673e-01 8.66016150e-01\n",
            " 9.27206755e-01 9.81270790e-01 9.91376996e-01 5.85349975e-04\n",
            " 3.93662065e-01 4.55990359e-02 1.74198207e-02 9.46185961e-02\n",
            " 9.81652915e-01 8.68552685e-01 7.57995173e-02 8.33547771e-01\n",
            " 9.99998569e-01 9.95077670e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 37 [0/107 (0%)]\tTrain Loss: 0.001329\n",
            "Train Epoch: 37 [4/107 (4%)]\tTrain Loss: 0.004008\n",
            "Train Epoch: 37 [8/107 (7%)]\tTrain Loss: 0.000064\n",
            "Train Epoch: 37 [12/107 (11%)]\tTrain Loss: 0.000357\n",
            "Train Epoch: 37 [16/107 (15%)]\tTrain Loss: 0.003857\n",
            "Train Epoch: 37 [20/107 (19%)]\tTrain Loss: 0.002040\n",
            "Train Epoch: 37 [24/107 (22%)]\tTrain Loss: 0.015386\n",
            "Train Epoch: 37 [28/107 (26%)]\tTrain Loss: 0.001438\n",
            "Train Epoch: 37 [32/107 (30%)]\tTrain Loss: 0.004007\n",
            "Train Epoch: 37 [36/107 (34%)]\tTrain Loss: 0.043046\n",
            "Train Epoch: 37 [40/107 (37%)]\tTrain Loss: 0.000560\n",
            "Train Epoch: 37 [44/107 (41%)]\tTrain Loss: 0.003110\n",
            "Train Epoch: 37 [48/107 (45%)]\tTrain Loss: 0.007586\n",
            "Train Epoch: 37 [52/107 (49%)]\tTrain Loss: 0.000934\n",
            "Train Epoch: 37 [56/107 (52%)]\tTrain Loss: 0.000913\n",
            "Train Epoch: 37 [60/107 (56%)]\tTrain Loss: 0.000689\n",
            "Train Epoch: 37 [64/107 (60%)]\tTrain Loss: 0.007964\n",
            "Train Epoch: 37 [68/107 (64%)]\tTrain Loss: 0.000369\n",
            "Train Epoch: 37 [72/107 (67%)]\tTrain Loss: 0.000124\n",
            "Train Epoch: 37 [76/107 (71%)]\tTrain Loss: 0.006874\n",
            "Train Epoch: 37 [80/107 (75%)]\tTrain Loss: 0.001964\n",
            "Train Epoch: 37 [84/107 (79%)]\tTrain Loss: 0.000940\n",
            "Train Epoch: 37 [88/107 (82%)]\tTrain Loss: 0.001188\n",
            "Train Epoch: 37 [92/107 (86%)]\tTrain Loss: 0.000327\n",
            "Train Epoch: 37 [96/107 (90%)]\tTrain Loss: 0.001040\n",
            "Train Epoch: 37 [100/107 (93%)]\tTrain Loss: 0.004445\n",
            "Train Epoch: 37 [104/107 (97%)]\tTrain Loss: 0.000273\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.34313917e-02 9.91171420e-01 1.54297754e-01 6.51853144e-01\n",
            " 1.68241635e-02 6.37516752e-02 7.31486857e-01 9.55342472e-01\n",
            " 2.62471545e-03 8.37992653e-02 6.18142664e-01 1.85479507e-01\n",
            " 8.36571038e-01 5.70210803e-04 7.46671925e-04 8.59502325e-05\n",
            " 6.94202352e-03 1.11896480e-02 3.35549033e-04 1.01506792e-03\n",
            " 1.00380749e-01 9.97239351e-01 3.24362248e-01 9.95370567e-01\n",
            " 9.88799512e-01 9.54568982e-01 9.80188370e-01 3.01372423e-03\n",
            " 1.30788510e-04 4.07089305e-04 2.75981147e-02 4.42302693e-03\n",
            " 5.91482455e-03 2.45232859e-05 1.70247313e-05 2.27457240e-05\n",
            " 6.72201859e-04 8.05123389e-01 2.68013090e-01 1.35717739e-04\n",
            " 2.00328752e-04 4.18432501e-05 8.52190495e-01 2.87699467e-03\n",
            " 1.52529627e-01 5.37980646e-02 9.43827569e-01 8.15699100e-01\n",
            " 9.18747365e-01 9.01722968e-01 9.81595457e-01 8.59640568e-06\n",
            " 2.18811474e-05 2.97462888e-04 1.33253519e-10 3.87464706e-06\n",
            " 6.02380514e-01 1.41888834e-09 8.32607620e-05 6.31255098e-05\n",
            " 9.99549329e-01 9.99806345e-01 9.99405980e-01 9.99368608e-01\n",
            " 9.93292451e-01 9.95085537e-01 9.88036633e-01 9.99989986e-01\n",
            " 9.99833465e-01 9.98336256e-01 9.97041523e-01 9.85727727e-01\n",
            " 9.48922634e-01 9.96108949e-01 9.18405175e-01 9.78551030e-01\n",
            " 9.99323845e-01 9.99521732e-01 9.99899030e-01 9.94093716e-01\n",
            " 9.99734700e-01 9.97288704e-01 9.99306679e-01 9.88632262e-01\n",
            " 4.78483230e-01 9.94340181e-01 9.94496524e-01 9.95269001e-01\n",
            " 5.02789160e-03 8.40617299e-01 9.95446742e-01 9.40029204e-01\n",
            " 9.48900402e-01 9.99964714e-01 9.99928355e-01 9.99730051e-01\n",
            " 5.24351776e-01 9.97064769e-01 8.98007631e-01 9.90589976e-01\n",
            " 2.42428899e-01 9.65760052e-01 4.97187644e-01 9.69197512e-01\n",
            " 9.90332186e-01 9.95324850e-01 9.97950971e-01 8.60708766e-04\n",
            " 1.24877319e-01 1.27545865e-02 1.41559998e-02 1.09150670e-01\n",
            " 9.87707675e-01 9.47227001e-01 3.74459177e-02 2.54770666e-01\n",
            " 9.99992847e-01 9.99479115e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 38 [0/107 (0%)]\tTrain Loss: 0.034538\n",
            "Train Epoch: 38 [4/107 (4%)]\tTrain Loss: 0.000200\n",
            "Train Epoch: 38 [8/107 (7%)]\tTrain Loss: 0.000158\n",
            "Train Epoch: 38 [12/107 (11%)]\tTrain Loss: 0.000524\n",
            "Train Epoch: 38 [16/107 (15%)]\tTrain Loss: 0.000605\n",
            "Train Epoch: 38 [20/107 (19%)]\tTrain Loss: 0.004321\n",
            "Train Epoch: 38 [24/107 (22%)]\tTrain Loss: 0.001327\n",
            "Train Epoch: 38 [28/107 (26%)]\tTrain Loss: 0.000094\n",
            "Train Epoch: 38 [32/107 (30%)]\tTrain Loss: 0.000518\n",
            "Train Epoch: 38 [36/107 (34%)]\tTrain Loss: 0.000026\n",
            "Train Epoch: 38 [40/107 (37%)]\tTrain Loss: 0.000142\n",
            "Train Epoch: 38 [44/107 (41%)]\tTrain Loss: 0.000556\n",
            "Train Epoch: 38 [48/107 (45%)]\tTrain Loss: 0.000065\n",
            "Train Epoch: 38 [52/107 (49%)]\tTrain Loss: 0.002282\n",
            "Train Epoch: 38 [56/107 (52%)]\tTrain Loss: 0.000036\n",
            "Train Epoch: 38 [60/107 (56%)]\tTrain Loss: 0.000069\n",
            "Train Epoch: 38 [64/107 (60%)]\tTrain Loss: 0.001471\n",
            "Train Epoch: 38 [68/107 (64%)]\tTrain Loss: 0.001370\n",
            "Train Epoch: 38 [72/107 (67%)]\tTrain Loss: 0.003282\n",
            "Train Epoch: 38 [76/107 (71%)]\tTrain Loss: 0.000229\n",
            "Train Epoch: 38 [80/107 (75%)]\tTrain Loss: 0.000962\n",
            "Train Epoch: 38 [84/107 (79%)]\tTrain Loss: 0.001307\n",
            "Train Epoch: 38 [88/107 (82%)]\tTrain Loss: 0.000022\n",
            "Train Epoch: 38 [92/107 (86%)]\tTrain Loss: 0.000190\n",
            "Train Epoch: 38 [96/107 (90%)]\tTrain Loss: 0.000035\n",
            "Train Epoch: 38 [100/107 (93%)]\tTrain Loss: 0.000481\n",
            "Train Epoch: 38 [104/107 (97%)]\tTrain Loss: 0.000039\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.91794655e-03 9.82089043e-01 3.72030661e-02 5.80114797e-02\n",
            " 2.83524423e-04 9.96925775e-03 1.15165964e-01 6.35537565e-01\n",
            " 3.91722977e-04 5.91720678e-02 3.59989524e-01 1.41935125e-01\n",
            " 6.12546444e-01 4.73916116e-05 1.06526539e-04 1.48905629e-05\n",
            " 1.20717756e-04 8.99052620e-03 2.33999468e-04 7.74869579e-04\n",
            " 1.16468780e-02 9.91491973e-01 5.62820584e-02 9.93816674e-01\n",
            " 9.85306263e-01 1.93308830e-01 9.16999817e-01 1.36960589e-04\n",
            " 3.29447648e-05 1.34038593e-04 1.86606264e-03 4.71982610e-04\n",
            " 8.82778317e-04 5.47676154e-06 1.40891427e-06 4.54520341e-06\n",
            " 7.20552853e-05 6.50522530e-01 6.55322820e-02 8.80338393e-06\n",
            " 2.36308897e-05 7.94393691e-06 9.06812310e-01 6.71997259e-04\n",
            " 1.90366469e-02 2.86694989e-03 6.82678938e-01 4.51839536e-01\n",
            " 3.35936904e-01 2.67026871e-01 9.58725333e-01 4.93616747e-09\n",
            " 7.43660109e-07 1.28315723e-05 1.46004939e-17 1.69384094e-07\n",
            " 6.75615435e-03 6.78238932e-15 6.07151151e-07 1.27046096e-05\n",
            " 9.99605000e-01 9.99728620e-01 9.99281228e-01 9.98948991e-01\n",
            " 8.58656585e-01 9.76617396e-01 9.85696077e-01 9.99987006e-01\n",
            " 9.99745190e-01 9.98910546e-01 9.93454874e-01 9.10574138e-01\n",
            " 8.93103838e-01 9.92805898e-01 6.38509929e-01 4.46163952e-01\n",
            " 9.98977780e-01 9.94099379e-01 9.99722540e-01 9.91154790e-01\n",
            " 9.99600112e-01 9.95728433e-01 9.99005497e-01 9.89356935e-01\n",
            " 1.73707634e-01 9.92464185e-01 9.83271658e-01 9.56166863e-01\n",
            " 1.32556900e-03 3.52454364e-01 9.92181778e-01 5.12012362e-01\n",
            " 7.07963407e-01 9.99981523e-01 9.99877810e-01 9.99015927e-01\n",
            " 3.19920927e-01 9.97082055e-01 9.25422609e-01 9.97752130e-01\n",
            " 7.40503490e-01 8.36617470e-01 1.92358017e-01 9.71813560e-01\n",
            " 9.76994336e-01 9.96326864e-01 9.97659802e-01 1.02417769e-04\n",
            " 4.70783859e-02 7.60712661e-04 2.32690549e-03 1.70572884e-02\n",
            " 9.71627355e-01 9.47865725e-01 5.33842249e-03 1.64469153e-01\n",
            " 9.99996185e-01 9.99383092e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 39 [0/107 (0%)]\tTrain Loss: 0.000141\n",
            "Train Epoch: 39 [4/107 (4%)]\tTrain Loss: 0.000469\n",
            "Train Epoch: 39 [8/107 (7%)]\tTrain Loss: 0.000029\n",
            "Train Epoch: 39 [12/107 (11%)]\tTrain Loss: 0.000114\n",
            "Train Epoch: 39 [16/107 (15%)]\tTrain Loss: 0.000047\n",
            "Train Epoch: 39 [20/107 (19%)]\tTrain Loss: 0.000738\n",
            "Train Epoch: 39 [24/107 (22%)]\tTrain Loss: 0.000131\n",
            "Train Epoch: 39 [28/107 (26%)]\tTrain Loss: 0.000078\n",
            "Train Epoch: 39 [32/107 (30%)]\tTrain Loss: 0.000064\n",
            "Train Epoch: 39 [36/107 (34%)]\tTrain Loss: 0.000742\n",
            "Train Epoch: 39 [40/107 (37%)]\tTrain Loss: 0.001250\n",
            "Train Epoch: 39 [44/107 (41%)]\tTrain Loss: 0.000758\n",
            "Train Epoch: 39 [48/107 (45%)]\tTrain Loss: 0.000029\n",
            "Train Epoch: 39 [52/107 (49%)]\tTrain Loss: 0.000039\n",
            "Train Epoch: 39 [56/107 (52%)]\tTrain Loss: 0.002424\n",
            "Train Epoch: 39 [60/107 (56%)]\tTrain Loss: 0.000182\n",
            "Train Epoch: 39 [64/107 (60%)]\tTrain Loss: 0.000014\n",
            "Train Epoch: 39 [68/107 (64%)]\tTrain Loss: 0.009096\n",
            "Train Epoch: 39 [72/107 (67%)]\tTrain Loss: 0.000015\n",
            "Train Epoch: 39 [76/107 (71%)]\tTrain Loss: 0.000079\n",
            "Train Epoch: 39 [80/107 (75%)]\tTrain Loss: 0.000028\n",
            "Train Epoch: 39 [84/107 (79%)]\tTrain Loss: 0.000680\n",
            "Train Epoch: 39 [88/107 (82%)]\tTrain Loss: 0.000295\n",
            "Train Epoch: 39 [92/107 (86%)]\tTrain Loss: 0.000080\n",
            "Train Epoch: 39 [96/107 (90%)]\tTrain Loss: 0.000064\n",
            "Train Epoch: 39 [100/107 (93%)]\tTrain Loss: 0.000085\n",
            "Train Epoch: 39 [104/107 (97%)]\tTrain Loss: 0.000075\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.03460436e-02 9.81997788e-01 6.61904365e-02 4.75722849e-01\n",
            " 1.22878039e-02 1.84831414e-02 2.06799507e-01 9.89064157e-01\n",
            " 1.36753928e-03 3.68068129e-01 9.28551853e-01 3.89756709e-01\n",
            " 9.81519938e-01 2.86084687e-04 5.67893730e-04 8.15162130e-05\n",
            " 3.77688603e-03 3.17100994e-02 3.01760650e-04 2.13516527e-03\n",
            " 6.30004108e-02 9.99361217e-01 3.91863912e-01 9.99331236e-01\n",
            " 9.94623184e-01 7.30731666e-01 9.77072835e-01 1.14072859e-03\n",
            " 4.97777692e-05 5.81162283e-04 2.57021142e-03 2.69879471e-03\n",
            " 3.50784441e-03 1.07737533e-05 3.44607270e-06 1.36030749e-05\n",
            " 4.32878558e-04 9.37890172e-01 3.99172813e-01 2.52979022e-04\n",
            " 3.81567370e-04 7.12802866e-05 9.63037312e-01 1.46875270e-02\n",
            " 1.48804039e-01 7.98968878e-03 9.48952377e-01 8.41898382e-01\n",
            " 6.49994075e-01 7.42351770e-01 9.84116018e-01 8.64827086e-07\n",
            " 6.71939142e-06 1.01600098e-03 6.75190249e-15 7.88071134e-07\n",
            " 1.98631898e-01 5.06300785e-13 5.60343096e-06 1.87170153e-05\n",
            " 9.99678969e-01 9.99938488e-01 9.99669790e-01 9.99568999e-01\n",
            " 9.64135587e-01 9.99304771e-01 9.94661391e-01 9.99999642e-01\n",
            " 9.99930739e-01 9.99484897e-01 9.99244452e-01 9.91976440e-01\n",
            " 9.78288293e-01 9.97191250e-01 9.42913055e-01 8.34812105e-01\n",
            " 9.99244213e-01 9.99224305e-01 9.99953032e-01 9.96828020e-01\n",
            " 9.99936819e-01 9.99179304e-01 9.99710977e-01 9.97328639e-01\n",
            " 8.84463489e-01 9.96800184e-01 9.79543626e-01 9.76026237e-01\n",
            " 1.72509870e-03 9.92662907e-01 9.97537732e-01 9.89426136e-01\n",
            " 9.68599677e-01 9.99999762e-01 9.99988317e-01 9.99930739e-01\n",
            " 5.84283292e-01 9.99345124e-01 9.80896473e-01 9.99843836e-01\n",
            " 9.97776926e-01 9.80100214e-01 5.16518414e-01 9.87559617e-01\n",
            " 9.89205003e-01 9.99118984e-01 9.99561012e-01 1.03141181e-03\n",
            " 2.01369777e-01 6.29723817e-03 2.61798110e-02 4.39162478e-02\n",
            " 9.96330798e-01 9.84514058e-01 7.01470450e-02 7.72116005e-01\n",
            " 9.99999285e-01 9.99951601e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 40 [0/107 (0%)]\tTrain Loss: 0.000070\n",
            "Train Epoch: 40 [4/107 (4%)]\tTrain Loss: 0.000267\n",
            "Train Epoch: 40 [8/107 (7%)]\tTrain Loss: 0.005272\n",
            "Train Epoch: 40 [12/107 (11%)]\tTrain Loss: 0.000077\n",
            "Train Epoch: 40 [16/107 (15%)]\tTrain Loss: 0.000097\n",
            "Train Epoch: 40 [20/107 (19%)]\tTrain Loss: 0.000157\n",
            "Train Epoch: 40 [24/107 (22%)]\tTrain Loss: 0.000077\n",
            "Train Epoch: 40 [28/107 (26%)]\tTrain Loss: 0.000448\n",
            "Train Epoch: 40 [32/107 (30%)]\tTrain Loss: 0.000250\n",
            "Train Epoch: 40 [36/107 (34%)]\tTrain Loss: 0.000033\n",
            "Train Epoch: 40 [40/107 (37%)]\tTrain Loss: 0.000125\n",
            "Train Epoch: 40 [44/107 (41%)]\tTrain Loss: 0.000006\n",
            "Train Epoch: 40 [48/107 (45%)]\tTrain Loss: 0.000013\n",
            "Train Epoch: 40 [52/107 (49%)]\tTrain Loss: 0.000168\n",
            "Train Epoch: 40 [56/107 (52%)]\tTrain Loss: 0.004035\n",
            "Train Epoch: 40 [60/107 (56%)]\tTrain Loss: 0.002682\n",
            "Train Epoch: 40 [64/107 (60%)]\tTrain Loss: 0.000008\n",
            "Train Epoch: 40 [68/107 (64%)]\tTrain Loss: 0.000496\n",
            "Train Epoch: 40 [72/107 (67%)]\tTrain Loss: 0.005031\n",
            "Train Epoch: 40 [76/107 (71%)]\tTrain Loss: 0.000070\n",
            "Train Epoch: 40 [80/107 (75%)]\tTrain Loss: 0.000036\n",
            "Train Epoch: 40 [84/107 (79%)]\tTrain Loss: 0.004265\n",
            "Train Epoch: 40 [88/107 (82%)]\tTrain Loss: 0.000127\n",
            "Train Epoch: 40 [92/107 (86%)]\tTrain Loss: 0.000211\n",
            "Train Epoch: 40 [96/107 (90%)]\tTrain Loss: 0.000027\n",
            "Train Epoch: 40 [100/107 (93%)]\tTrain Loss: 0.001603\n",
            "Train Epoch: 40 [104/107 (97%)]\tTrain Loss: 0.001258\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.08599309e-02 9.49832082e-01 1.88667607e-02 1.68374687e-01\n",
            " 9.88961547e-04 6.95674913e-03 7.23613724e-02 9.28861618e-01\n",
            " 9.95775452e-04 2.53282674e-02 4.67794299e-01 1.30728289e-01\n",
            " 9.70873475e-01 1.75133446e-05 4.08861524e-05 9.04023545e-06\n",
            " 2.23571169e-05 4.88224020e-03 8.92216194e-05 5.30185003e-04\n",
            " 4.85278899e-03 9.98634636e-01 7.15391263e-02 9.98388529e-01\n",
            " 9.94074881e-01 6.90402836e-02 7.94379115e-01 1.37161071e-04\n",
            " 8.63626519e-06 2.35759901e-04 7.10299646e-04 3.90641886e-04\n",
            " 1.51166308e-03 7.16712520e-06 1.25535973e-06 1.18077951e-05\n",
            " 4.58380615e-04 6.54442072e-01 3.93365137e-02 2.61592650e-05\n",
            " 2.53321141e-05 2.78243679e-05 8.41102242e-01 6.36596640e-04\n",
            " 4.05931771e-02 8.22387578e-04 5.61847270e-01 4.29389924e-01\n",
            " 3.46314549e-01 2.19757557e-01 9.74066913e-01 2.99642061e-10\n",
            " 1.87822877e-07 2.31536342e-06 2.17693850e-23 1.87706775e-08\n",
            " 7.27989172e-05 9.62073931e-20 9.56516910e-09 2.35395851e-06\n",
            " 9.98560250e-01 9.99515653e-01 9.98869121e-01 9.98604238e-01\n",
            " 7.91238546e-01 9.97532964e-01 9.78671014e-01 9.99989748e-01\n",
            " 9.99505043e-01 9.98091042e-01 9.83089685e-01 7.88698792e-01\n",
            " 6.96997404e-01 9.96379316e-01 7.54084170e-01 2.45128945e-01\n",
            " 9.97997344e-01 9.98010576e-01 9.99571621e-01 9.70247328e-01\n",
            " 9.99122083e-01 9.59821343e-01 9.98340011e-01 9.93700266e-01\n",
            " 6.71147943e-01 9.87676382e-01 6.17422640e-01 7.58083105e-01\n",
            " 3.68181878e-04 9.64570701e-01 9.94336307e-01 9.90562916e-01\n",
            " 9.17327821e-01 9.99983072e-01 9.99816358e-01 9.99545157e-01\n",
            " 2.63938785e-01 9.90718424e-01 9.44109797e-01 9.99516726e-01\n",
            " 9.91518080e-01 9.83419776e-01 6.55737445e-02 9.12353814e-01\n",
            " 4.51309085e-01 9.26589131e-01 9.93869126e-01 1.59415498e-03\n",
            " 7.58194476e-02 4.81795694e-04 5.34184910e-02 2.60138791e-02\n",
            " 9.62963581e-01 9.93412197e-01 6.10865699e-03 1.55335311e-02\n",
            " 9.99994397e-01 9.99797165e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "vote_pred [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "TP= 47 TN= 47 FN= 11 FP= 13\n",
            "TP+FP 60\n",
            "precision 0.7833333333333333\n",
            "recall 0.8103448275862069\n",
            "F1 0.7966101694915254\n",
            "acc 0.7966101694915254\n",
            "AUCp 0.7968390804597701\n",
            "AUC 0.8617816091954023\n",
            "\n",
            " The epoch is 40, average recall: 0.8103, average precision: 0.7833,average F1: 0.7966, average accuracy: 0.7966, average AUC: 0.8618\n",
            "Train Epoch: 41 [0/107 (0%)]\tTrain Loss: 0.000036\n",
            "Train Epoch: 41 [4/107 (4%)]\tTrain Loss: 0.007328\n",
            "Train Epoch: 41 [8/107 (7%)]\tTrain Loss: 0.009169\n",
            "Train Epoch: 41 [12/107 (11%)]\tTrain Loss: 0.000061\n",
            "Train Epoch: 41 [16/107 (15%)]\tTrain Loss: 0.000034\n",
            "Train Epoch: 41 [20/107 (19%)]\tTrain Loss: 0.000222\n",
            "Train Epoch: 41 [24/107 (22%)]\tTrain Loss: 0.002044\n",
            "Train Epoch: 41 [28/107 (26%)]\tTrain Loss: 0.000091\n",
            "Train Epoch: 41 [32/107 (30%)]\tTrain Loss: 0.001195\n",
            "Train Epoch: 41 [36/107 (34%)]\tTrain Loss: 0.000125\n",
            "Train Epoch: 41 [40/107 (37%)]\tTrain Loss: 0.000005\n",
            "Train Epoch: 41 [44/107 (41%)]\tTrain Loss: 0.000011\n",
            "Train Epoch: 41 [48/107 (45%)]\tTrain Loss: 0.000041\n",
            "Train Epoch: 41 [52/107 (49%)]\tTrain Loss: 0.000124\n",
            "Train Epoch: 41 [56/107 (52%)]\tTrain Loss: 0.005920\n",
            "Train Epoch: 41 [60/107 (56%)]\tTrain Loss: 0.000131\n",
            "Train Epoch: 41 [64/107 (60%)]\tTrain Loss: 0.000169\n",
            "Train Epoch: 41 [68/107 (64%)]\tTrain Loss: 0.000091\n",
            "Train Epoch: 41 [72/107 (67%)]\tTrain Loss: 0.000099\n",
            "Train Epoch: 41 [76/107 (71%)]\tTrain Loss: 0.000821\n",
            "Train Epoch: 41 [80/107 (75%)]\tTrain Loss: 0.002157\n",
            "Train Epoch: 41 [84/107 (79%)]\tTrain Loss: 0.001303\n",
            "Train Epoch: 41 [88/107 (82%)]\tTrain Loss: 0.005546\n",
            "Train Epoch: 41 [92/107 (86%)]\tTrain Loss: 0.005256\n",
            "Train Epoch: 41 [96/107 (90%)]\tTrain Loss: 0.000105\n",
            "Train Epoch: 41 [100/107 (93%)]\tTrain Loss: 0.000061\n",
            "Train Epoch: 41 [104/107 (97%)]\tTrain Loss: 0.000103\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.61942715e-04 9.90275025e-01 5.17006516e-02 9.59035337e-01\n",
            " 3.13740522e-02 1.68632111e-03 3.41610104e-01 9.84372973e-01\n",
            " 7.28058687e-04 9.85347688e-01 9.99266207e-01 4.00725245e-01\n",
            " 9.95208204e-01 8.30274075e-03 4.76891547e-03 5.00988681e-03\n",
            " 1.20593840e-02 9.89812791e-01 4.86068707e-03 2.88703721e-02\n",
            " 3.79622161e-01 9.99611318e-01 9.98262942e-01 9.99614239e-01\n",
            " 9.96392071e-01 9.99314666e-01 9.99082565e-01 4.40235175e-02\n",
            " 1.43620826e-03 1.08037321e-02 2.86853127e-02 4.83209640e-01\n",
            " 1.36140659e-01 4.96010645e-04 3.61995975e-04 6.58474339e-04\n",
            " 1.69771761e-02 9.97234404e-01 7.69901752e-01 1.00551639e-02\n",
            " 2.16003065e-03 3.92838009e-03 9.91095901e-01 7.04524755e-01\n",
            " 8.62846732e-01 7.40075111e-01 9.78639007e-01 9.75679100e-01\n",
            " 9.05619025e-01 9.89932656e-01 9.94702160e-01 2.63600149e-11\n",
            " 9.94097081e-06 2.03836011e-03 2.43620027e-27 3.93633627e-06\n",
            " 1.47312239e-05 2.02316178e-24 3.37427331e-09 7.30327854e-04\n",
            " 9.99327302e-01 9.99804437e-01 9.99173582e-01 9.99019384e-01\n",
            " 9.83524024e-01 9.99535441e-01 9.96907890e-01 9.99999046e-01\n",
            " 9.99853730e-01 9.98882830e-01 9.99629855e-01 9.98278856e-01\n",
            " 9.27453279e-01 9.95358527e-01 9.87566471e-01 9.00836051e-01\n",
            " 9.99118030e-01 9.99447763e-01 9.99772131e-01 9.94827926e-01\n",
            " 9.99805152e-01 9.98372018e-01 9.98860240e-01 9.99066770e-01\n",
            " 7.32959688e-01 9.98413682e-01 9.98071611e-01 9.98484910e-01\n",
            " 5.65184839e-03 9.62167561e-01 9.93729234e-01 9.89263713e-01\n",
            " 9.57252085e-01 9.99990702e-01 9.99816597e-01 9.99349415e-01\n",
            " 9.90079880e-01 9.95154619e-01 9.97393489e-01 9.99894142e-01\n",
            " 9.97854054e-01 9.06960249e-01 3.85401189e-01 9.20636415e-01\n",
            " 9.90568221e-01 9.93426442e-01 9.95932877e-01 8.81641209e-02\n",
            " 1.86106324e-01 2.89273914e-02 6.76741153e-02 7.44518280e-01\n",
            " 9.97262836e-01 9.77742493e-01 2.25157708e-01 8.75266433e-01\n",
            " 9.99978900e-01 9.96420622e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 42 [0/107 (0%)]\tTrain Loss: 0.001288\n",
            "Train Epoch: 42 [4/107 (4%)]\tTrain Loss: 0.026167\n",
            "Train Epoch: 42 [8/107 (7%)]\tTrain Loss: 0.003756\n",
            "Train Epoch: 42 [12/107 (11%)]\tTrain Loss: 0.325905\n",
            "Train Epoch: 42 [16/107 (15%)]\tTrain Loss: 0.002479\n",
            "Train Epoch: 42 [20/107 (19%)]\tTrain Loss: 0.000022\n",
            "Train Epoch: 42 [24/107 (22%)]\tTrain Loss: 0.000018\n",
            "Train Epoch: 42 [28/107 (26%)]\tTrain Loss: 0.231152\n",
            "Train Epoch: 42 [32/107 (30%)]\tTrain Loss: 0.000020\n",
            "Train Epoch: 42 [36/107 (34%)]\tTrain Loss: 0.005805\n",
            "Train Epoch: 42 [40/107 (37%)]\tTrain Loss: 0.004996\n",
            "Train Epoch: 42 [44/107 (41%)]\tTrain Loss: 0.000248\n",
            "Train Epoch: 42 [48/107 (45%)]\tTrain Loss: 0.032067\n",
            "Train Epoch: 42 [52/107 (49%)]\tTrain Loss: 0.005492\n",
            "Train Epoch: 42 [56/107 (52%)]\tTrain Loss: 0.038224\n",
            "Train Epoch: 42 [60/107 (56%)]\tTrain Loss: 0.000267\n",
            "Train Epoch: 42 [64/107 (60%)]\tTrain Loss: 0.089058\n",
            "Train Epoch: 42 [68/107 (64%)]\tTrain Loss: 0.000296\n",
            "Train Epoch: 42 [72/107 (67%)]\tTrain Loss: 0.000063\n",
            "Train Epoch: 42 [76/107 (71%)]\tTrain Loss: 0.010155\n",
            "Train Epoch: 42 [80/107 (75%)]\tTrain Loss: 0.000509\n",
            "Train Epoch: 42 [84/107 (79%)]\tTrain Loss: 0.000044\n",
            "Train Epoch: 42 [88/107 (82%)]\tTrain Loss: 0.006140\n",
            "Train Epoch: 42 [92/107 (86%)]\tTrain Loss: 0.061262\n",
            "Train Epoch: 42 [96/107 (90%)]\tTrain Loss: 0.011794\n",
            "Train Epoch: 42 [100/107 (93%)]\tTrain Loss: 0.291556\n",
            "Train Epoch: 42 [104/107 (97%)]\tTrain Loss: 0.002245\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.49503684e-01 9.99199331e-01 9.96098399e-01 9.49358523e-01\n",
            " 9.05170143e-01 5.14244676e-01 9.93382812e-01 9.99038100e-01\n",
            " 2.67554849e-01 4.99022543e-01 9.64835823e-01 4.00303632e-01\n",
            " 9.78525460e-01 3.59935279e-04 5.93280653e-03 4.26824154e-05\n",
            " 8.15326348e-03 6.78148195e-02 3.11502405e-02 1.81275502e-01\n",
            " 6.68707967e-01 9.99670863e-01 9.29545701e-01 9.91490185e-01\n",
            " 9.92226958e-01 9.72998381e-01 9.30973470e-01 6.82946891e-02\n",
            " 9.94746457e-04 1.38229892e-01 1.05075026e-02 6.22523606e-01\n",
            " 8.23104680e-01 1.00684213e-03 8.97154678e-04 1.21258451e-02\n",
            " 1.45177841e-01 9.79995787e-01 9.02041972e-01 1.25475158e-03\n",
            " 3.28123681e-02 5.25361451e-04 9.82614338e-01 9.17663217e-01\n",
            " 7.57941365e-01 5.07154644e-01 9.56206322e-01 8.21039617e-01\n",
            " 9.98560846e-01 9.93048310e-01 9.99001324e-01 2.11465817e-06\n",
            " 1.96078261e-07 9.05104727e-02 5.32137001e-21 2.92988498e-05\n",
            " 2.74186194e-01 5.76193302e-17 6.16426996e-06 3.96012911e-06\n",
            " 9.99818265e-01 9.99777496e-01 9.99882340e-01 9.99601066e-01\n",
            " 9.98489976e-01 9.99482632e-01 9.98704791e-01 9.99979138e-01\n",
            " 9.99376237e-01 9.95795727e-01 9.99184430e-01 9.97073054e-01\n",
            " 9.95303392e-01 9.99740899e-01 9.93915379e-01 9.99828339e-01\n",
            " 9.99961734e-01 9.99977946e-01 9.99987483e-01 9.98871386e-01\n",
            " 9.99907017e-01 9.99688148e-01 9.99966502e-01 9.61755991e-01\n",
            " 9.27184105e-01 9.97930169e-01 9.97375846e-01 9.99678016e-01\n",
            " 4.09028977e-02 9.42401826e-01 9.99320745e-01 9.99276221e-01\n",
            " 9.89586174e-01 9.99363601e-01 9.99453723e-01 9.87401426e-01\n",
            " 7.98200369e-01 6.34398103e-01 9.22222197e-01 9.98752236e-01\n",
            " 8.64268541e-01 9.96092498e-01 3.24540019e-01 9.80921030e-01\n",
            " 9.95641470e-01 9.95792150e-01 9.99661684e-01 7.62013495e-01\n",
            " 8.12943816e-01 7.52436444e-02 1.97442695e-01 1.04901552e-01\n",
            " 9.99288261e-01 9.79450226e-01 5.88532150e-01 9.22168493e-01\n",
            " 9.99469340e-01 9.93834853e-01]\n",
            "predict [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train Epoch: 43 [0/107 (0%)]\tTrain Loss: 0.075308\n",
            "Train Epoch: 43 [4/107 (4%)]\tTrain Loss: 0.000370\n",
            "Train Epoch: 43 [8/107 (7%)]\tTrain Loss: 0.094191\n",
            "Train Epoch: 43 [12/107 (11%)]\tTrain Loss: 0.015467\n",
            "Train Epoch: 43 [16/107 (15%)]\tTrain Loss: 0.036478\n",
            "Train Epoch: 43 [20/107 (19%)]\tTrain Loss: 0.001024\n",
            "Train Epoch: 43 [24/107 (22%)]\tTrain Loss: 0.150246\n",
            "Train Epoch: 43 [28/107 (26%)]\tTrain Loss: 0.001014\n",
            "Train Epoch: 43 [32/107 (30%)]\tTrain Loss: 0.008234\n",
            "Train Epoch: 43 [36/107 (34%)]\tTrain Loss: 0.003472\n",
            "Train Epoch: 43 [40/107 (37%)]\tTrain Loss: 0.023929\n",
            "Train Epoch: 43 [44/107 (41%)]\tTrain Loss: 0.139963\n",
            "Train Epoch: 43 [48/107 (45%)]\tTrain Loss: 0.002428\n",
            "Train Epoch: 43 [52/107 (49%)]\tTrain Loss: 0.007087\n",
            "Train Epoch: 43 [56/107 (52%)]\tTrain Loss: 0.003095\n",
            "Train Epoch: 43 [60/107 (56%)]\tTrain Loss: 0.000171\n",
            "Train Epoch: 43 [64/107 (60%)]\tTrain Loss: 0.001095\n",
            "Train Epoch: 43 [68/107 (64%)]\tTrain Loss: 0.000086\n",
            "Train Epoch: 43 [72/107 (67%)]\tTrain Loss: 0.001838\n",
            "Train Epoch: 43 [76/107 (71%)]\tTrain Loss: 0.002130\n",
            "Train Epoch: 43 [80/107 (75%)]\tTrain Loss: 0.000314\n",
            "Train Epoch: 43 [84/107 (79%)]\tTrain Loss: 0.000621\n",
            "Train Epoch: 43 [88/107 (82%)]\tTrain Loss: 0.012677\n",
            "Train Epoch: 43 [92/107 (86%)]\tTrain Loss: 0.000091\n",
            "Train Epoch: 43 [96/107 (90%)]\tTrain Loss: 0.000262\n",
            "Train Epoch: 43 [100/107 (93%)]\tTrain Loss: 0.002322\n",
            "Train Epoch: 43 [104/107 (97%)]\tTrain Loss: 0.001116\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [8.96819770e-01 9.87791538e-01 9.40688848e-01 9.24908876e-01\n",
            " 8.15944612e-01 2.03687698e-01 9.56452966e-01 9.98015642e-01\n",
            " 3.01121697e-02 3.94768178e-01 4.71869409e-01 9.84138548e-01\n",
            " 3.57832879e-01 2.94046884e-04 9.54516989e-04 3.92477988e-04\n",
            " 5.30692101e-01 1.93964632e-03 1.42017717e-03 9.50730219e-02\n",
            " 9.90236625e-02 9.78036344e-01 8.74281153e-02 9.88500834e-01\n",
            " 9.87563014e-01 7.64688730e-01 9.88836229e-01 3.98149888e-04\n",
            " 2.59815104e-04 1.10876199e-03 8.37153813e-04 9.51590482e-04\n",
            " 3.84011358e-01 3.41255814e-02 2.89122434e-03 5.73188923e-02\n",
            " 5.93703628e-01 9.53282237e-01 5.71380138e-01 2.81246961e-03\n",
            " 6.65126182e-03 9.66091454e-03 8.90436471e-01 2.03031339e-02\n",
            " 6.75983950e-02 1.73899367e-01 7.35081673e-01 5.83836026e-02\n",
            " 8.89064312e-01 4.09471244e-01 9.82521355e-01 4.41544398e-13\n",
            " 1.14740601e-07 1.86933976e-05 5.03188507e-31 4.67364139e-08\n",
            " 3.12763914e-05 5.67311785e-26 2.39469977e-09 5.52717438e-06\n",
            " 9.79480505e-01 9.70192790e-01 9.91500378e-01 9.96812046e-01\n",
            " 9.53948915e-01 9.97156978e-01 9.96198833e-01 9.99747694e-01\n",
            " 9.99476850e-01 8.73896539e-01 9.64900553e-01 8.73306632e-01\n",
            " 8.89056206e-01 9.83249843e-01 7.77940154e-01 6.55838788e-01\n",
            " 9.97747719e-01 9.99082923e-01 9.99219060e-01 9.81614292e-01\n",
            " 9.98287976e-01 9.86003816e-01 9.99899983e-01 6.21004820e-01\n",
            " 4.55310404e-01 5.39256573e-01 6.96772575e-01 9.38068926e-01\n",
            " 1.72602553e-02 9.96229589e-01 9.99992847e-01 9.95121658e-01\n",
            " 9.36115742e-01 9.99969244e-01 9.99985814e-01 9.99283850e-01\n",
            " 3.47378701e-01 5.42742729e-01 9.47238326e-01 9.99539852e-01\n",
            " 9.53390658e-01 9.67802048e-01 5.84764659e-01 9.67567265e-01\n",
            " 9.30201352e-01 9.91112888e-01 9.94929194e-01 9.69412446e-01\n",
            " 1.63858950e-01 3.96271870e-02 2.02714324e-01 2.22542211e-01\n",
            " 9.99703348e-01 8.27832341e-01 4.26512631e-03 3.27804033e-03\n",
            " 9.99160171e-01 9.95547295e-01]\n",
            "predict [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 44 [0/107 (0%)]\tTrain Loss: 0.011144\n",
            "Train Epoch: 44 [4/107 (4%)]\tTrain Loss: 0.000530\n",
            "Train Epoch: 44 [8/107 (7%)]\tTrain Loss: 0.001193\n",
            "Train Epoch: 44 [12/107 (11%)]\tTrain Loss: 0.000060\n",
            "Train Epoch: 44 [16/107 (15%)]\tTrain Loss: 0.013708\n",
            "Train Epoch: 44 [20/107 (19%)]\tTrain Loss: 0.138996\n",
            "Train Epoch: 44 [24/107 (22%)]\tTrain Loss: 0.004052\n",
            "Train Epoch: 44 [28/107 (26%)]\tTrain Loss: 0.001555\n",
            "Train Epoch: 44 [32/107 (30%)]\tTrain Loss: 0.000788\n",
            "Train Epoch: 44 [36/107 (34%)]\tTrain Loss: 0.002604\n",
            "Train Epoch: 44 [40/107 (37%)]\tTrain Loss: 0.000106\n",
            "Train Epoch: 44 [44/107 (41%)]\tTrain Loss: 0.000845\n",
            "Train Epoch: 44 [48/107 (45%)]\tTrain Loss: 0.000260\n",
            "Train Epoch: 44 [52/107 (49%)]\tTrain Loss: 0.002766\n",
            "Train Epoch: 44 [56/107 (52%)]\tTrain Loss: 0.004554\n",
            "Train Epoch: 44 [60/107 (56%)]\tTrain Loss: 0.000491\n",
            "Train Epoch: 44 [64/107 (60%)]\tTrain Loss: 0.000917\n",
            "Train Epoch: 44 [68/107 (64%)]\tTrain Loss: 0.001177\n",
            "Train Epoch: 44 [72/107 (67%)]\tTrain Loss: 0.003367\n",
            "Train Epoch: 44 [76/107 (71%)]\tTrain Loss: 0.011004\n",
            "Train Epoch: 44 [80/107 (75%)]\tTrain Loss: 0.001209\n",
            "Train Epoch: 44 [84/107 (79%)]\tTrain Loss: 0.005306\n",
            "Train Epoch: 44 [88/107 (82%)]\tTrain Loss: 0.000675\n",
            "Train Epoch: 44 [92/107 (86%)]\tTrain Loss: 0.000184\n",
            "Train Epoch: 44 [96/107 (90%)]\tTrain Loss: 0.000607\n",
            "Train Epoch: 44 [100/107 (93%)]\tTrain Loss: 0.012252\n",
            "Train Epoch: 44 [104/107 (97%)]\tTrain Loss: 0.000256\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.57458712e-04 1.14541464e-01 1.73064612e-03 4.97212529e-01\n",
            " 1.59508124e-01 5.00474707e-04 5.60731301e-03 9.95342135e-01\n",
            " 4.05653873e-06 4.18355747e-04 4.39799726e-01 2.89820530e-03\n",
            " 5.22048138e-02 2.45124156e-05 3.26562149e-04 3.04582481e-05\n",
            " 7.56030277e-05 3.52219283e-03 3.70350725e-04 7.47049041e-03\n",
            " 2.10699402e-02 9.97314513e-01 2.97359794e-01 9.99968410e-01\n",
            " 9.99189317e-01 9.36200440e-01 9.98932898e-01 6.45693671e-03\n",
            " 6.09023031e-04 1.84345746e-03 1.00633246e-03 8.66747927e-03\n",
            " 4.51781936e-02 2.56335420e-06 6.18880563e-07 1.40789594e-03\n",
            " 6.21989137e-04 9.75190580e-01 6.26547098e-01 8.65531911e-05\n",
            " 2.13352469e-04 4.93519590e-04 9.85074878e-01 1.26095936e-01\n",
            " 9.55735803e-01 6.16502296e-03 2.39891231e-01 1.92716628e-01\n",
            " 4.71592337e-01 8.12722027e-01 9.97305989e-01 5.46938068e-15\n",
            " 1.52412184e-07 2.95270524e-07 1.73517850e-28 6.84301171e-10\n",
            " 1.43166588e-04 7.02397845e-29 7.45301737e-12 9.89657929e-05\n",
            " 9.99816597e-01 9.99776423e-01 9.99840498e-01 9.99656320e-01\n",
            " 9.94938135e-01 9.99200642e-01 9.99070585e-01 9.99999523e-01\n",
            " 9.99935031e-01 9.99576509e-01 9.99743283e-01 9.99124229e-01\n",
            " 9.95813429e-01 9.99153614e-01 9.88316357e-01 9.88404512e-01\n",
            " 9.91780579e-01 9.98994172e-01 9.99999046e-01 9.99606907e-01\n",
            " 9.99994040e-01 9.99376953e-01 9.99999762e-01 9.98906612e-01\n",
            " 7.16733932e-01 9.91738141e-01 9.97537732e-01 9.68573213e-01\n",
            " 1.62682366e-02 5.12659550e-01 9.99995947e-01 9.97973144e-01\n",
            " 5.74503064e-01 1.00000000e+00 1.00000000e+00 9.99887705e-01\n",
            " 5.92675328e-01 8.13211083e-01 9.68083262e-01 9.88081813e-01\n",
            " 9.39124584e-01 9.54403162e-01 7.64899179e-02 9.92745817e-01\n",
            " 9.07312930e-01 9.99486685e-01 9.99987602e-01 1.63821623e-01\n",
            " 2.62163277e-03 1.82516081e-03 3.69862318e-02 3.41908969e-02\n",
            " 9.99673009e-01 9.01655316e-01 6.75335201e-03 1.32578760e-01\n",
            " 9.99998569e-01 9.99006450e-01]\n",
            "predict [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 45 [0/107 (0%)]\tTrain Loss: 0.000460\n",
            "Train Epoch: 45 [4/107 (4%)]\tTrain Loss: 0.000264\n",
            "Train Epoch: 45 [8/107 (7%)]\tTrain Loss: 0.001123\n",
            "Train Epoch: 45 [12/107 (11%)]\tTrain Loss: 0.004056\n",
            "Train Epoch: 45 [16/107 (15%)]\tTrain Loss: 0.000334\n",
            "Train Epoch: 45 [20/107 (19%)]\tTrain Loss: 0.000839\n",
            "Train Epoch: 45 [24/107 (22%)]\tTrain Loss: 0.001161\n",
            "Train Epoch: 45 [28/107 (26%)]\tTrain Loss: 0.000201\n",
            "Train Epoch: 45 [32/107 (30%)]\tTrain Loss: 0.001141\n",
            "Train Epoch: 45 [36/107 (34%)]\tTrain Loss: 0.006795\n",
            "Train Epoch: 45 [40/107 (37%)]\tTrain Loss: 0.000277\n",
            "Train Epoch: 45 [44/107 (41%)]\tTrain Loss: 0.000285\n",
            "Train Epoch: 45 [48/107 (45%)]\tTrain Loss: 0.000101\n",
            "Train Epoch: 45 [52/107 (49%)]\tTrain Loss: 0.000379\n",
            "Train Epoch: 45 [56/107 (52%)]\tTrain Loss: 0.061599\n",
            "Train Epoch: 45 [60/107 (56%)]\tTrain Loss: 0.000170\n",
            "Train Epoch: 45 [64/107 (60%)]\tTrain Loss: 0.000043\n",
            "Train Epoch: 45 [68/107 (64%)]\tTrain Loss: 0.000277\n",
            "Train Epoch: 45 [72/107 (67%)]\tTrain Loss: 0.004236\n",
            "Train Epoch: 45 [76/107 (71%)]\tTrain Loss: 0.004830\n",
            "Train Epoch: 45 [80/107 (75%)]\tTrain Loss: 0.116737\n",
            "Train Epoch: 45 [84/107 (79%)]\tTrain Loss: 0.000167\n",
            "Train Epoch: 45 [88/107 (82%)]\tTrain Loss: 0.011469\n",
            "Train Epoch: 45 [92/107 (86%)]\tTrain Loss: 0.001835\n",
            "Train Epoch: 45 [96/107 (90%)]\tTrain Loss: 0.003276\n",
            "Train Epoch: 45 [100/107 (93%)]\tTrain Loss: 0.000095\n",
            "Train Epoch: 45 [104/107 (97%)]\tTrain Loss: 0.000845\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.63183711e-03 8.14556658e-01 2.68290378e-03 6.42129183e-01\n",
            " 5.77127784e-02 2.12525413e-03 2.82469355e-02 9.79450762e-01\n",
            " 1.08621774e-04 4.76616099e-02 5.69382012e-01 2.15713188e-01\n",
            " 6.15466237e-02 2.81112734e-04 1.82839192e-03 6.25363537e-05\n",
            " 1.75331326e-04 3.80356750e-03 1.40599266e-03 2.62255166e-02\n",
            " 1.07132860e-01 9.92526174e-01 7.71476507e-01 9.99383330e-01\n",
            " 9.91662502e-01 7.42013454e-01 9.91829932e-01 6.50939643e-02\n",
            " 6.38169702e-04 7.16397190e-04 5.64469956e-03 5.72431684e-02\n",
            " 9.54043493e-02 7.31811160e-05 2.16338030e-05 2.18183780e-03\n",
            " 7.92315579e-04 9.44750309e-01 4.27387446e-01 5.23676026e-05\n",
            " 1.37013994e-04 4.06177540e-04 9.54975605e-01 1.17342062e-02\n",
            " 8.22219074e-01 8.14226568e-02 8.12393129e-02 3.97235900e-02\n",
            " 2.20226958e-01 4.17733602e-02 8.70774031e-01 1.42931349e-20\n",
            " 2.20975718e-08 2.99769121e-09 5.02983461e-37 1.23457261e-13\n",
            " 5.32381137e-07 3.71624353e-41 2.39981798e-15 5.65146143e-03\n",
            " 9.98484313e-01 9.99147296e-01 9.99437273e-01 9.99118149e-01\n",
            " 9.93316114e-01 9.95714605e-01 9.95357096e-01 9.99625325e-01\n",
            " 9.98362839e-01 9.93037164e-01 9.96434569e-01 9.94904160e-01\n",
            " 9.99426365e-01 9.99800980e-01 9.96072292e-01 7.88837433e-01\n",
            " 9.72131491e-01 9.88773167e-01 9.99585688e-01 9.87625659e-01\n",
            " 9.99475181e-01 9.99296665e-01 9.99776304e-01 9.88609314e-01\n",
            " 9.57145929e-01 9.87571001e-01 9.95587707e-01 9.97871995e-01\n",
            " 3.00428569e-01 2.99176097e-01 9.96695757e-01 9.92115676e-01\n",
            " 8.49332035e-01 9.99961853e-01 9.99953508e-01 9.99400616e-01\n",
            " 9.98634517e-01 9.89600956e-01 9.50216174e-01 9.81796086e-01\n",
            " 9.36051309e-01 9.73843396e-01 1.48068205e-01 9.76998627e-01\n",
            " 9.25440371e-01 9.97260928e-01 9.99861836e-01 5.78210969e-03\n",
            " 8.89586983e-04 1.80625368e-03 5.63438880e-05 2.77137548e-01\n",
            " 6.35546029e-01 9.22064066e-01 7.21518556e-03 4.66871560e-01\n",
            " 9.99910474e-01 9.99321699e-01]\n",
            "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 46 [0/107 (0%)]\tTrain Loss: 0.000777\n",
            "Train Epoch: 46 [4/107 (4%)]\tTrain Loss: 0.000792\n",
            "Train Epoch: 46 [8/107 (7%)]\tTrain Loss: 0.008374\n",
            "Train Epoch: 46 [12/107 (11%)]\tTrain Loss: 0.000056\n",
            "Train Epoch: 46 [16/107 (15%)]\tTrain Loss: 0.000519\n",
            "Train Epoch: 46 [20/107 (19%)]\tTrain Loss: 0.000368\n",
            "Train Epoch: 46 [24/107 (22%)]\tTrain Loss: 0.000127\n",
            "Train Epoch: 46 [28/107 (26%)]\tTrain Loss: 0.000279\n",
            "Train Epoch: 46 [32/107 (30%)]\tTrain Loss: 0.000070\n",
            "Train Epoch: 46 [36/107 (34%)]\tTrain Loss: 0.000039\n",
            "Train Epoch: 46 [40/107 (37%)]\tTrain Loss: 0.000422\n",
            "Train Epoch: 46 [44/107 (41%)]\tTrain Loss: 0.000152\n",
            "Train Epoch: 46 [48/107 (45%)]\tTrain Loss: 0.000819\n",
            "Train Epoch: 46 [52/107 (49%)]\tTrain Loss: 0.001384\n",
            "Train Epoch: 46 [56/107 (52%)]\tTrain Loss: 0.002639\n",
            "Train Epoch: 46 [60/107 (56%)]\tTrain Loss: 0.000306\n",
            "Train Epoch: 46 [64/107 (60%)]\tTrain Loss: 0.000044\n",
            "Train Epoch: 46 [68/107 (64%)]\tTrain Loss: 0.000026\n",
            "Train Epoch: 46 [72/107 (67%)]\tTrain Loss: 0.000016\n",
            "Train Epoch: 46 [76/107 (71%)]\tTrain Loss: 0.000429\n",
            "Train Epoch: 46 [80/107 (75%)]\tTrain Loss: 0.000434\n",
            "Train Epoch: 46 [84/107 (79%)]\tTrain Loss: 0.461145\n",
            "Train Epoch: 46 [88/107 (82%)]\tTrain Loss: 0.009860\n",
            "Train Epoch: 46 [92/107 (86%)]\tTrain Loss: 0.000663\n",
            "Train Epoch: 46 [96/107 (90%)]\tTrain Loss: 0.179480\n",
            "Train Epoch: 46 [100/107 (93%)]\tTrain Loss: 0.003312\n",
            "Train Epoch: 46 [104/107 (97%)]\tTrain Loss: 0.000645\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [2.55787522e-01 9.47759748e-01 3.21470022e-01 9.98620868e-01\n",
            " 8.95869255e-01 7.41633654e-01 8.72617602e-01 9.99801815e-01\n",
            " 8.89693916e-01 9.90822196e-01 9.99031663e-01 9.99419689e-01\n",
            " 9.88888979e-01 8.57313797e-02 8.82894576e-01 6.64467516e-04\n",
            " 5.62381685e-01 9.74046111e-01 6.25198007e-01 7.84620166e-01\n",
            " 8.11569750e-01 9.99896646e-01 9.99334633e-01 9.99999523e-01\n",
            " 9.99736726e-01 9.99397635e-01 9.99996305e-01 9.75082815e-01\n",
            " 5.80324709e-01 4.69591558e-01 9.86416578e-01 7.84418821e-01\n",
            " 8.69502306e-01 4.84171435e-02 5.02699660e-03 3.64579946e-01\n",
            " 8.57938707e-01 9.98067319e-01 8.69858921e-01 2.09542826e-01\n",
            " 1.85979530e-01 2.92728454e-01 9.33514059e-01 7.05944121e-01\n",
            " 9.92915392e-01 3.34362566e-01 9.39142644e-01 3.67559135e-01\n",
            " 7.39106238e-01 1.77478299e-01 9.84203219e-01 1.97415602e-06\n",
            " 8.43462534e-04 1.02490276e-01 2.38706193e-16 4.89057529e-05\n",
            " 5.76835573e-01 1.16831532e-16 1.78944629e-06 4.52467710e-01\n",
            " 9.99608457e-01 9.99824107e-01 9.99602258e-01 9.99274909e-01\n",
            " 9.99927163e-01 9.99981642e-01 9.99635100e-01 9.99999881e-01\n",
            " 9.99925256e-01 9.87543583e-01 9.99499917e-01 9.96685803e-01\n",
            " 9.99520063e-01 9.99847293e-01 9.99888659e-01 9.99617457e-01\n",
            " 9.94327724e-01 9.93446410e-01 9.99997973e-01 9.99592483e-01\n",
            " 9.99953270e-01 9.99700665e-01 9.99996305e-01 9.99042094e-01\n",
            " 9.99616385e-01 9.98848081e-01 9.99861598e-01 9.99909878e-01\n",
            " 9.09977734e-01 9.99985695e-01 9.99815881e-01 9.78055954e-01\n",
            " 9.93154883e-01 1.00000000e+00 9.99999881e-01 9.99996662e-01\n",
            " 9.99866724e-01 9.99302506e-01 9.93463695e-01 9.92568791e-01\n",
            " 9.79909360e-01 9.99874115e-01 9.88889933e-01 9.99325633e-01\n",
            " 9.94813085e-01 9.99789059e-01 9.99956369e-01 8.04908097e-01\n",
            " 9.74585474e-01 7.60403991e-01 2.69486070e-01 3.39947492e-01\n",
            " 9.99838352e-01 9.99977469e-01 4.99648780e-01 9.43252742e-01\n",
            " 9.99997854e-01 9.99997139e-01]\n",
            "predict [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train Epoch: 47 [0/107 (0%)]\tTrain Loss: 0.001087\n",
            "Train Epoch: 47 [4/107 (4%)]\tTrain Loss: 0.011254\n",
            "Train Epoch: 47 [8/107 (7%)]\tTrain Loss: 0.004016\n",
            "Train Epoch: 47 [12/107 (11%)]\tTrain Loss: 0.007194\n",
            "Train Epoch: 47 [16/107 (15%)]\tTrain Loss: 0.011693\n",
            "Train Epoch: 47 [20/107 (19%)]\tTrain Loss: 0.000865\n",
            "Train Epoch: 47 [24/107 (22%)]\tTrain Loss: 0.003549\n",
            "Train Epoch: 47 [28/107 (26%)]\tTrain Loss: 0.063647\n",
            "Train Epoch: 47 [32/107 (30%)]\tTrain Loss: 0.002551\n",
            "Train Epoch: 47 [36/107 (34%)]\tTrain Loss: 0.011517\n",
            "Train Epoch: 47 [40/107 (37%)]\tTrain Loss: 0.000443\n",
            "Train Epoch: 47 [44/107 (41%)]\tTrain Loss: 0.000127\n",
            "Train Epoch: 47 [48/107 (45%)]\tTrain Loss: 0.001786\n",
            "Train Epoch: 47 [52/107 (49%)]\tTrain Loss: 0.000462\n",
            "Train Epoch: 47 [56/107 (52%)]\tTrain Loss: 0.000202\n",
            "Train Epoch: 47 [60/107 (56%)]\tTrain Loss: 0.003020\n",
            "Train Epoch: 47 [64/107 (60%)]\tTrain Loss: 0.016474\n",
            "Train Epoch: 47 [68/107 (64%)]\tTrain Loss: 0.002715\n",
            "Train Epoch: 47 [72/107 (67%)]\tTrain Loss: 0.003106\n",
            "Train Epoch: 47 [76/107 (71%)]\tTrain Loss: 0.001292\n",
            "Train Epoch: 47 [80/107 (75%)]\tTrain Loss: 0.000171\n",
            "Train Epoch: 47 [84/107 (79%)]\tTrain Loss: 0.001245\n",
            "Train Epoch: 47 [88/107 (82%)]\tTrain Loss: 0.022607\n",
            "Train Epoch: 47 [92/107 (86%)]\tTrain Loss: 0.003168\n",
            "Train Epoch: 47 [96/107 (90%)]\tTrain Loss: 0.001559\n",
            "Train Epoch: 47 [100/107 (93%)]\tTrain Loss: 0.002064\n",
            "Train Epoch: 47 [104/107 (97%)]\tTrain Loss: 0.001147\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [4.10496518e-02 4.69436944e-02 3.19811814e-02 7.37347364e-01\n",
            " 1.27771404e-02 1.49608329e-01 2.74627395e-02 9.35851097e-01\n",
            " 1.04990928e-02 7.82550871e-01 6.30347013e-01 9.37130332e-01\n",
            " 1.60099342e-01 8.68480201e-05 4.93068062e-03 3.76746902e-05\n",
            " 3.46834771e-03 4.04199166e-03 1.50946546e-02 1.39746722e-03\n",
            " 3.32165882e-03 9.86141443e-01 1.14043660e-01 9.99369085e-01\n",
            " 9.94361520e-01 1.79609790e-01 9.96351123e-01 3.64940235e-04\n",
            " 1.69308187e-04 5.76361723e-04 7.06208695e-04 5.91327611e-04\n",
            " 6.48416504e-02 3.73760558e-05 5.02288140e-06 4.28163970e-04\n",
            " 3.83105455e-03 1.59260020e-01 2.30393372e-03 1.73666001e-06\n",
            " 3.17668560e-06 2.63464080e-05 1.34655703e-02 5.39687742e-03\n",
            " 1.01023570e-01 7.50300987e-03 6.52459502e-01 1.08209103e-01\n",
            " 8.60089421e-01 4.91572648e-01 9.68821645e-01 1.34858199e-14\n",
            " 4.38337977e-10 3.93500443e-07 1.55224551e-27 4.76149120e-10\n",
            " 1.78872747e-03 1.46728713e-30 8.96032346e-11 2.60474678e-07\n",
            " 9.67618823e-01 9.41567004e-01 9.95148003e-01 9.90485966e-01\n",
            " 3.17606539e-01 9.95908380e-01 7.55942047e-01 9.98564541e-01\n",
            " 9.96709466e-01 9.15562034e-01 9.77472126e-01 8.24057579e-01\n",
            " 5.79626083e-01 9.90322948e-01 3.33512649e-02 1.16977997e-01\n",
            " 9.81569409e-01 9.91618216e-01 9.95561481e-01 9.88620162e-01\n",
            " 9.99879956e-01 9.90534425e-01 9.99790609e-01 9.87490952e-01\n",
            " 9.74054813e-01 9.98446524e-01 9.07982528e-01 9.95975673e-01\n",
            " 1.39219500e-02 9.59456325e-01 9.82722521e-01 9.57792580e-01\n",
            " 8.73351276e-01 9.99999762e-01 9.99993920e-01 9.99871254e-01\n",
            " 9.04675961e-01 9.90311384e-01 8.65082145e-01 4.06832337e-01\n",
            " 8.30074787e-01 9.96735990e-01 6.57183975e-02 9.79115784e-01\n",
            " 9.53999341e-01 9.99181092e-01 9.99699473e-01 9.05540437e-05\n",
            " 7.94510356e-07 7.74452565e-06 6.76445495e-08 2.38426356e-03\n",
            " 1.15639746e-01 9.95024860e-01 1.42306378e-02 5.94331883e-02\n",
            " 9.99954939e-01 9.99459922e-01]\n",
            "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 48 [0/107 (0%)]\tTrain Loss: 0.000260\n",
            "Train Epoch: 48 [4/107 (4%)]\tTrain Loss: 0.000042\n",
            "Train Epoch: 48 [8/107 (7%)]\tTrain Loss: 0.000708\n",
            "Train Epoch: 48 [12/107 (11%)]\tTrain Loss: 0.000019\n",
            "Train Epoch: 48 [16/107 (15%)]\tTrain Loss: 0.000088\n",
            "Train Epoch: 48 [20/107 (19%)]\tTrain Loss: 0.002319\n",
            "Train Epoch: 48 [24/107 (22%)]\tTrain Loss: 0.004105\n",
            "Train Epoch: 48 [28/107 (26%)]\tTrain Loss: 0.000552\n",
            "Train Epoch: 48 [32/107 (30%)]\tTrain Loss: 0.000279\n",
            "Train Epoch: 48 [36/107 (34%)]\tTrain Loss: 0.001195\n",
            "Train Epoch: 48 [40/107 (37%)]\tTrain Loss: 0.000555\n",
            "Train Epoch: 48 [44/107 (41%)]\tTrain Loss: 0.006005\n",
            "Train Epoch: 48 [48/107 (45%)]\tTrain Loss: 0.034809\n",
            "Train Epoch: 48 [52/107 (49%)]\tTrain Loss: 0.001418\n",
            "Train Epoch: 48 [56/107 (52%)]\tTrain Loss: 0.000267\n",
            "Train Epoch: 48 [60/107 (56%)]\tTrain Loss: 0.002626\n",
            "Train Epoch: 48 [64/107 (60%)]\tTrain Loss: 0.000120\n",
            "Train Epoch: 48 [68/107 (64%)]\tTrain Loss: 0.000870\n",
            "Train Epoch: 48 [72/107 (67%)]\tTrain Loss: 0.000188\n",
            "Train Epoch: 48 [76/107 (71%)]\tTrain Loss: 0.002669\n",
            "Train Epoch: 48 [80/107 (75%)]\tTrain Loss: 0.093180\n",
            "Train Epoch: 48 [84/107 (79%)]\tTrain Loss: 0.030640\n",
            "Train Epoch: 48 [88/107 (82%)]\tTrain Loss: 0.020187\n",
            "Train Epoch: 48 [92/107 (86%)]\tTrain Loss: 0.001297\n",
            "Train Epoch: 48 [96/107 (90%)]\tTrain Loss: 0.006451\n",
            "Train Epoch: 48 [100/107 (93%)]\tTrain Loss: 0.003888\n",
            "Train Epoch: 48 [104/107 (97%)]\tTrain Loss: 0.001319\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.42031401e-01 8.38510990e-01 5.85368514e-01 5.95141470e-01\n",
            " 2.03477722e-02 1.00700200e-01 5.27369499e-01 9.88225579e-01\n",
            " 4.65132445e-02 2.98420131e-01 9.98975515e-01 8.50525856e-01\n",
            " 9.85638678e-01 1.87593289e-02 1.05640143e-01 8.46271496e-03\n",
            " 2.68116385e-01 1.80737808e-01 9.59768742e-02 8.89421552e-02\n",
            " 1.68762043e-01 9.96752799e-01 9.97954488e-01 9.99853373e-01\n",
            " 9.77345943e-01 9.99150515e-01 9.99357998e-01 5.79153240e-01\n",
            " 2.92823642e-01 2.70488411e-01 3.18879113e-02 5.16758934e-02\n",
            " 4.91838038e-01 1.39297533e-03 4.55042720e-03 6.18893560e-03\n",
            " 5.88595383e-02 9.75652695e-01 6.92802444e-02 1.11126136e-02\n",
            " 1.94740258e-02 8.21745396e-03 1.28774345e-01 7.45386243e-01\n",
            " 7.77651191e-01 5.07464111e-01 9.89522159e-01 8.89855027e-01\n",
            " 9.81444895e-01 9.92024660e-01 9.99387622e-01 8.89684423e-04\n",
            " 4.47809900e-04 9.54366088e-01 3.19818472e-13 3.55141005e-03\n",
            " 7.93488204e-01 1.90311197e-10 4.89539052e-05 5.62035653e-04\n",
            " 9.99776423e-01 9.99733984e-01 9.99903798e-01 9.99832749e-01\n",
            " 9.94460821e-01 9.99868393e-01 7.98280060e-01 9.99999762e-01\n",
            " 9.99900222e-01 9.44529891e-01 9.99384642e-01 9.97555196e-01\n",
            " 9.89269435e-01 9.97529447e-01 9.96036112e-01 9.44114268e-01\n",
            " 9.99231696e-01 9.99187529e-01 9.99721110e-01 9.97948706e-01\n",
            " 9.99993801e-01 9.99760330e-01 9.99962926e-01 9.86526430e-01\n",
            " 9.75435615e-01 9.97202039e-01 9.78929460e-01 9.91755366e-01\n",
            " 3.80000360e-02 9.99545157e-01 9.99336541e-01 9.55805957e-01\n",
            " 8.40412140e-01 9.99999762e-01 1.00000000e+00 9.99616504e-01\n",
            " 9.90149856e-01 3.28836977e-01 9.37421083e-01 9.88687038e-01\n",
            " 1.85570821e-01 9.96936321e-01 2.43258998e-01 9.61686969e-01\n",
            " 9.88687038e-01 9.60299611e-01 9.93813157e-01 8.57916474e-01\n",
            " 2.24203855e-01 9.31411624e-01 1.45117670e-01 3.83275654e-03\n",
            " 9.99998450e-01 9.99917626e-01 1.95061620e-02 2.59357363e-01\n",
            " 9.97976005e-01 9.99256551e-01]\n",
            "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 49 [0/107 (0%)]\tTrain Loss: 0.000217\n",
            "Train Epoch: 49 [4/107 (4%)]\tTrain Loss: 0.004638\n",
            "Train Epoch: 49 [8/107 (7%)]\tTrain Loss: 0.028792\n",
            "Train Epoch: 49 [12/107 (11%)]\tTrain Loss: 0.010593\n",
            "Train Epoch: 49 [16/107 (15%)]\tTrain Loss: 0.002506\n",
            "Train Epoch: 49 [20/107 (19%)]\tTrain Loss: 0.010271\n",
            "Train Epoch: 49 [24/107 (22%)]\tTrain Loss: 0.001995\n",
            "Train Epoch: 49 [28/107 (26%)]\tTrain Loss: 0.002626\n",
            "Train Epoch: 49 [32/107 (30%)]\tTrain Loss: 0.002604\n",
            "Train Epoch: 49 [36/107 (34%)]\tTrain Loss: 0.023984\n",
            "Train Epoch: 49 [40/107 (37%)]\tTrain Loss: 0.004011\n",
            "Train Epoch: 49 [44/107 (41%)]\tTrain Loss: 0.003455\n",
            "Train Epoch: 49 [48/107 (45%)]\tTrain Loss: 0.009467\n",
            "Train Epoch: 49 [52/107 (49%)]\tTrain Loss: 0.005702\n",
            "Train Epoch: 49 [56/107 (52%)]\tTrain Loss: 0.005260\n",
            "Train Epoch: 49 [60/107 (56%)]\tTrain Loss: 0.007927\n",
            "Train Epoch: 49 [64/107 (60%)]\tTrain Loss: 0.004114\n",
            "Train Epoch: 49 [68/107 (64%)]\tTrain Loss: 0.001272\n",
            "Train Epoch: 49 [72/107 (67%)]\tTrain Loss: 0.007011\n",
            "Train Epoch: 49 [76/107 (71%)]\tTrain Loss: 0.003712\n",
            "Train Epoch: 49 [80/107 (75%)]\tTrain Loss: 0.000437\n",
            "Train Epoch: 49 [84/107 (79%)]\tTrain Loss: 0.004492\n",
            "Train Epoch: 49 [88/107 (82%)]\tTrain Loss: 0.015019\n",
            "Train Epoch: 49 [92/107 (86%)]\tTrain Loss: 0.002049\n",
            "Train Epoch: 49 [96/107 (90%)]\tTrain Loss: 0.000147\n",
            "Train Epoch: 49 [100/107 (93%)]\tTrain Loss: 0.005754\n",
            "Train Epoch: 49 [104/107 (97%)]\tTrain Loss: 0.001510\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [5.09653464e-02 9.39902067e-01 2.69829988e-01 5.95277399e-02\n",
            " 3.60549726e-02 2.12762486e-02 2.82678753e-02 7.04063177e-01\n",
            " 5.29068569e-03 2.83325259e-02 4.91012692e-01 5.83663940e-01\n",
            " 1.00657329e-01 3.93145136e-04 2.06219289e-03 4.09575505e-03\n",
            " 4.16074693e-02 1.74594892e-03 3.27941758e-04 2.36669295e-02\n",
            " 3.33968666e-03 8.19518447e-01 5.26266813e-01 9.99200046e-01\n",
            " 9.92862642e-01 8.31749201e-01 9.95643616e-01 3.67408502e-03\n",
            " 4.35570371e-04 7.15905451e-04 1.20922420e-02 2.51435977e-03\n",
            " 2.55486071e-01 1.07180487e-04 2.03186006e-04 1.03282463e-03\n",
            " 1.44496630e-03 9.67039108e-01 4.66722585e-02 3.46899556e-04\n",
            " 1.23785110e-04 2.71651172e-03 5.22842929e-02 8.66954867e-03\n",
            " 3.92449498e-02 5.83535172e-02 8.96150708e-01 5.76410532e-01\n",
            " 5.95729589e-01 2.86478907e-01 9.40812707e-01 5.99299013e-11\n",
            " 6.60096077e-07 3.40823644e-05 4.83540328e-25 1.12379166e-06\n",
            " 2.04389551e-04 2.92510742e-20 4.28834468e-10 2.45985921e-05\n",
            " 9.98247266e-01 9.78303015e-01 9.99099612e-01 9.98381495e-01\n",
            " 3.67259026e-01 9.28916693e-01 3.51110846e-01 9.99940038e-01\n",
            " 9.96837854e-01 9.93292212e-01 9.94610548e-01 8.10875058e-01\n",
            " 8.43924344e-01 9.66417015e-01 4.19271141e-01 2.08480164e-01\n",
            " 9.99385595e-01 9.99900699e-01 9.99890566e-01 6.86922729e-01\n",
            " 9.99079585e-01 9.72474098e-01 9.99791563e-01 9.95144665e-01\n",
            " 8.87760520e-01 9.96960580e-01 7.19111979e-01 9.26438332e-01\n",
            " 8.59297626e-03 9.66341436e-01 9.54310298e-01 6.06989086e-01\n",
            " 7.67642483e-02 9.99994993e-01 9.99934673e-01 9.97396827e-01\n",
            " 7.61922775e-03 8.47822726e-01 9.82149303e-01 7.12938070e-01\n",
            " 9.90693986e-01 9.99537945e-01 1.83437333e-01 6.06119454e-01\n",
            " 8.34702924e-02 1.16902702e-01 9.91310239e-01 9.44269419e-01\n",
            " 1.16013242e-02 4.95316654e-01 1.60487294e-01 4.27088290e-02\n",
            " 9.99960065e-01 9.89659369e-01 9.48652392e-04 3.04932008e-03\n",
            " 9.99987245e-01 9.99916553e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "Train Epoch: 50 [0/107 (0%)]\tTrain Loss: 0.000268\n",
            "Train Epoch: 50 [4/107 (4%)]\tTrain Loss: 0.000250\n",
            "Train Epoch: 50 [8/107 (7%)]\tTrain Loss: 0.000172\n",
            "Train Epoch: 50 [12/107 (11%)]\tTrain Loss: 0.005814\n",
            "Train Epoch: 50 [16/107 (15%)]\tTrain Loss: 0.000636\n",
            "Train Epoch: 50 [20/107 (19%)]\tTrain Loss: 0.000245\n",
            "Train Epoch: 50 [24/107 (22%)]\tTrain Loss: 0.000020\n",
            "Train Epoch: 50 [28/107 (26%)]\tTrain Loss: 0.000107\n",
            "Train Epoch: 50 [32/107 (30%)]\tTrain Loss: 0.000204\n",
            "Train Epoch: 50 [36/107 (34%)]\tTrain Loss: 0.000363\n",
            "Train Epoch: 50 [40/107 (37%)]\tTrain Loss: 0.000573\n",
            "Train Epoch: 50 [44/107 (41%)]\tTrain Loss: 0.000128\n",
            "Train Epoch: 50 [48/107 (45%)]\tTrain Loss: 0.000288\n",
            "Train Epoch: 50 [52/107 (49%)]\tTrain Loss: 0.000160\n",
            "Train Epoch: 50 [56/107 (52%)]\tTrain Loss: 0.000040\n",
            "Train Epoch: 50 [60/107 (56%)]\tTrain Loss: 0.006786\n",
            "Train Epoch: 50 [64/107 (60%)]\tTrain Loss: 0.000663\n",
            "Train Epoch: 50 [68/107 (64%)]\tTrain Loss: 0.002619\n",
            "Train Epoch: 50 [72/107 (67%)]\tTrain Loss: 0.000180\n",
            "Train Epoch: 50 [76/107 (71%)]\tTrain Loss: 0.004171\n",
            "Train Epoch: 50 [80/107 (75%)]\tTrain Loss: 0.003228\n",
            "Train Epoch: 50 [84/107 (79%)]\tTrain Loss: 0.001387\n",
            "Train Epoch: 50 [88/107 (82%)]\tTrain Loss: 0.001610\n",
            "Train Epoch: 50 [92/107 (86%)]\tTrain Loss: 0.000066\n",
            "Train Epoch: 50 [96/107 (90%)]\tTrain Loss: 0.000169\n",
            "Train Epoch: 50 [100/107 (93%)]\tTrain Loss: 0.003056\n",
            "Train Epoch: 50 [104/107 (97%)]\tTrain Loss: 0.005509\n",
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [1.43505922e-02 9.75801885e-01 8.20561573e-02 1.35653615e-01\n",
            " 3.66184041e-02 1.81534849e-02 7.90432170e-02 7.98801720e-01\n",
            " 3.04983207e-03 5.73272035e-02 8.30840051e-01 7.92540610e-01\n",
            " 7.62556568e-02 2.73014612e-05 4.93276282e-04 4.34832968e-04\n",
            " 7.35102280e-04 3.57457623e-03 9.32959738e-05 1.75741669e-02\n",
            " 5.51691325e-03 9.97395039e-01 9.89582658e-01 9.99924064e-01\n",
            " 9.99290943e-01 9.91530776e-01 9.90747452e-01 4.12869873e-03\n",
            " 7.96737659e-05 4.95490560e-04 6.21991884e-03 9.75587813e-04\n",
            " 1.48399666e-01 4.19281741e-06 3.78204140e-06 1.62962184e-04\n",
            " 8.29488039e-04 9.93642449e-01 2.76614893e-02 8.99560691e-05\n",
            " 2.08238580e-05 3.68735893e-03 1.71342582e-01 5.76338992e-02\n",
            " 6.45778775e-02 2.88840081e-03 9.41712976e-01 8.71821880e-01\n",
            " 7.38004625e-01 7.88500160e-02 9.82687533e-01 1.40203071e-10\n",
            " 6.31639580e-07 7.97252214e-05 1.71836545e-24 1.18800801e-06\n",
            " 2.73274649e-02 2.17484185e-20 9.10947373e-10 1.88397571e-05\n",
            " 9.99881387e-01 9.99626160e-01 9.99950647e-01 9.99874234e-01\n",
            " 8.26671541e-01 9.78005588e-01 4.03975576e-01 9.99996901e-01\n",
            " 9.98069823e-01 9.96292770e-01 9.98296916e-01 9.81077135e-01\n",
            " 9.61799026e-01 9.89661336e-01 9.48540032e-01 3.76273602e-01\n",
            " 9.99477088e-01 9.99796927e-01 9.99970317e-01 6.86490178e-01\n",
            " 9.99269783e-01 9.68889117e-01 9.99939322e-01 9.99911308e-01\n",
            " 9.99536633e-01 9.99589145e-01 9.97622550e-01 9.99363005e-01\n",
            " 4.52141464e-03 9.29517865e-01 2.60280252e-01 8.20199430e-01\n",
            " 4.54638362e-01 9.99998212e-01 9.99774396e-01 9.94987249e-01\n",
            " 5.50474465e-01 9.90208983e-01 9.97251093e-01 2.08102971e-01\n",
            " 9.97428834e-01 9.99868751e-01 1.85268298e-01 6.65776253e-01\n",
            " 5.71491756e-03 1.39629608e-02 9.91132557e-01 9.60350096e-01\n",
            " 7.13398505e-04 5.50290383e-02 2.58892775e-01 9.29119065e-03\n",
            " 9.99754012e-01 9.97661352e-01 1.16087700e-04 5.23960683e-03\n",
            " 9.99996305e-01 9.99974847e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "vote_pred [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "TP= 50 TN= 43 FN= 8 FP= 17\n",
            "TP+FP 67\n",
            "precision 0.746268656716418\n",
            "recall 0.8620689655172413\n",
            "F1 0.7999999999999999\n",
            "acc 0.788135593220339\n",
            "AUCp 0.7893678160919539\n",
            "AUC 0.8655172413793104\n",
            "\n",
            " The epoch is 50, average recall: 0.8621, average precision: 0.7463,average F1: 0.8000, average accuracy: 0.7881, average AUC: 0.8655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZJ-TwNNLXFw",
        "outputId": "4acdde29-0689-41d0-f6d8-090576506279"
      },
      "source": [
        "# test\n",
        "bs = 10\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "epoch = 1\n",
        "r_list = []\n",
        "p_list = []\n",
        "acc_list = []\n",
        "AUC_list = []\n",
        "# TP = 0\n",
        "# TN = 0\n",
        "# FN = 0\n",
        "# FP = 0\n",
        "vote_pred = np.zeros(testset.__len__())\n",
        "vote_score = np.zeros(testset.__len__())\n",
        "\n",
        "\n",
        "targetlist, scorelist, predlist = test(epoch)\n",
        "print('target',targetlist)\n",
        "print('score',scorelist)\n",
        "print('predict',predlist)\n",
        "vote_pred = vote_pred + predlist \n",
        "vote_score = vote_score + scorelist \n",
        "\n",
        "TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
        "\n",
        "TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
        "FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
        "FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
        "\n",
        "print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
        "print('TP+FP',TP+FP)\n",
        "p = TP / (TP + FP)\n",
        "print('precision',p)\n",
        "p = TP / (TP + FP)\n",
        "r = TP / (TP + FN)\n",
        "print('recall',r)\n",
        "F1 = 2 * r * p / (r + p)\n",
        "acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "print('F1',F1)\n",
        "print('acc',acc)\n",
        "AUC = roc_auc_score(targetlist, vote_score)\n",
        "print('AUC', AUC)\n",
        "\n",
        "# f = open(f'model_result/medical_transfer/test_{modelname}_{alpha_name}_LUNA_moco_CT_moco.txt', 'a+')\n",
        "# f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
        "# average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
        "# epoch, r, p, F1, acc, AUC))\n",
        "# f.close()\n",
        "# torch.save(model.state_dict(), \"model_backup/medical_transfer/{}_{}_covid_moco_covid.pt\".format(modelname,alpha_name))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "score [3.01163364e-02 9.99855995e-01 6.55280950e-04 1.99695397e-03\n",
            " 1.59057599e-04 8.90912313e-04 9.16666468e-04 5.92302322e-01\n",
            " 4.99192392e-03 2.59223394e-03 5.91172874e-02 1.76374917e-03\n",
            " 1.50085063e-04 9.02054191e-01 4.48518805e-03 2.13623829e-02\n",
            " 2.63713899e-14 3.02244065e-04 2.24807867e-04 1.44166348e-04\n",
            " 1.59814360e-03 7.61498814e-05 6.33504533e-05 3.08940129e-04\n",
            " 3.70607455e-03 1.51993590e-03 1.79235218e-03 4.58250428e-03\n",
            " 2.33372152e-01 3.01170908e-03 3.50240292e-03 1.11048535e-01\n",
            " 6.05998814e-01 8.16834567e-04 4.15617542e-04 7.36676055e-39\n",
            " 1.33306547e-34 1.06800787e-01 6.40994927e-04 5.76789549e-04\n",
            " 1.18111733e-04 8.32952093e-03 8.00996320e-04 6.67851418e-05\n",
            " 1.44039412e-04 2.46279500e-02 4.72333841e-03 2.17279900e-04\n",
            " 6.17097914e-01 9.07439768e-01 4.39745672e-02 9.03921973e-05\n",
            " 6.78029656e-01 9.75242615e-01 7.49611435e-03 7.09011778e-03\n",
            " 4.92696792e-01 3.84755656e-02 9.98831451e-01 9.67029989e-01\n",
            " 3.68591910e-03 9.99118030e-01 1.54337773e-04 4.81772989e-01\n",
            " 7.87209938e-05 1.91258619e-06 4.31992703e-07 7.97556822e-07\n",
            " 1.86149264e-03 9.95387971e-01 2.35143001e-03 1.12116195e-01\n",
            " 3.17768921e-04 6.60146354e-04 1.09624445e-04 3.57483214e-06\n",
            " 4.48222086e-03 9.74958122e-01 2.33815368e-02 2.08943635e-01\n",
            " 4.22675250e-04 6.63368788e-04 3.62838665e-03 2.65564723e-03\n",
            " 8.63837486e-05 7.50961015e-04 2.18175575e-01 9.49667534e-04\n",
            " 2.06165132e-03 5.87393792e-33 3.98116881e-39 9.54484999e-01\n",
            " 9.75443780e-01 7.04636097e-01 9.00289655e-01 1.53292283e-01\n",
            " 9.55153406e-01 9.95795250e-01 9.99965429e-01 9.37627673e-01\n",
            " 9.92326140e-01 9.99994159e-01 9.99986053e-01 7.01426566e-01\n",
            " 9.94965732e-01 9.99717057e-01 9.98998940e-01 9.71033037e-01\n",
            " 9.92076397e-01 9.99958634e-01 9.95869935e-01 9.97914374e-01\n",
            " 9.97795224e-01 9.88949537e-01 9.95944083e-01 8.43408823e-01\n",
            " 9.99849677e-01 9.99513626e-01 9.99711096e-01 9.99942660e-01\n",
            " 9.99955058e-01 9.99979496e-01 9.99964118e-01 9.99961019e-01\n",
            " 9.99944091e-01 9.99947429e-01 9.99387026e-01 9.99584854e-01\n",
            " 9.98774469e-01 9.91247118e-01 5.53367555e-01 5.87849855e-01\n",
            " 9.80735004e-01 9.45982099e-01 9.90571380e-01 9.97924209e-01\n",
            " 9.99558628e-01 9.99495625e-01 9.99365628e-01 9.98982728e-01\n",
            " 9.19509888e-01 9.96907294e-01 9.99116123e-01 9.81437087e-01\n",
            " 9.90228295e-01 2.95735151e-01 9.99911308e-01 1.70378331e-02\n",
            " 1.38344809e-01 9.98898625e-01 9.94937897e-01 9.67011511e-01\n",
            " 2.04358026e-01 9.88801360e-01 9.98469770e-01 9.99273598e-01\n",
            " 9.99953151e-01 9.99606550e-01 5.01486778e-01 1.38808764e-03\n",
            " 2.86250144e-01 9.99974847e-01 1.36870295e-01 9.99961734e-01\n",
            " 2.06213724e-02 9.99644876e-01 2.44748414e-01 9.98213172e-01\n",
            " 9.25007403e-01 8.75212252e-03 1.39203602e-02 4.01200563e-01\n",
            " 9.99825060e-01 9.95608985e-01 7.48879552e-01 3.87976952e-02\n",
            " 3.67662966e-01 9.65458810e-01 1.89053074e-01 9.78530228e-01\n",
            " 9.97214139e-01 2.20325533e-02 3.60608962e-03 9.96287823e-01\n",
            " 9.83149350e-01 9.87704039e-01 9.99349058e-01 9.99824941e-01\n",
            " 2.68542230e-01 4.81362604e-02 3.29290889e-03 9.36202466e-01\n",
            " 9.99694228e-01 9.80293632e-01 9.97320712e-01 9.87047851e-01\n",
            " 9.42438900e-01 9.18124795e-01 9.58965003e-01 9.93378982e-02\n",
            " 3.21810320e-02 1.14025769e-03 2.01854423e-01]\n",
            "predict [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
            "TP= 81 TN= 79 FN= 24 FP= 19\n",
            "TP+FP 100\n",
            "precision 0.81\n",
            "recall 0.7714285714285715\n",
            "F1 0.7902439024390244\n",
            "acc 0.7881773399014779\n",
            "AUC 0.8926141885325558\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}